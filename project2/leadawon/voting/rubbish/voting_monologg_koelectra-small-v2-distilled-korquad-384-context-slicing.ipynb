{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNWYfo7ZgJaSYw47TSLtfgc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"ebc229e6874c47378261fd048bbd41b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8b3f58bd5d34a97a88a4cbc801248da","IPY_MODEL_d100e9a4c7f34ec38a3e469a1c99d1f7","IPY_MODEL_062d41dedd8248fc9c0f550f26953d17"],"layout":"IPY_MODEL_e269182b3d9c44c88d86b3db3bb551cc"}},"d8b3f58bd5d34a97a88a4cbc801248da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dc886788c8e424ba4ba9bf7792debf2","placeholder":"​","style":"IPY_MODEL_472188726a004c919b7ed9f49451d6e4","value":"100%"}},"d100e9a4c7f34ec38a3e469a1c99d1f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_870595f3f347454fbff78940ef61b58c","max":1491,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f7fbdc19ee5477ca183f1c96e4c4b8c","value":1491}},"062d41dedd8248fc9c0f550f26953d17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56b7b3ab2a484644a700778363ed65f1","placeholder":"​","style":"IPY_MODEL_a7f9df9fc89e4301a226b16bbf94237f","value":" 1491/1491 [18:19&lt;00:00,  1.01step/s, batch_loss=8.838488, loss=1.463552]"}},"e269182b3d9c44c88d86b3db3bb551cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dc886788c8e424ba4ba9bf7792debf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"472188726a004c919b7ed9f49451d6e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"870595f3f347454fbff78940ef61b58c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f7fbdc19ee5477ca183f1c96e4c4b8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56b7b3ab2a484644a700778363ed65f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7f9df9fc89e4301a226b16bbf94237f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f69c0a13996b40b3bd10c4897eac5961":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_173c281d5e0440ebb4e9eebf59cfeea8","IPY_MODEL_57bc1e2b18f9465aabc6391b2a6cbb05","IPY_MODEL_7c4099b9741242aeb56d66cc10a2a185"],"layout":"IPY_MODEL_1f8b056c1f064d55ad3e5e45262797b2"}},"173c281d5e0440ebb4e9eebf59cfeea8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c12f370f80f342d7a5526011294bd048","placeholder":"​","style":"IPY_MODEL_b789c2ff3f2e49d8aff05c1b0c7467a9","value":"Downloading: 100%"}},"57bc1e2b18f9465aabc6391b2a6cbb05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c477c66d7bf24d0ea68f614e5c468b25","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cdd932506b374431aaf9f0a610f10e23","value":49}},"7c4099b9741242aeb56d66cc10a2a185":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e06e421a35624b88a454ef83c07de9a3","placeholder":"​","style":"IPY_MODEL_0eb4aec1d4b145e3971519f9f4aae580","value":" 49.0/49.0 [00:00&lt;00:00, 2.56kB/s]"}},"1f8b056c1f064d55ad3e5e45262797b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c12f370f80f342d7a5526011294bd048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b789c2ff3f2e49d8aff05c1b0c7467a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c477c66d7bf24d0ea68f614e5c468b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdd932506b374431aaf9f0a610f10e23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e06e421a35624b88a454ef83c07de9a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eb4aec1d4b145e3971519f9f4aae580":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4888aac97177418bab3c8ee06ebb3996":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0c4a8d908d64955b5267c959f63228c","IPY_MODEL_b2a77d10bb684853945ceb8a22145d96","IPY_MODEL_e6dc30384fa74349b8001c63ab16f346"],"layout":"IPY_MODEL_5df9a756990c4defb321715abeb55ab4"}},"a0c4a8d908d64955b5267c959f63228c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e456b39ec1a04141a3acd65ae3484f65","placeholder":"​","style":"IPY_MODEL_bc701473db0d474fa0c1a7392b54fd86","value":"Downloading: 100%"}},"b2a77d10bb684853945ceb8a22145d96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_697ecd3d08ff4acfb77777e3360c4fcd","max":472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b1b059e3bb2486b85eea466640d90a3","value":472}},"e6dc30384fa74349b8001c63ab16f346":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d5f8e0515e7454a9a5657b15841177b","placeholder":"​","style":"IPY_MODEL_bfc8061296a342f9a87b9027a4ab6b3f","value":" 472/472 [00:00&lt;00:00, 29.7kB/s]"}},"5df9a756990c4defb321715abeb55ab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e456b39ec1a04141a3acd65ae3484f65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc701473db0d474fa0c1a7392b54fd86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"697ecd3d08ff4acfb77777e3360c4fcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b1b059e3bb2486b85eea466640d90a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d5f8e0515e7454a9a5657b15841177b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfc8061296a342f9a87b9027a4ab6b3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3589f6cad92d47aea8919863bbded062":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfb60fe125cb4686a5eb28bee83fe559","IPY_MODEL_3c03baf007974428983c28602716e075","IPY_MODEL_5486e5c3c1f64350a81c038485d5c97b"],"layout":"IPY_MODEL_7f92b7a20df1459dbb026b6fe89aa9c9"}},"dfb60fe125cb4686a5eb28bee83fe559":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49ddfc3f8bab4cb293ba222a2e0316da","placeholder":"​","style":"IPY_MODEL_5f66e6bec8a3466d843a35f503586d5a","value":"Downloading: 100%"}},"3c03baf007974428983c28602716e075":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f11841ad59cf4903b2f723200d00cdf0","max":255191,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b00fa34adce742d99cd30c68167ad6b2","value":255191}},"5486e5c3c1f64350a81c038485d5c97b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29d66f1fed78445fbb0d5a3aa2f5638c","placeholder":"​","style":"IPY_MODEL_b6dc6d9bb5f641f6b2c83c6194cc6fee","value":" 255k/255k [00:00&lt;00:00, 310kB/s]"}},"7f92b7a20df1459dbb026b6fe89aa9c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49ddfc3f8bab4cb293ba222a2e0316da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f66e6bec8a3466d843a35f503586d5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f11841ad59cf4903b2f723200d00cdf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00fa34adce742d99cd30c68167ad6b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29d66f1fed78445fbb0d5a3aa2f5638c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6dc6d9bb5f641f6b2c83c6194cc6fee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ded49e42119400ab482055b28db8bcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_097478015c374ed5a381dad767d5efb0","IPY_MODEL_606d745eac324b34ad32fac1bf11479a","IPY_MODEL_8b50a46822f54125a9c814adff8e4466"],"layout":"IPY_MODEL_b1bd25d4b453440e8a077230febb7564"}},"097478015c374ed5a381dad767d5efb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa51033fb88842788a3212b42eaa5e09","placeholder":"​","style":"IPY_MODEL_e943b93f278f4d758b3ec8ac8928069d","value":"Downloading: 100%"}},"606d745eac324b34ad32fac1bf11479a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e6cada6ab294b80a53316b1580e06a9","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43b5b2ff4b0f44e18a15eaaffc67b6ce","value":112}},"8b50a46822f54125a9c814adff8e4466":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_922f0b25072b4518b3c0ec2a4c6db22d","placeholder":"​","style":"IPY_MODEL_09828e935c104ee8aeaaa7d66da68ce9","value":" 112/112 [00:00&lt;00:00, 6.06kB/s]"}},"b1bd25d4b453440e8a077230febb7564":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa51033fb88842788a3212b42eaa5e09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e943b93f278f4d758b3ec8ac8928069d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e6cada6ab294b80a53316b1580e06a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b5b2ff4b0f44e18a15eaaffc67b6ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"922f0b25072b4518b3c0ec2a4c6db22d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09828e935c104ee8aeaaa7d66da68ce9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"255fc1f3ab374123bf17d2ae90c339a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa92edea7e284efe889ae426facd6e62","IPY_MODEL_d4f49a9032af4a93b7eca1167c38f40d","IPY_MODEL_2a8d6b40fcc942818d0155ee2fc2b7f8"],"layout":"IPY_MODEL_db18e101030c48a3a28458d0e3ad153d"}},"aa92edea7e284efe889ae426facd6e62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7202dbc465bf46bf97f7f8901407ed44","placeholder":"​","style":"IPY_MODEL_5fc1d6b8ca9e4e638aa606f2da40a6d7","value":"100%"}},"d4f49a9032af4a93b7eca1167c38f40d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeaa3845c4e246df9eca98f3b4676e7d","max":8811,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3267ffce2dd4d60b5aef9e66b11d646","value":8811}},"2a8d6b40fcc942818d0155ee2fc2b7f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76af7947f270475b9e9b7870c7443a9f","placeholder":"​","style":"IPY_MODEL_acf77dd38860414494173e629370fa9e","value":" 8811/8811 [00:00&lt;00:00, 162748.05it/s]"}},"db18e101030c48a3a28458d0e3ad153d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7202dbc465bf46bf97f7f8901407ed44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc1d6b8ca9e4e638aa606f2da40a6d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeaa3845c4e246df9eca98f3b4676e7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3267ffce2dd4d60b5aef9e66b11d646":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76af7947f270475b9e9b7870c7443a9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acf77dd38860414494173e629370fa9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13f85615f8424bc1951770cb36d762a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_720bbfaa194a4ba2afe9d3612dbfb329","IPY_MODEL_c896effd4a6746ed91b99022b1181c1f","IPY_MODEL_f808afdd3e754e7bb4bc58dfea97847a"],"layout":"IPY_MODEL_05a7c26d4e41404693b5ac7e01a02edc"}},"720bbfaa194a4ba2afe9d3612dbfb329":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a326e5328d24143aa01c137eb5da939","placeholder":"​","style":"IPY_MODEL_ec3fd08f150043c7b6edc2e29cf1b88c","value":"100%"}},"c896effd4a6746ed91b99022b1181c1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df553b790f2a4de0b4976f1424bebc97","max":978,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0094aa937bdc4ad3a05f8d356b10f225","value":978}},"f808afdd3e754e7bb4bc58dfea97847a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34171de7a48548ef973529779dbb9963","placeholder":"​","style":"IPY_MODEL_62bf7028d16c4438936ac2b0c2fe08c9","value":" 978/978 [00:00&lt;00:00, 48750.11it/s]"}},"05a7c26d4e41404693b5ac7e01a02edc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a326e5328d24143aa01c137eb5da939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec3fd08f150043c7b6edc2e29cf1b88c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df553b790f2a4de0b4976f1424bebc97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0094aa937bdc4ad3a05f8d356b10f225":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34171de7a48548ef973529779dbb9963":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62bf7028d16c4438936ac2b0c2fe08c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fc5f43361a043f984db7e038e444e17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14d316e4300049caac0c15889c2503fc","IPY_MODEL_a6a9264479b14b4f928ed06af0982902","IPY_MODEL_4ee13851e1714a1e8fc7d61481ed8eea"],"layout":"IPY_MODEL_3510b4f3418a4e58a6e14cd69cab1a87"}},"14d316e4300049caac0c15889c2503fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e032f76b964c01828626000cebb782","placeholder":"​","style":"IPY_MODEL_15e5cb84fbdb4b879144473ad9059660","value":"Downloading: 100%"}},"a6a9264479b14b4f928ed06af0982902":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d386eb52e8b43e6bdb9df26d992967b","max":54844630,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4511e0a78d2f49d2b52808b8d1814ce4","value":54844630}},"4ee13851e1714a1e8fc7d61481ed8eea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31e77171d06a4d8cb9be177950bad564","placeholder":"​","style":"IPY_MODEL_92a84020bd364a0ca20ee9769bf18085","value":" 54.8M/54.8M [00:03&lt;00:00, 21.2MB/s]"}},"3510b4f3418a4e58a6e14cd69cab1a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e032f76b964c01828626000cebb782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15e5cb84fbdb4b879144473ad9059660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d386eb52e8b43e6bdb9df26d992967b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4511e0a78d2f49d2b52808b8d1814ce4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31e77171d06a4d8cb9be177950bad564":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92a84020bd364a0ca20ee9769bf18085":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"861fcbb3951a44d3901d093a30a63feb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d19d6fe593e64bc4a6f8372a097181a2","IPY_MODEL_f8b6c906d2d44a34bef3e5030d22b58d","IPY_MODEL_bbe88ae33509404ba9fd0902a45d606a"],"layout":"IPY_MODEL_c4dbb87a25a54f66bae37e7456b86ca8"}},"d19d6fe593e64bc4a6f8372a097181a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed7eedea902e427e9338a4688e69f639","placeholder":"​","style":"IPY_MODEL_ef2e7e8c4d874f8f8369133068c2eeb3","value":"100%"}},"f8b6c906d2d44a34bef3e5030d22b58d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc293a12c6ae4efe91c34993ca2bba24","max":3709,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f1e3b9371b34738a6b404f4be73b148","value":3709}},"bbe88ae33509404ba9fd0902a45d606a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1102354027ee47c1b067482e0698e22d","placeholder":"​","style":"IPY_MODEL_4772c954eba04d61aa02a724b7d7ccf8","value":" 3709/3709 [00:00&lt;00:00, 163312.65it/s]"}},"c4dbb87a25a54f66bae37e7456b86ca8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed7eedea902e427e9338a4688e69f639":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef2e7e8c4d874f8f8369133068c2eeb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc293a12c6ae4efe91c34993ca2bba24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f1e3b9371b34738a6b404f4be73b148":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1102354027ee47c1b067482e0698e22d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4772c954eba04d61aa02a724b7d7ccf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77},"id":"JdDfIoUOmjSz","outputId":"4eca5de4-cb2e-4c94-a6da-5624ba06c923","executionInfo":{"status":"ok","timestamp":1673420097918,"user_tz":-540,"elapsed":3926643,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-28f407b4-8cf7-411e-ada9-abbe10977f16\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-28f407b4-8cf7-411e-ada9-abbe10977f16\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving output_model_best to output_model_best\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iD2fyMsZUvjr","executionInfo":{"status":"ok","timestamp":1673420156699,"user_tz":-540,"elapsed":58809,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"35d73b29-73c0-4c0d-d5b6-fc0dc10888a7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NzdBggGVDWN","executionInfo":{"status":"ok","timestamp":1673420170880,"user_tz":-540,"elapsed":14186,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"789b7017-8658-41ac-a0a6-1a0466affbd0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}]},{"cell_type":"code","source":["tokenizer_name = \"monologg/koelectra-small-v2-distilled-korquad-384\"\n","model_name = \"monologg/koelectra-small-v2-distilled-korquad-384\""],"metadata":{"id":"DzO254vpvh33","executionInfo":{"status":"ok","timestamp":1673420170881,"user_tz":-540,"elapsed":31,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ldhyGH4nTyGf","executionInfo":{"status":"ok","timestamp":1673420175429,"user_tz":-540,"elapsed":4578,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["import json\n","import random\n","\n","import torch\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW"]},{"cell_type":"code","source":["with open(\"/content/drive/MyDrive/WARNING_PRIVATE_FOLDER/goorm_nlp_8th_group3/goorm_nlp_8th_group3/project2/train.json\", 'rb') as f:\n","    input_dict = json.load(f)\n","input_dict[\"data\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Nw0P9pTT9lU","executionInfo":{"status":"ok","timestamp":1673420177649,"user_tz":-540,"elapsed":2228,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"b124121d-2e5b-4776-de08-273c9d3bad64"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'title': '제주도 장마 시작 … 중부는 이달 말부터',\n"," 'paragraphs': [{'context': '올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.',\n","   'qas': [{'question': '북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?',\n","     'answers': [{'text': '한 달가량', 'answer_start': 478},\n","      {'text': '한 달', 'answer_start': 478}],\n","     'guid': '798db07f0b9046759deed9d4a35ce31e'}]}],\n"," 'news_category': '종합',\n"," 'source': 'hankyung'}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["input_dict[\"data\"][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlXz6rjkT__1","executionInfo":{"status":"ok","timestamp":1673420177650,"user_tz":-540,"elapsed":18,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"f8836863-064a-447e-d417-d0ad99d3bea4"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'title': '부산정보산업진흥원, 과기부 지역SW서비스사업화 지원사업 4개 과제 선정',\n"," 'paragraphs': [{'context': '부산시와 (재)부산정보산업진흥원(원장 이인숙)이 ‘2020~2021년 지역SW서비스사업화 지원사업’ 공모사업에 4개 과제가 선정되어 본격적인 사업 착수에 나선다. 과학기술정보통신부가 주관하는 ‘지역SW서비스사업화 지원사업’은 강소SW기업 및 초기 스타트업의 SW서비스 사업화 지원과 신시장 진출 지원을 통해 기업 경쟁력 강화와 지역경제 활성화를 도모하는 사업이다. 올해부터 2개년으로 진행되며, 국비와 시비, 민자 등 2년간 약 37억원의 예산이 투입된다. 앞서 진흥원은 부산의 미래 먹거리산업인 스마트해양, 지능형기계, 지능정보서비스 분야로 사전 수요조사를 진행했고, 평가를 통해 선정된 5개 과제를 공모사업에 신청했다. 그 결과 부산의 4개 과제가 최종 선정되는 쾌거를 거뒀다. 당 사업은 전국 진흥기관을 대상으로 공모를 시작해, 총 17개 지역에서 42개 과제가 선정되었으며, 4개 과제가 선정된 곳은 부산과 강원지역 뿐이다. 금번 선정된 과제들은 ‘인공지능융합센서와 서보 이송 로봇을 이용한 전단보강재의 자동용접시스템 개발’ 등 총 4개 과제다. 부산시가 지원하고, 부산정보산업진흥원과 지역기업, 대학, 연구소 등이 컨소시엄을 구성하여 기술개발 및 사업화 지원을 추진한다. 2개의 Track으로 구분되는 이번사업은 Track 1(SW중소기업)에서 ㈜에이아이플랫폼, 엔컴(주), Track 2(스타트업)에서는 ㈜토즈, 삼보테크놀로지를 지원한다. ○ ‘Track 1‘의 (주)에이아이플랫폼이 주관기업으로 진행하는 <인공지능 기반 망막 내 아밀로이드 플라크 영상 분석을 통한 치매조기진단 플랫폼 상용화>는 치매 확진의 원인이 되는 중요 단백질(아밀로이드 플라크)을 자체개발 관측장비로 진단한다. 이를 통해 치매를 조기 발견하여, 각종 경제적 비용과 치료 및 예방 등 사회적 문제를 해 결하고 시민들이 쉽게 접근 가능한 실효성 있는 치매관리체계 개발을 목표로 한다. ○ 엔컴(주)이 주관기업으로 참여하는 <AI영상분석 기반 가공철근 생산성 향상 시스템 기술개발 및 사업화>는 산업안전, 환경규제, 생산체계의 변화로 침체된 부산 핵심 산업인 철강업 활성화에 나선다. 실시간으로 절곡되어 나오는 가공철근의 형상을 인식하고 불량 형상 판단 시 적합한 교정 값을 절곡설비에 전달함으로써, 무중단 생산이 가능한 영상분석 기술과 생산설비 자동화 제어기술을 개발한다. ○ ‘Track 2’의 ㈜토즈는 자립기반이 약한 국내 중소형 조선소의 산업기술 변화에 혁신적인 대응을 위해 <가상현실 기반 원격 다자간 선박 및 해양구조물 사전 검사 시스템>을 개발한다. 선박 건조 前, 설계 단계에서 설계자 뿐만 아니라 생산관리자, 품질관리자, 선급검사관, 선주감독관 등의 이해관계자가 공동으로 가상의 환경에서 선박 및 해양구조물의 자재 배치와 간섭, 작업성, 설계 오작 등에 대한 검사를 진행할 수 있는 기술을 확보하여 조선소의 업무효율을 극대화 할 예정이다. ○ 삼보테크놀로지는 재래식 건설 부자재의 시공성, 안전성, 내구성 등의 문제점을 보완하여 시민 안전과 건설근로자의 환경개선, 생산성 및 수익성 향상을 위해 <인공지능융합센서와 새들형 토치 서보 이송 로봇을 이용한 고속 SRD 전단보강재 자동용접시스템>을 개발한다. 로봇응용 SRD 용접자동화 설비를 제작하고, 용접 모니터링 및 품질검사 소프트웨어를 개발하여 건설분야에 4차산업 대비 지능형 생산자동화 기반기술을 확보할 예정이다. (재)부산정보산업진흥원 이인숙 원장은 “이번 코로나19 사태로 인해 부산 기업들이 매출과 고용유지, 자재수급 등에 큰 타격을 입었지만, 지역SW서비스사업화 지원사업을 통해 지역과 기업차원에서 기반을 다지는 계기가 됐으면 좋겠다‘며 ”진흥원은 어려운 사태를 대비해 지역 기업들을 지원할 수 있는 다른 방편을 계속 모색 중이며, 더욱 성장해 나갈 수 있도록 적극 지원하겠다“고 전했다.',\n","   'qas': [{'question': '지능형 생산자동화 기반기술을 개발중인 스타트업은?',\n","     'answers': [{'text': '삼보테크놀로지', 'answer_start': 1422}],\n","     'guid': '67c85e4f86ae43939b807684537c909c'}]}],\n"," 'news_category': '경제',\n"," 'source': 'acrofan'}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from copy import deepcopy\n","def split_input_dict(input_dict, ratio = 0.1, seed = 42):\n","    split_point = int(len(input_dict['data']) * ratio)\n","    random.seed(seed)\n","    random.shuffle(input_dict['data'])\n","    valid_dict = deepcopy(input_dict)\n","    train_dict = input_dict\n","\n","    valid_dict['data'] = input_dict['data'][:split_point]\n","    train_dict['data'] = input_dict['data'][split_point:]\n","    return train_dict, valid_dict"],"metadata":{"id":"rUTHPL_my3e9","executionInfo":{"status":"ok","timestamp":1673420177650,"user_tz":-540,"elapsed":6,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def read_input(path):\n","    with open(path, 'rb') as f:\n","        input_dict = json.load(f)\n","    train_dict,valid_dict =split_input_dict(input_dict)\n","    train_contexts = []\n","    train_questions = []\n","    train_answers = []\n","    for group in tqdm(train_dict['data']):       #딕셔너리 하나씩 꺼낸다.\n","        for passage in group['paragraphs']:     #딕셔너리의 paragraphs\n","            context = passage['context']        #paragraphs의 context\n","            for qa in passage['qas']:           #paragraphs의 qas\n","                question = qa['question']       #paragraphs의 question\n","                for answer in qa['answers']:    #question의 answers\n","                    ### context 넘겨서 자르기 ###\n","                    target_context = context\n","                    if answer['answer_start'] > 1400:\n","                        target_context = target_context[1000:]\n","                        answer['answer_start'] -= 1000 \n","                    elif answer['answer_start'] > 1200:\n","                        target_context = target_context[800:]\n","                        answer['answer_start'] -= 800\n","                    elif answer['answer_start'] > 1000:\n","                        target_context = target_context[600:]\n","                        answer['answer_start'] -= 600\n","                    elif answer['answer_start'] > 800:\n","                        target_context = target_context[400:]\n","                        answer['answer_start'] -= 400\n","                    \n","                    train_contexts.append(target_context)    #answers의 한 answer당 해당하는 context 저장\n","                    ### context 넘겨서 자르기 ###\n","                    train_questions.append(question)  #answers의 한 answer당 해당하는 question 저장\n","                    train_answers.append(answer)      #answers의 한 answer 저장\n","  \n","    valid_contexts = []\n","    valid_questions = []\n","    valid_answers = []\n","    for group in tqdm(valid_dict['data']):       #딕셔너리 하나씩 꺼낸다.\n","        for passage in group['paragraphs']:     #딕셔너리의 paragraphs\n","            context = passage['context']        #paragraphs의 context\n","            for qa in passage['qas']:           #paragraphs의 qas\n","                question = qa['question']       #paragraphs의 question\n","                for answer in qa['answers']:    #question의 answers\n","                    ### context 넘겨서 자르기 ###\n","                    target_context = context\n","                    if answer['answer_start'] > 1400:\n","                        target_context = target_context[1000:]\n","                        answer['answer_start'] -= 1000 \n","                    elif answer['answer_start'] > 1200:\n","                        target_context = target_context[800:]\n","                        answer['answer_start'] -= 800\n","                    elif answer['answer_start'] > 1000:\n","                        target_context = target_context[600:]\n","                        answer['answer_start'] -= 600\n","                    elif answer['answer_start'] > 800:\n","                        target_context = target_context[400:]\n","                        answer['answer_start'] -= 400\n","                    \n","                    valid_contexts.append(target_context)    #answers의 한 answer당 해당하는 context 저장\n","                    ### context 넘겨서 자르기 ###\n","                    valid_questions.append(question)  #answers의 한 answer당 해당하는 question 저장\n","                    valid_answers.append(answer)      #answers의 한 answer 저장\n","    return train_contexts, train_questions, train_answers, valid_contexts, valid_questions, valid_answers"],"metadata":{"id":"QyvCyOeyUAuX","executionInfo":{"status":"ok","timestamp":1673420177650,"user_tz":-540,"elapsed":6,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def add_end_idx(answers, contexts):\n","    for answer, context in zip(answers, contexts):\n","        gold_text = answer['text']\n","        start_idx = answer['answer_start']\n","        end_idx = start_idx + len(gold_text)\n","\n","        if context[start_idx:end_idx] == gold_text:\n","            answer['answer_end'] = end_idx\n","        elif context[start_idx-1:end_idx-1] == gold_text:\n","            print(\"there is an unitended error in dataset\") #이렇게까지 할 필요가 있나?\n","            answer['answer_start'] = start_idx - 1\n","            answer['answer_end'] = end_idx - 1\n","        elif context[start_idx-2:end_idx-2] == gold_text:\n","            print(\"there is an unitended error in dataset\")\n","            answer['answer_start'] = start_idx - 2\n","            answer['answer_end'] = end_idx - 2"],"metadata":{"id":"OBumo39dUH8R","executionInfo":{"status":"ok","timestamp":1673420177651,"user_tz":-540,"elapsed":6,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"],"metadata":{"id":"MEN_bEdcUJZq","executionInfo":{"status":"ok","timestamp":1673420186817,"user_tz":-540,"elapsed":9171,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["f69c0a13996b40b3bd10c4897eac5961","173c281d5e0440ebb4e9eebf59cfeea8","57bc1e2b18f9465aabc6391b2a6cbb05","7c4099b9741242aeb56d66cc10a2a185","1f8b056c1f064d55ad3e5e45262797b2","c12f370f80f342d7a5526011294bd048","b789c2ff3f2e49d8aff05c1b0c7467a9","c477c66d7bf24d0ea68f614e5c468b25","cdd932506b374431aaf9f0a610f10e23","e06e421a35624b88a454ef83c07de9a3","0eb4aec1d4b145e3971519f9f4aae580","4888aac97177418bab3c8ee06ebb3996","a0c4a8d908d64955b5267c959f63228c","b2a77d10bb684853945ceb8a22145d96","e6dc30384fa74349b8001c63ab16f346","5df9a756990c4defb321715abeb55ab4","e456b39ec1a04141a3acd65ae3484f65","bc701473db0d474fa0c1a7392b54fd86","697ecd3d08ff4acfb77777e3360c4fcd","1b1b059e3bb2486b85eea466640d90a3","8d5f8e0515e7454a9a5657b15841177b","bfc8061296a342f9a87b9027a4ab6b3f","3589f6cad92d47aea8919863bbded062","dfb60fe125cb4686a5eb28bee83fe559","3c03baf007974428983c28602716e075","5486e5c3c1f64350a81c038485d5c97b","7f92b7a20df1459dbb026b6fe89aa9c9","49ddfc3f8bab4cb293ba222a2e0316da","5f66e6bec8a3466d843a35f503586d5a","f11841ad59cf4903b2f723200d00cdf0","b00fa34adce742d99cd30c68167ad6b2","29d66f1fed78445fbb0d5a3aa2f5638c","b6dc6d9bb5f641f6b2c83c6194cc6fee","8ded49e42119400ab482055b28db8bcc","097478015c374ed5a381dad767d5efb0","606d745eac324b34ad32fac1bf11479a","8b50a46822f54125a9c814adff8e4466","b1bd25d4b453440e8a077230febb7564","fa51033fb88842788a3212b42eaa5e09","e943b93f278f4d758b3ec8ac8928069d","8e6cada6ab294b80a53316b1580e06a9","43b5b2ff4b0f44e18a15eaaffc67b6ce","922f0b25072b4518b3c0ec2a4c6db22d","09828e935c104ee8aeaaa7d66da68ce9"]},"outputId":"5e0536b0-2233-409d-cdfb-6f9414bf348a"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f69c0a13996b40b3bd10c4897eac5961"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/472 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4888aac97177418bab3c8ee06ebb3996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/255k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3589f6cad92d47aea8919863bbded062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ded49e42119400ab482055b28db8bcc"}},"metadata":{}}]},{"cell_type":"code","source":["question = \"북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?\"\n","context = \"올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.\"\n","tokenizer(context, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVb8hk2WUKx0","executionInfo":{"status":"ok","timestamp":1673420186817,"user_tz":-540,"elapsed":29,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"ccd260eb-4be7-4b9a-8591-f72e079e9564"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [2, 156, 18876, 8381, 29956, 550, 29982, 2757, 29951, 29962, 392, 30201, 29948, 5, 188, 55, 4473, 4660, 29961, 8674, 29997, 29948, 23326, 30672, 455, 1821, 29961, 6, 30124, 103, 30277, 8381, 29956, 392, 30292, 627, 29947, 29948, 5, 550, 29982, 5337, 29951, 541, 30013, 2757, 4613, 23905, 29951, 24, 29950, 8381, 9972, 29953, 814, 9563, 17196, 2757, 12364, 298, 7418, 16239, 29951, 10954, 21036, 29956, 1358, 29954, 13956, 3196, 29951, 1, 7532, 29959, 29950, 204, 29961, 97, 29956, 2708, 29948, 5, 881, 29953, 8381, 29950, 10062, 29997, 29948, 28, 260, 57, 29982, 18, 136, 29973, 29997, 1312, 989, 5046, 392, 30201, 29948, 5, 8381, 29950, 15024, 29948, 30207, 29957, 299, 10299, 27674, 29990, 14, 30833, 278, 30425, 29957, 84, 30128, 27805, 29973, 27674, 29947, 1028, 2158, 30078, 29950, 8381, 9972, 29951, 29962, 2185, 29950, 97, 29965, 913, 1086, 5, 8381, 9972, 29961, 462, 29982, 2757, 943, 4613, 3306, 9563, 11560, 2883, 90, 29982, 30277, 548, 18521, 29973, 1583, 14726, 30108, 29954, 814, 29952, 397, 45, 9563, 835, 5, 26701, 347, 90, 260, 610, 29982, 3378, 4660, 29951, 29967, 8674, 29997, 29948, 5752, 455, 8381, 29956, 5046, 26845, 627, 29947, 29948, 5, 416, 8381, 9972, 29952, 5551, 19393, 29950, 299, 10299, 3741, 30481, 1874, 29947, 9363, 188, 55, 4473, 4660, 29961, 10062, 29997, 29948, 23326, 30672, 29956, 30293, 1821, 29961, 6, 30124, 103, 628, 8381, 29956, 392, 30292, 45, 29947, 24545, 58, 5337, 29953, 515, 29947, 29948, 5, 8381, 9972, 29961, 378, 14, 148, 29956, 30293, 2355, 9889, 29983, 29965, 17386, 30053, 3196, 29951, 97, 29965, 2240, 30494, 627, 29947, 29948, 5, 409, 346, 30027, 30067, 846, 30055, 29951, 541, 30013, 4473, 4660, 29953, 8381, 392, 29982, 29961, 121, 30086, 9129, 260, 509, 29982, 29947, 30080, 2673, 8381, 29960, 30067, 29961, 1314, 29982, 18, 5293, 29982, 29974, 29950, 550, 5, 28, 29982, 29947, 30080, 29948, 5, 5337, 29961, 5849, 8381, 29960, 30067, 29953, 846, 10210, 29947, 7417, 260, 1, 10062, 29990, 1623, 29959, 8345, 51, 29952, 45, 9563, 4390, 29948, 5, 2423, 1686, 131, 29990, 1263, 29953, 235, 29956, 1428, 29950, 462, 29982, 648, 188, 29961, 4884, 6158, 29947, 613, 1556, 440, 97, 29950, 9628, 109, 29952, 45, 9563, 675, 30340, 1117, 2815, 29951, 29950, 7916, 29947, 116, 29952, 627, 29947, 29948, 5, 3, 299, 10299, 27674, 29990, 84, 30128, 27805, 29973, 27674, 29947, 1028, 417, 29951, 11536, 29950, 655, 29961, 420, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["class KlueDataset(Dataset):\n","    def __init__(self, contexts, questions, answers, model_max_position_embedings, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.answers = answers\n","        self.questions = questions\n","        self.contexts = contexts\n","        self.model_max_position_embedings = model_max_position_embedings\n","        print(\"Tokenizing ...\")\n","        self.encodings = self.tokenizer(self.contexts, \n","                                        self.questions,\n","                                        max_length=512, #512 truncation\n","                                        truncation=True,\n","                                        padding=\"max_length\",\n","                                        return_token_type_ids=False)\n","        print(\"Done !!!\")\n","        self.add_token_positions()\n","        \n","    def add_token_positions(self):\n","        start_positions = []\n","        end_positions = []\n","        for i in range(len(self.answers)):\n","            start_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_start']))\n","            end_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_end'] - 1)) # -1으로 : 진짜로 답이 있는 end_position 의 인덱스를 구함.(char_to_token은 인덱스를 구함)\n","            #https://huggingface.co/docs/tokenizers/v0.13.2/en/api/encoding#tokenizers.Encoding.char_to_token\n","\n","            # positions 값이 None 값이라면, answer가 포함된 context가 잘렸다는 의미\n","            if start_positions[-1] is None:\n","                print(\"there is an error 1\")\n","                start_positions[-1] = self.model_max_position_embedings\n","            if end_positions[-1] is None:\n","                print(\"there is an error 2\")\n","                end_positions[-1] = self.model_max_position_embedings\n","\n","        self.encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","        \n","    def get_data(self):\n","        return {\"contexts\":self.contexts, 'questions':self.questions, 'answers':self.answers}\n","    \n","    \n","    def get_encodings(self):\n","        return self.encodings\n","        \n","    \n","    def __getitem__(self, idx):\n","        return {key:torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","    \n","    def __len__(self):\n","        return len(self.encodings['input_ids'])"],"metadata":{"id":"1Q4tWEnKUMMa","executionInfo":{"status":"ok","timestamp":1673420186818,"user_tz":-540,"elapsed":24,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_contexts, train_questions, train_answers, valid_contexts, valid_questions, valid_answers = read_input(\"/content/drive/MyDrive/WARNING_PRIVATE_FOLDER/goorm_nlp_8th_group3/goorm_nlp_8th_group3/project2/train.json\")\n","add_end_idx(train_answers, train_contexts)                                                      #anwer 마다 answer_end 달아준다.\n","train_dataset = KlueDataset(train_contexts, train_questions, train_answers, 512, tokenizer)\n","\n","add_end_idx(valid_answers, valid_contexts)                                                      #anwer 마다 answer_end 달아준다.\n","valid_dataset = KlueDataset(valid_contexts, valid_questions, valid_answers, 512, tokenizer)"],"metadata":{"id":"rU76rNKaUO5i","colab":{"base_uri":"https://localhost:8080/","height":320,"referenced_widgets":["255fc1f3ab374123bf17d2ae90c339a6","aa92edea7e284efe889ae426facd6e62","d4f49a9032af4a93b7eca1167c38f40d","2a8d6b40fcc942818d0155ee2fc2b7f8","db18e101030c48a3a28458d0e3ad153d","7202dbc465bf46bf97f7f8901407ed44","5fc1d6b8ca9e4e638aa606f2da40a6d7","aeaa3845c4e246df9eca98f3b4676e7d","f3267ffce2dd4d60b5aef9e66b11d646","76af7947f270475b9e9b7870c7443a9f","acf77dd38860414494173e629370fa9e","13f85615f8424bc1951770cb36d762a8","720bbfaa194a4ba2afe9d3612dbfb329","c896effd4a6746ed91b99022b1181c1f","f808afdd3e754e7bb4bc58dfea97847a","05a7c26d4e41404693b5ac7e01a02edc","3a326e5328d24143aa01c137eb5da939","ec3fd08f150043c7b6edc2e29cf1b88c","df553b790f2a4de0b4976f1424bebc97","0094aa937bdc4ad3a05f8d356b10f225","34171de7a48548ef973529779dbb9963","62bf7028d16c4438936ac2b0c2fe08c9"]},"executionInfo":{"status":"ok","timestamp":1673420193622,"user_tz":-540,"elapsed":6828,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"def7a1aa-75f8-467c-e817-00b338c59812"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8811 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"255fc1f3ab374123bf17d2ae90c339a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/978 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f85615f8424bc1951770cb36d762a8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenizing ...\n","Done !!!\n","there is an error 1\n","there is an error 2\n","there is an error 1\n","there is an error 2\n","there is an error 2\n","there is an error 1\n","there is an error 2\n","there is an error 1\n","there is an error 2\n","Tokenizing ...\n","Done !!!\n"]}]},{"cell_type":"code","source":["model = AutoModelForQuestionAnswering.from_pretrained(model_name)"],"metadata":{"id":"s-UGcsCxUQSd","executionInfo":{"status":"ok","timestamp":1673420199821,"user_tz":-540,"elapsed":6204,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["6fc5f43361a043f984db7e038e444e17","14d316e4300049caac0c15889c2503fc","a6a9264479b14b4f928ed06af0982902","4ee13851e1714a1e8fc7d61481ed8eea","3510b4f3418a4e58a6e14cd69cab1a87","30e032f76b964c01828626000cebb782","15e5cb84fbdb4b879144473ad9059660","6d386eb52e8b43e6bdb9df26d992967b","4511e0a78d2f49d2b52808b8d1814ce4","31e77171d06a4d8cb9be177950bad564","92a84020bd364a0ca20ee9769bf18085"]},"outputId":"5830cd16-e42d-4ffa-ed77-b108d5482a2e"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/54.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc5f43361a043f984db7e038e444e17"}},"metadata":{}}]},{"cell_type":"code","source":["EPOCH = 3\n","LEARNING_RATE = 5e-5\n","BATCH_SIZE = 32"],"metadata":{"id":"u7rskVG5UR48","executionInfo":{"status":"ok","timestamp":1673420199822,"user_tz":-540,"elapsed":35,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def train_runner(model, train_dataset, valid_dataset , batch_size, num_train_epochs, learning_rate):\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    \n","    model.to(device)\n","    model.train()\n","    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n","    valid_dataloader = DataLoader(dataset = valid_dataset, batch_size = batch_size)\n","\n","    lowest_total_valid_loss = 9999.\n","\n","    global_total_step = len(train_dataloader) * num_train_epochs\n","    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0)\n","    print(\"TRAIN START\")\n","    with tqdm(total=global_total_step, unit='step') as t:\n","        total = 0\n","        total_loss = 0\n","        for epoch in range(num_train_epochs):\n","            for iteration,batch in enumerate(train_dataloader):\n","                optimizer.zero_grad()\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                start_positions = batch['start_positions'].to(device)\n","                end_positions = batch['end_positions'].to(device)\n","                outputs = model(input_ids,\n","                             attention_mask=attention_mask,\n","                             start_positions=start_positions,\n","                             end_positions=end_positions)\n","                loss = outputs.loss\n","                loss.backward()\n","                optimizer.step()\n","                \n","                batch_loss = loss.item() * len(input_ids)\n","                total += len(input_ids)\n","                total_loss += batch_loss\n","                global_total_step += 1\n","                t.set_postfix(loss=\"{:.6f}\".format(total_loss / total), batch_loss=\"{:.6f}\".format(batch_loss))\n","                t.update(1)\n","                \n","                del input_ids\n","                del attention_mask\n","                del start_positions\n","                del end_positions\n","                del outputs\n","                del loss\n","\n","                ## validation ##\n","                if iteration != 0 and iteration % int(len(train_dataloader) / 10) == 0:\n","                    total_valid_loss = 0\n","                    for batch_val in valid_dataloader:\n","                        model.eval()\n","                        optimizer.zero_grad()\n","\n","                        input_ids = batch_val['input_ids'].to(device)\n","                        attention_mask = batch_val['attention_mask'].to(device)\n","                        start_positions = batch_val['start_positions'].to(device)\n","                        end_positions = batch_val['end_positions'].to(device)\n","                \n","                        with torch.no_grad():\n","                            outputs = model(input_ids,\n","                                    attention_mask=attention_mask,\n","                                    start_positions=start_positions,\n","                                    end_positions=end_positions)\n","                            loss = outputs.loss\n","                            total_valid_loss += loss.item()\n","                    \n","                    if total_valid_loss < lowest_total_valid_loss:\n","                        print(f\"lowest_total_valid_loss: {total_valid_loss} epoch : {epoch} iteration : {iteration}\")\n","                        torch.save(model.state_dict(),'./output_model_best')\n","                        lowest_total_valid_loss = total_valid_loss\n","                ## validation ##\n","\n","    #model.save_pretrained(\"./klue_output_model\")\n","    print(\"TRAIN END\")"],"metadata":{"id":"hAoMuSXCUUc0","executionInfo":{"status":"ok","timestamp":1673420199823,"user_tz":-540,"elapsed":34,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train_runner(model,train_dataset,valid_dataset, BATCH_SIZE, EPOCH, LEARNING_RATE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326,"referenced_widgets":["ebc229e6874c47378261fd048bbd41b0","d8b3f58bd5d34a97a88a4cbc801248da","d100e9a4c7f34ec38a3e469a1c99d1f7","062d41dedd8248fc9c0f550f26953d17","e269182b3d9c44c88d86b3db3bb551cc","8dc886788c8e424ba4ba9bf7792debf2","472188726a004c919b7ed9f49451d6e4","870595f3f347454fbff78940ef61b58c","9f7fbdc19ee5477ca183f1c96e4c4b8c","56b7b3ab2a484644a700778363ed65f1","a7f9df9fc89e4301a226b16bbf94237f"]},"id":"0ixcdbKvUV-A","outputId":"82799323-be4e-43d3-f074-973df4cab7b6","executionInfo":{"status":"ok","timestamp":1673330513870,"user_tz":-540,"elapsed":1100290,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TRAIN START\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1491 [00:00<?, ?step/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc229e6874c47378261fd048bbd41b0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["lowest_total_valid_loss: 149.65906262397766 epoch : 0 iteration : 49\n","lowest_total_valid_loss: 128.1626913547516 epoch : 0 iteration : 98\n","lowest_total_valid_loss: 118.34222495555878 epoch : 0 iteration : 147\n","lowest_total_valid_loss: 114.39701163768768 epoch : 0 iteration : 196\n","lowest_total_valid_loss: 110.5122891664505 epoch : 0 iteration : 245\n","lowest_total_valid_loss: 108.90088152885437 epoch : 0 iteration : 294\n","lowest_total_valid_loss: 105.69972097873688 epoch : 0 iteration : 343\n","lowest_total_valid_loss: 104.61543434858322 epoch : 0 iteration : 392\n","lowest_total_valid_loss: 103.32061803340912 epoch : 0 iteration : 441\n","lowest_total_valid_loss: 101.94842576980591 epoch : 1 iteration : 98\n","TRAIN END\n"]}]},{"cell_type":"code","source":["def read_dev_klue(path):\n","    with open(path, 'rb') as f:\n","        klue_dict = json.load(f)\n","\n","    contexts = []\n","    questions = []\n","    answers = []\n","    guids = []\n","\n","    for group in tqdm(klue_dict['data']):\n","        for passage in group['paragraphs']:\n","            context = passage['context']\n","            for qa in passage['qas']:\n","                question = qa['question']\n","                guid = qa['guid']\n","                #temp_answer = []\n","                #for answer in qa['answers']:\n","                    #temp_answer.append(answer['text'])\n","                #if len(temp_answer) != 0: # answers의 길이가 0 == 답변할 수 없는 질문\n","                    #contexts.append(context)\n","                    #questions.append(question)\n","                    #answers.append(temp_answer)\n","                contexts.append(context)##\n","                questions.append(question)##\n","                guids.append(guid)\n","\n","    #return contexts, questions, answers\n","    return contexts, questions , guids"],"metadata":{"id":"gpww3QngUXmP","executionInfo":{"status":"ok","timestamp":1673420199823,"user_tz":-540,"elapsed":33,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#dev_contexts, dev_questions, dev_answers = read_dev_klue(\"/content/drive/MyDrive/WARNING_PRIVATE_FOLDER/goorm_nlp_8th_group3/goorm_nlp_8th_group3/project2/test.json\")\n","dev_contexts, dev_questions, dev_guids = read_dev_klue(\"/content/drive/MyDrive/WARNING_PRIVATE_FOLDER/goorm_nlp_8th_group3/goorm_nlp_8th_group3/project2/test.json\")"],"metadata":{"id":"3dT95zo0UZH7","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["861fcbb3951a44d3901d093a30a63feb","d19d6fe593e64bc4a6f8372a097181a2","f8b6c906d2d44a34bef3e5030d22b58d","bbe88ae33509404ba9fd0902a45d606a","c4dbb87a25a54f66bae37e7456b86ca8","ed7eedea902e427e9338a4688e69f639","ef2e7e8c4d874f8f8369133068c2eeb3","fc293a12c6ae4efe91c34993ca2bba24","6f1e3b9371b34738a6b404f4be73b148","1102354027ee47c1b067482e0698e22d","4772c954eba04d61aa02a724b7d7ccf8"]},"executionInfo":{"status":"ok","timestamp":1673420199824,"user_tz":-540,"elapsed":33,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"e80226e1-0fe0-4111-c14a-062713c56162"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3709 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"861fcbb3951a44d3901d093a30a63feb"}},"metadata":{}}]},{"cell_type":"code","source":["import re\n","def remove_post(text):\n","        ''' 불필요한 기호 제거 '''\n","        \n","        text = re.sub(\"'\", \"\", text)\n","        text = re.sub('\"', \"\", text)\n","        text = re.sub('《', \"\", text)\n","        text = re.sub('》', \"\", text)\n","        text = re.sub('<', \"\", text)\n","        text = re.sub('>', \"\", text)\n","        text = re.sub('〈', \"\", text)\n","        text = re.sub('〉', \"\", text)\n","        text = re.sub(\"\\(\", \"\", text)\n","        text = re.sub(\"\\)\", \"\", text)\n","        text = re.sub(\"‘\", \"\", text)\n","        text = re.sub(\"’\", \"\", text)\n","        text = re.sub(\"  \", \" \", text)\n","        text = re.sub(\"#\", \"\", text)\n","        text = text.strip()\n","        return text"],"metadata":{"id":"T3L9vhb2JYXq","executionInfo":{"status":"ok","timestamp":1673420199824,"user_tz":-540,"elapsed":23,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# start, end logit의 확률값을 이용한 예측 정답값\n","# logit의 상위 5개 확률을 리스트로 뽑아 틀린 정답이었다면 다음 확률로 넘어가서 확인.\n","\n","def to_list(tensor):\n","    return tensor.detach().cpu().tolist()\n","\n","def logits_change(input_ids, STA_logits, END_logits):\n","\n","    # 로짓의 확률값 ~ 상위 5개를 선택 \n","    # 틀린 추론이었다면 다음 선택 (틀린 추론 : start > end, 길이가 너무 긴 문장.)\n","    change_logit = 0\n","    cnt = 0\n","    \n","    # 기존 정답\n","    save_s = STA_logits\n","    save_e = END_logits\n","\n","    STK_start_index, STK_end_index = save_s.argmax(dim=-1), save_e.argmax(dim=-1)\n","    save_pred_ids = tokenizer.decode(input_ids[0][STK_start_index: STK_end_index + 1])\n","    print(save_pred_ids) \n","\n","    # 바뀐 정답\n","    STA_logits = to_list(STA_logits)[0]\n","    END_logits = to_list(END_logits)[0]\n","\n","    start_idx_and_logit = sorted(enumerate(STA_logits), key=lambda x: x[1], reverse=True)\n","    end_idx_and_logit = sorted(enumerate(END_logits), key=lambda x: x[1], reverse=True)\n","\n","    start_idx_and_logit = start_idx_and_logit[:5]\n","    end_idx_and_logit = end_idx_and_logit[:5]\n","\n","    TK_start_index, TK_end_index = start_idx_and_logit, end_idx_and_logit\n","\n","    pred_prob_loss = 0\n","\n","    for i in range(5):\n","        if TK_start_index[i][0] > TK_end_index[i][0] or TK_end_index[i][0] - TK_start_index[i][0] > 10 : \n","            cnt += 1\n","            continue\n","        else : \n","            change_logit += 1\n","            pred_ids = input_ids[0][TK_start_index[i][0]: TK_end_index[i][0] + 1]\n","            pred_prob_loss = TK_start_index[i][1] + TK_end_index[i][1]\n","            pred_ids = tokenizer.decode(pred_ids)\n","            #print(pred_ids, 'change')\n","            break\n","\n","    if change_logit == 0 :\n","        return save_pred_ids, max(save_s[0]) + max(save_e[0])\n","    elif cnt == 5:\n","        return '', 0\n","    else : \n","        if pred_ids == save_pred_ids:\n","            #print('same answer')\n","            return pred_ids , max(save_s[0]) + max(save_e[0])\n","        else :\n","            #print('different answer')\n","            return pred_ids , pred_prob_loss\n","\n","    \n","\n","# start_logits , end_logits\n","# index를 추적하면서 시작, 종료 index에 대한 확률이 가장 높은것을 선택하는 방법.\n","# 만약에 차이가 큰 start, end 값을 반환할때 이 정보들을 저장하지 않고 넘긴다면? \n"],"metadata":{"id":"VUok6PUJHVWg","executionInfo":{"status":"ok","timestamp":1673420199825,"user_tz":-540,"elapsed":23,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"ZH6VSrKLn-PI","executionInfo":{"status":"ok","timestamp":1673420199825,"user_tz":-540,"elapsed":22,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","\n","def prediction(contexts, questions, guids):\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    model.load_state_dict(torch.load('./output_model_best', map_location=device))\n","    model.to(device)\n","    \n","    model.eval()\n","    \n","    result = []\n","    list_dict_all = []\n","    list_dict_all2 = []\n","    with torch.no_grad():\n","        \n","        for context, question, guid in zip(contexts, questions, guids):\n","            encodings = tokenizer(context, question, max_length=512, truncation=True,\n","                                     padding=\"max_length\", return_token_type_ids=False)\n","            encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n","            \n","            input_ids = encodings[\"input_ids\"].to(device)\n","            attention_mask = encodings[\"attention_mask\"].to(device)\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n","            ### uploading pickle ###\n","            dict_all = {\"input_ids\":input_ids,\"start_logits\":start_logits,\"end_logits\":end_logits,\"tokenizer_name\":tokenizer_name,\"guid\":guid}\n","            list_dict_all.append(dict(dict_all))\n","            ### uploading pickle ###\n","            # pred, prob1 =logits_change(input_ids, start_logits, end_logits)\n","\n","\n","            #token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n","            #pred_ids = input_ids[0][token_start_index: token_end_index + 1]\n","\n","\n","\n","            ### context 뒷부분 test ###\n","            if len(context) > 800:\n","                if len(context) > 1600:\n","                    context=context[800:]\n","                elif len(context) > 1400:\n","                    context = context[600:]\n","                elif len(context) > 1200:\n","                    context = context[400:]\n","                elif len(context) > 1000:\n","                    context = context[200:]\n","                else:\n","                    context = context[100:]\n","                encodings = tokenizer(context, question, max_length=512, truncation=True,\n","                                     padding=\"max_length\", return_token_type_ids=False)\n","                encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n","            \n","                input_ids = encodings[\"input_ids\"].to(device)\n","                attention_mask = encodings[\"attention_mask\"].to(device)\n","            \n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                start_logits2, end_logits2 = outputs.start_logits, outputs.end_logits\n","                ### uploading pickle ###\n","                dict_all2 = {\"input_ids\":input_ids,\"start_logits\":start_logits,\"end_logits\":end_logits,\"tokenizer_name\":tokenizer_name,\"guid\":guid}\n","                list_dict_all2.append(dict(dict_all))\n","            else:\n","                encodings = tokenizer(context, question, max_length=512, truncation=True,\n","                                     padding=\"max_length\", return_token_type_ids=False)\n","                encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n","            \n","                input_ids = encodings[\"input_ids\"].to(device)\n","                attention_mask = encodings[\"attention_mask\"].to(device)\n","            \n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                start_logits2, end_logits2 = outputs.start_logits, outputs.end_logits\n","                ### uploading pickle ###\n","                dict_all2 = {\"input_ids\":input_ids,\"start_logits\":start_logits,\"end_logits\":end_logits,\"tokenizer_name\":tokenizer_name,\"guid\":guid}\n","                list_dict_all2.append(dict(dict_all))\n","                ### uploading pickle ###\n","            #     #token_start_index, token_end_index = start_logits2.argmax(dim=-1), end_logits2.argmax(dim=-1)\n","            #     #pred_ids = input_ids[0][token_start_index: token_end_index + 1]\n","            #     #pred2 = tokenizer.decode(pred_ids)\n","\n","            #     pred2, prob2 = logits_change(input_ids, start_logits2, end_logits2)\n","            #     #print(pred,\"####\",pred2, end=\"-----\")\n","            #     if prob1 < prob2:\n","            #         pred = pred2\n","\n","            #     #print(pred)\n","\n","            # ### context 뒷부분 test ###\n","            # pred = pred[:8]\n","            # pred = remove_post(pred)\n","            # tp = (guid,pred)\n","            \n","            # result.append(tp)\n","        with open('input_ids_and_logits.pickle', 'wb') as f:\n","            pickle.dump(list_dict_all, f)\n","        with open('input_ids_and_logits_koelec2.pickle', 'wb') as f:\n","            pickle.dump(list_dict_all2, f)\n","        print(list_dict_all2[:5])\n","    return result"],"metadata":{"id":"1YMQbh-qUanh","executionInfo":{"status":"ok","timestamp":1673420206543,"user_tz":-540,"elapsed":14,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["pred_answers = prediction(dev_contexts, dev_questions, dev_guids)\n","pred_answers"],"metadata":{"id":"oEQ3CJBeUbze","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673421297150,"user_tz":-540,"elapsed":1090618,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"9071fe3a-aef9-4c68-9015-e6b33db8964d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'input_ids': tensor([[    2,  7636,  3166,    36,   237, 10093, 30425,    39,     9,  5361,\n","           509, 29995, 30027, 29952,  1379, 29959, 29950,    96,  7636,  3166,\n","           509, 29995, 30027, 13595,    95,    10,  3815,  1216, 29594,   253,\n","         29948,     5,   334,  7636,  3166,   509, 29995, 30027, 13595,    36,\n","          1084,   509, 29995, 30027, 13595,    39,    13,  7636,    57, 29966,\n","          1643, 30033,    85, 29966,  1643,    18,   145, 29966,  1643,    18,\n","           150, 29966,  1643,   233,    88, 30154,    18,   121, 30031,  1214,\n","         29958,  1216, 30078, 30053,    18,  7636,  4407,  1214, 29992, 29958,\n","          5693,   151,    24, 29950,  1224,  5326, 29954,  3723, 29956, 12462,\n","         29951,  1034, 30340,   682,  4326, 29957,  1963, 29990, 22164, 29953,\n","          4722, 29956, 12870,  2051, 30024, 30077,  2307, 29952,  2187,  1086,\n","             5,  1185,   115, 11099, 30146,   298,   115, 11099, 30353,   509,\n","         29995, 30027, 13595, 29961, 24832, 29951,   347, 18874, 12141,  2292,\n","            36,   569, 29963,  3815,    39,  1063, 13804,  3513,    36,   569,\n","         29963,  3815,    39,  3723, 29956,  1034, 30077, 29948,     5, 12839,\n","          2117, 29951,  1034, 30078, 29950, 18874, 12141,  2292, 29961,   136,\n","          4221, 30027,    57,  2571,    57, 29966,  1643, 29965,   257,   604,\n","          5693,  6166,  9563,  5816, 29961,  4056, 29990,  3154, 29957,  8186,\n","         29947,    84, 30701, 29957,  4722, 29965,  1480, 29950,    45, 29947,\n","          1999, 29947, 29948,     5,   430,  1350,  5112, 24832, 29951,  1034,\n","         30078, 29950, 13804,  3513, 29950,  6703, 30027,    28,  2571,    57,\n","         29966,  1643, 29965,   257,   604,  5693,   151,    24,  2673,    18,\n","            48, 31631, 30656, 22140, 29950,  3723, 30111, 29947,  2307, 29947,\n","         29948,     5,   115, 17079, 30353,   509, 29995, 30027, 13595,    36,\n","           509, 29963,  3815,    39,    13,   350, 30444,   486, 30494, 18093,\n","         30054,  4834,  3723, 29958,  1216, 30077, 29948,     5,  7636, 29956,\n","          1305, 30027, 29951,   604,  5693,   350, 30444,   486, 30494, 18093,\n","         30054,  4834, 29950,  4381,   166, 16122, 29955,  1414, 29961, 18601,\n","         29952,  2187, 29959, 30053,    18,   454,  5897, 29952,   137, 30239,\n","          9563,  2090, 29973,   760, 30187, 29952,  8672, 29948,     5,   115,\n","         18373, 30146,   509, 29995, 30027, 13595,    36,   509, 29963,  3815,\n","            39,    13,   115,    57, 29966,  1643,   509, 29995, 30027, 13595,\n","         29951, 29967,  1034, 30077, 13804,  3513,  3723, 29956,  1713, 30077,\n","         29948,     5,   115, 25094, 30345, 30146,   509, 29995, 30027, 13595,\n","            36,   145, 29963,  3815,    39, 21223, 11168, 11713, 30054,  2292,\n","         10979,  6166, 29947,  1034, 30077, 29948,     5, 16418,  8738, 29962,\n","         29967,    84, 30701, 29957,  1414, 29961,  4056, 29952, 11167, 29959,\n","         29950, 11168, 11713, 30054,  2292, 10979, 29950,  4280, 30060, 29958,\n","           834, 30078, 29950, 11658, 11168, 11713, 30054, 29951, 29962,  8030,\n","         30201, 29948,     5,   115, 25288, 30146,  8074, 30333,  7504,  7594,\n","         29691, 30541, 30344,   509, 29995, 30027, 13595,    36,   150, 29963,\n","          3815,    39,    13, 29837, 29953,  4746, 29955,  2718, 29957,     8,\n","         30285, 30887, 30061,  1616, 29952,  5582, 30397,    12, 29950,   728,\n","         30217, 30203,  3513,  3723, 29958,  1216, 30077, 29948,     5,   454,\n","           728, 30217, 30203,  3513, 29950,   136,  6938, 30027,    23,  2571,\n","           150, 29966,  1643, 29951,   604,  9563,  1034, 30078, 30080, 30153,\n","           705,  7129, 23530, 29995, 29959, 29950,   893, 29965,   414, 29955,\n","            24, 29948,     5,     3, 11168, 11713, 30054, 29951, 29962,  1079,\n","          5200, 29952,   426, 29957, 13595, 29961,   420,     3,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]]), 'start_logits': tensor([[-1.5115,  0.2288, -4.9412, -5.9033, -4.1217, -3.2736, -7.5873, -7.1568,\n","         -6.6073, -1.3735, -2.3471, -7.4038, -7.1942, -8.4602, -6.7935, -7.2751,\n","         -6.8009,  4.4649,  5.0458,  1.2103,  3.6921, -3.5664, -3.1414, -0.7975,\n","         -2.6163, -4.0001,  1.8790, -4.4590, -7.7809, -7.1812, -7.9790, -6.4454,\n","          0.6724,  4.0979,  3.1321,  4.8998, -0.9844, -1.3978,  0.3366,  0.8822,\n","          3.9530,  3.5037, -1.1915, -2.2816, -0.7325, -2.3441, -3.8921,  2.1452,\n","          2.8504, -2.0891, -3.7333, -4.4564,  0.6263, -2.9716, -4.1664, -3.9551,\n","          0.3231, -3.0926, -4.3894, -3.9628,  1.3553, -2.1750, -3.4298, -3.3669,\n","         -2.6919, -6.7965, -6.4902, -1.4383, -6.9111, -3.3695, -5.6931, -3.3315,\n","         -6.7219, -7.4102, -7.0883,  0.2665, -1.7349, -4.3393, -6.4791, -6.7425,\n","         -4.1272, -4.5313, -6.6087, -7.3083, -0.6621, -6.1877, -6.5420, -4.2792,\n","         -7.6332, -3.9419, -8.2834, -6.2232, -8.6102, -2.7479, -7.4158, -8.9321,\n","         -6.8927, -8.9587, -5.9866, -9.1383, -7.6201, -9.2802, -7.4849, -6.3044,\n","         -9.0975, -9.5414, -7.4844, -9.4883, -7.5879, -8.0420, -7.3955, -0.9534,\n","          4.1339,  0.8251, -4.7544, -2.5840,  1.9203,  0.5142, -4.2515,  3.5921,\n","         -0.8443, -2.1656, -1.2453, -6.2336, -0.5992, -7.1798, -4.9680,  1.3560,\n","         -4.7714, -3.3420, -4.6364, -0.2193, -5.5799, -4.2126, -5.1714, -4.5204,\n","          0.6156, -3.4616, -5.3984, -1.1698, -6.1359, -4.1513, -4.5076, -4.2017,\n","         -7.7192, -5.5148, -7.6235, -7.7159, -6.6173,  1.6805, -4.3677, -6.7097,\n","         -4.7568, -6.8811, -6.2033,  4.1545, -3.8869, -1.9013, -5.3832,  3.8332,\n","          3.7594, -1.7742,  4.7920, -0.4735,  3.7381, -0.3451, -1.4203, -4.0281,\n","         -2.6856, -0.8432, -3.4324, -4.1634, -7.4850, -2.8132, -7.6212, -4.4986,\n","         -8.2819, -3.8997, -7.7534, -3.3220, -7.9719, -1.2640, -7.2714, -8.7865,\n","         -5.9770, -8.9320, -7.2765, -8.7768, -8.1151, -8.9605, -6.6794, -8.4464,\n","         -7.4332, -5.6933,  4.1786,  1.8233, -0.4738, -1.4498, -4.8632, -3.3516,\n","         -5.0554, -4.5817,  4.6663, -0.7579, -5.0888,  4.0344, -2.0153,  5.1098,\n","         -0.7935,  2.8179, -0.1526, -2.0168, -4.9035, -3.4655, -0.5893, -3.0483,\n","         -3.8360, -5.3589, -7.0189, -5.7038, -1.2621, -6.9586, -7.4159, -6.0592,\n","         -8.9406, -4.3946, -8.0263, -9.0073, -6.3870, -8.8204, -7.4646, -5.1506,\n","          6.5422,  4.5023, -1.7286,  5.9640,  1.6690, -0.2638, -0.0173,  0.0455,\n","          2.4449, -3.9672, -1.4378, -0.3145, -1.5266,  5.7068, -1.9199,  1.8072,\n","         -2.8781, -3.6541, -5.1201, -0.7398, -2.9613, -5.6375, -2.4100, -5.0798,\n","         -4.8921, -4.4313,  1.6278, -3.2383,  0.6102, -4.4585, -4.4754, -0.8423,\n","         -2.4326,  6.6816, -0.2326,  3.4859, -2.0413, -2.9374, -4.4545, -1.5795,\n","         -5.5526, -3.3014, -5.9876, -4.2264, -8.6567, -5.8296, -8.3949, -5.0087,\n","         -8.3212, -6.3269, -7.4195, -8.6178, -6.6659, -3.9659, -2.1873, -7.5037,\n","         -2.3542, -5.9777, -8.0001, -5.0160, -8.1633, -3.9356, -8.0424, -8.8813,\n","         -6.4973, -6.3908, -4.5652,  6.9727,  5.0143, -1.6154,  5.9593,  1.2218,\n","         -0.4630,  0.0235, -0.1868,  1.9666, -4.2144, -1.3799, -0.7888, -1.0953,\n","          6.7217,  4.6918,  1.2967, -1.4742,  5.7943,  1.6493, -0.4019,  0.0459,\n","         -3.7573, -2.0216, -1.5356, -3.8536,  4.7859,  0.7410, -1.2033, -5.3680,\n","         -2.2066, -4.2328, -4.0384, -2.7920,  7.4224,  5.6085, -1.4129, -1.5507,\n","          6.3976,  3.1679,  0.6910,  0.9480,  4.0876,  6.0587, -0.5223,  0.8476,\n","          0.0833, -0.7661,  4.7291, -2.8736, -2.5145,  2.3429,  1.4975, -1.7513,\n","         -5.6778, -3.4010, -5.2792, -4.4551, -3.1236,  2.5005, -6.6782, -6.3573,\n","         -6.3540,  4.3742, -5.4368, -6.7989, -0.6450, -6.2910, -1.3494, -6.6361,\n","         -3.6247, -7.0307, -5.9472,  4.8333, -2.6290, -2.5706,  2.4321, -0.0367,\n","         -5.1774,  1.4265, -4.5093, -7.0204, -4.9647, -6.4706, -5.4453,  4.4356,\n","          3.3346, -4.6173, -2.3753, -5.1163, -5.6100, -4.1952, -7.0435, -5.8335,\n","         -3.1898,  7.0044,  5.3359, -2.0001,  4.4866, -2.7071, -2.2415, -2.7594,\n","          4.7004,  0.0203, -1.8656,  4.7427, -0.3671, -0.4505, -0.0669,  0.5045,\n","          3.0937, -3.1254, -0.3118, -0.9855, -2.6830, -2.8274, -7.5049, -5.6870,\n","         -8.9330, -6.0859, -8.6615, -0.2336, -7.3642, -6.5391, -6.5555, -6.6934,\n","         -8.9038, -7.0191, -9.0970, -7.4595, -7.5445,  3.4024, -2.9024, -5.3994,\n","         -2.5392, -4.3165, -7.4683, -4.6877, -7.1036, -6.3479, -5.8623, -6.7495,\n","          2.0392, -4.6660, -5.5934, -5.2587, -8.3176,  0.3636,  0.4091, -6.0880,\n","          1.2179, -3.2900, -0.3059, -4.5160, -4.1429, -6.9412, -5.1870, -8.5382,\n","         -6.3619, -8.7665, -8.8848, -8.1667, -8.3606, -7.6652, -6.5119, -9.3143,\n","         -9.5343, -9.7197, -8.7970, -9.8278, -8.6597, -9.6011, -9.1416, -9.1808,\n","         -7.8329, -7.3796, -4.6422, -8.1518, -7.2562, -7.9972, -7.7875, -7.5800,\n","         -7.0312, -8.9521, -8.0384, -8.7110, -6.4047, -8.6534, -7.9533, -7.8347,\n","         -3.7006, -3.6890, -3.7721, -3.9014, -3.1493, -3.5434, -3.4201, -3.5497,\n","         -3.8646, -4.5967, -4.5387, -3.8711, -3.1963, -3.3167, -3.3150, -3.0680,\n","         -2.8465, -3.3488, -3.1402, -2.6315, -2.3204, -2.2653, -2.3607, -1.5134]]), 'end_logits': tensor([[-3.2423e+00, -4.6951e+00, -5.0028e+00, -7.4839e+00, -6.6844e+00,\n","         -7.4124e+00, -6.4938e+00, -4.7837e+00, -7.3725e+00, -5.4378e+00,\n","         -6.3997e+00, -7.4165e+00, -4.2863e+00, -7.9011e+00, -7.0949e+00,\n","         -8.9727e+00, -7.9611e+00, -3.5050e+00, -1.3421e+00, -1.3045e+00,\n","         -1.0648e+00, -4.0442e+00,  1.9581e+00,  3.1623e+00,  2.6475e+00,\n","         -4.4182e+00, -2.6321e+00, -4.4023e+00, -6.2697e+00, -8.9213e+00,\n","         -6.5481e+00, -3.7722e+00, -4.6262e+00, -1.8799e+00, -1.3959e+00,\n","         -8.5269e-01, -2.6028e+00,  2.2589e+00,  3.3355e+00, -3.0337e+00,\n","         -1.4848e+00, -2.3821e+00, -3.8971e+00,  1.1263e+00,  2.6773e+00,\n","          1.5750e+00, -5.0601e+00, -4.1265e+00, -2.8001e+00, -6.7318e+00,\n","          4.1300e-01, -6.1282e+00, -3.7494e+00, -7.2378e+00, -1.1754e+00,\n","         -6.0624e+00, -3.6737e+00, -7.3778e+00, -1.3177e+00, -5.3531e+00,\n","         -2.2770e+00, -6.9952e+00, -1.9989e-01, -7.3050e+00, -6.4283e+00,\n","         -5.4254e+00, -7.1734e+00, -5.1301e+00, -4.9461e+00, -2.9827e+00,\n","         -5.6210e+00, -4.3838e+00, -6.9456e+00, -6.1342e+00, -5.8141e+00,\n","         -4.3320e+00, -4.1665e+00, -2.5019e+00, -5.5350e+00, -6.5336e+00,\n","         -5.7385e+00, -6.2883e+00, -8.4564e+00, -8.0738e+00, -5.7293e+00,\n","         -3.9493e+00, -3.9944e+00, -2.6963e+00, -7.5360e+00, -5.9447e+00,\n","         -8.7165e+00, -6.6361e+00, -8.4065e+00, -6.7277e+00, -5.7458e+00,\n","         -8.0266e+00, -6.8522e+00, -9.0313e+00, -7.9668e+00, -9.5088e+00,\n","         -8.3049e+00, -9.7431e+00, -9.0995e+00, -9.5774e+00, -9.0198e+00,\n","         -9.4165e+00, -8.7580e+00, -9.5726e+00, -9.0576e+00, -9.2440e+00,\n","         -5.7649e+00, -4.8851e+00, -2.8180e+00, -2.1145e+00, -3.0947e-01,\n","         -4.2595e+00, -4.4175e+00, -4.0401e+00, -1.4396e+00,  1.0553e-01,\n","         -2.4839e+00,  2.3246e+00,  2.6257e+00, -4.0438e+00, -3.6096e+00,\n","         -6.2330e+00, -7.0369e+00, -4.2198e+00, -4.2370e+00, -1.9082e+00,\n","         -7.2218e+00, -4.4031e+00, -3.8064e+00, -3.2702e+00, -2.7359e+00,\n","         -6.8888e+00, -3.5961e+00, -3.2466e+00, -7.4760e+00, -5.0096e+00,\n","         -4.6592e+00, -3.4315e+00, -3.4851e+00, -4.3641e+00, -7.2268e+00,\n","         -6.6752e+00, -8.2854e+00, -6.8554e+00, -4.8639e+00, -2.3695e+00,\n","         -2.2901e+00, -6.0772e+00, -5.6416e+00, -8.0223e+00, -7.9250e+00,\n","         -1.7737e+00, -1.6512e+00,  1.6476e+00, -4.0208e+00, -2.7858e+00,\n","         -2.1853e+00, -1.4797e+00, -1.3859e+00, -1.6027e+00,  8.4475e-01,\n","         -3.8529e+00,  3.5930e+00, -2.6952e+00, -2.1444e+00, -3.9415e+00,\n","         -4.3819e+00, -5.0217e+00, -7.1657e+00, -7.0825e+00, -9.0791e+00,\n","         -5.7648e+00, -8.8653e+00, -7.8135e+00, -8.7715e+00, -4.2922e+00,\n","         -8.6140e+00, -6.2506e+00, -6.0270e+00, -8.3673e+00, -7.4520e+00,\n","         -9.3568e+00, -8.8744e+00, -9.4509e+00, -8.9562e+00, -9.4439e+00,\n","         -8.4290e+00, -9.1162e+00, -7.4662e+00, -3.8593e+00, -1.4380e+00,\n","         -1.3720e+00,  9.6347e-02,  1.7968e+00, -3.6525e+00, -3.6597e+00,\n","         -6.5253e+00, -6.3864e+00, -4.2767e-01,  1.4055e+00, -3.3590e+00,\n","         -2.1692e+00, -1.6295e+00, -1.3001e+00, -1.3275e+00,  1.6273e+00,\n","         -3.6603e+00,  3.6049e+00, -2.4977e+00, -2.2638e+00, -3.3187e+00,\n","         -4.2009e+00, -4.8044e+00, -7.2869e+00, -5.7340e+00, -5.1386e+00,\n","         -6.8822e+00, -6.6566e+00, -5.3812e+00, -7.8771e+00, -9.3141e+00,\n","         -5.9937e+00, -7.4595e+00, -9.3787e+00, -7.6960e+00, -9.3563e+00,\n","         -7.9913e+00, -3.3799e+00, -9.3060e-01, -6.3742e-01,  2.4954e+00,\n","          1.3235e+00,  8.2687e-01,  4.2276e+00,  5.3864e+00, -1.8860e+00,\n","         -2.2990e+00, -2.2114e+00,  5.9194e-01,  3.5972e+00, -2.1209e+00,\n","         -8.1044e-01, -8.7428e-01, -3.8878e+00, -3.9821e+00, -1.9769e+00,\n","         -1.3266e-01, -3.6457e-01, -1.4229e+00, -3.9197e+00, -2.7674e+00,\n","         -5.5800e+00, -4.0512e+00, -2.0146e+00, -2.0163e+00, -5.0728e+00,\n","         -3.8375e+00, -1.5733e+00, -4.3016e+00, -4.2735e+00, -4.1609e+00,\n","         -4.1090e-02,  1.6050e-04, -2.8691e+00, -2.5589e+00, -1.0285e+00,\n","          1.1418e+00,  1.5964e+00, -3.0039e+00, -7.1660e+00, -8.7065e+00,\n","         -6.9772e+00, -8.9375e+00, -8.0241e+00, -8.4541e+00, -5.0795e+00,\n","         -7.2128e+00, -7.4900e+00, -8.7343e+00, -7.4269e+00, -5.4229e+00,\n","         -7.0421e+00, -4.4198e+00, -8.5803e+00, -6.6861e+00, -4.5456e+00,\n","         -7.8132e+00, -5.5934e+00, -8.2132e+00, -7.4024e+00, -6.8790e+00,\n","         -8.6277e+00, -8.0193e+00, -5.6492e+00, -1.9659e+00, -5.2938e-01,\n","          6.7594e-01,  3.3665e+00,  1.0456e+00, -1.5748e+00,  3.7523e+00,\n","          5.1974e+00, -2.4407e+00, -2.5897e+00, -2.0312e+00,  4.5564e-01,\n","          3.4200e+00, -2.6428e+00, -1.1865e+00,  7.0778e-01, -4.1926e+00,\n","          3.6558e+00,  6.7083e-01, -1.1335e+00,  3.9819e+00,  5.0252e+00,\n","         -1.9317e+00, -1.5326e+00, -2.3421e+00, -3.8342e+00,  2.0693e-01,\n","          9.5577e-01,  1.1814e+00, -2.9428e+00, -4.2502e+00, -5.6966e+00,\n","         -3.3978e+00, -1.1063e+00, -3.8531e-01,  1.5234e+00,  6.4960e-01,\n","          4.5226e+00,  2.6917e+00,  4.4017e-01,  4.7139e+00,  5.8063e+00,\n","         -2.7793e-01,  1.8739e+00,  2.1174e+00,  4.1378e+00,  4.8043e+00,\n","         -1.3796e+00, -1.7351e+00, -3.5600e+00,  1.7177e-01, -9.9818e-01,\n","          2.0990e+00, -3.9667e-01, -4.0361e+00, -3.5743e+00, -6.2060e+00,\n","         -3.5322e+00, -1.1820e+00, -2.6788e+00, -7.7926e+00, -7.1484e+00,\n","         -4.4957e+00, -2.1320e+00, -3.3143e+00, -6.4125e+00, -5.4328e+00,\n","         -6.6211e+00, -1.9575e+00, -5.7014e+00, -4.4477e+00, -8.9929e+00,\n","         -6.7984e+00, -2.0669e+00, -3.9111e+00,  4.6034e-02, -1.3338e+00,\n","          2.9985e+00, -4.1761e+00, -2.4121e+00, -9.0478e-01, -5.2910e+00,\n","         -5.9506e+00, -7.9708e+00, -7.1848e+00, -3.0343e-01, -2.0956e+00,\n","         -2.1061e+00,  3.7461e+00, -3.7542e+00, -5.2122e+00, -4.4515e+00,\n","         -6.7368e+00, -5.5444e+00, -1.2436e+00, -9.4062e-01,  8.6630e-01,\n","          9.0296e-01, -7.5341e-01, -3.1202e+00, -3.8535e+00,  1.3043e+00,\n","         -1.8138e+00, -2.5759e+00,  2.4998e+00,  1.6832e+00,  2.4612e-01,\n","          4.1416e+00,  5.6845e+00, -6.6876e-01, -6.8702e-01, -1.4948e+00,\n","          8.7315e-01,  3.7271e+00, -2.7256e+00, -5.1805e+00, -7.3978e+00,\n","         -8.9262e+00, -9.1362e+00, -7.6815e+00, -8.5012e+00, -5.9618e+00,\n","         -6.6036e+00, -4.6988e+00, -2.4716e+00, -5.8312e+00, -8.3287e+00,\n","         -8.3517e+00, -9.3719e+00, -1.0071e+01, -9.2922e+00, -2.7167e+00,\n","         -5.2078e+00, -1.7055e+00, -8.4198e-01, -2.9121e+00, -6.0916e+00,\n","         -5.6117e+00, -7.7979e+00, -5.9383e+00, -2.8158e+00, -9.2472e+00,\n","         -3.8348e+00, -7.0880e+00, -3.5588e+00, -2.8566e+00, -7.1592e+00,\n","         -5.7029e+00, -4.7214e+00, -4.3714e+00, -4.8873e+00, -4.6443e+00,\n","         -3.0501e+00, -7.2284e+00,  4.9603e-01, -5.3516e+00, -7.8043e+00,\n","         -7.6540e+00, -6.9460e+00, -8.6429e+00, -8.7107e+00, -8.4182e+00,\n","         -9.1594e+00, -9.6888e+00, -9.4451e+00, -7.9139e+00, -1.0245e+01,\n","         -1.0276e+01, -9.4497e+00, -1.0228e+01, -1.0270e+01, -1.0414e+01,\n","         -1.0596e+01, -9.6533e+00, -6.3440e+00, -6.7843e+00, -8.4015e+00,\n","         -8.5950e+00, -5.8642e+00, -8.9995e+00, -9.2516e+00, -9.5176e+00,\n","         -8.7364e+00, -9.7835e+00, -9.7883e+00, -1.0140e+01, -7.9144e+00,\n","         -9.4686e+00, -9.6517e+00, -9.0073e+00, -5.8748e+00, -5.7806e+00,\n","         -5.8701e+00, -6.1429e+00, -5.5208e+00, -5.7257e+00, -5.5942e+00,\n","         -5.7493e+00, -5.9655e+00, -6.6383e+00, -6.5544e+00, -5.8193e+00,\n","         -5.3057e+00, -5.2926e+00, -5.3609e+00, -5.2283e+00, -5.1112e+00,\n","         -5.4668e+00, -5.3666e+00, -4.8580e+00, -4.6027e+00, -4.6143e+00,\n","         -4.7977e+00, -3.2444e+00]]), 'tokenizer_name': 'monologg/koelectra-small-v2-distilled-korquad-384', 'guid': 'd14cb73158624cf094c546d856fd3c80'}, {'input_ids': tensor([[    2,  1160,  3378, 21906, 29951,  3757,  2748, 30044, 29953,  5692,\n","         29965,  1473,   174, 30455, 31005, 29980, 11578, 29950, 25806, 30154,\n","         29964, 29956,  3002, 30006,  9563,  4584, 29966, 30588,    45,  9563,\n","         13119,  1160,   737, 29947,   702, 29982,   524, 29987, 29948,     5,\n","         10961,   340,    55, 29951,   541, 30013,   642, 29952,   400,    62,\n","         29972,  1160,   737, 29953,  3387, 29980,    33, 30851,  1066, 29950,\n","         17196,   214, 30016, 30339, 29952,   208, 29986,   105,  5636, 30069,\n","          3816, 30629, 30148, 29984, 30055, 29965,   645, 29957,   449,  9541,\n","         29956,  5636, 30069,   654,  9563,  5882,   521, 25806, 30154, 29964,\n","         29956,  3002, 30006,  9563, 11578, 29965,  3636, 29959, 30103,    14,\n","            45,   195, 29948,   106,    15,   253, 29948,     5,    33, 30851,\n","          1066, 29950,   105, 25806, 30154, 29964, 29956,  3002, 30006,  9563,\n","         11578, 19553, 30246, 30731, 29952, 16806, 29955,    18, 11578, 29953,\n","         19553, 30147, 29967, 29956, 27941, 29948,   106,    94,   105,   736,\n","          3113,  5636, 30197,  1095,    24, 30153,  9541, 29956,   128, 29952,\n","           766,   926, 16607, 29955,  1499, 29965, 19400,   440,    18, 25806,\n","         30154, 29964, 29950,   128, 29952,   208, 29954,   109, 30190, 29948,\n","           106,    15,   515, 29987, 29948,     5,    46, 29950,   105,  1140,\n","          1943, 30108, 29954, 25806, 30154, 29964, 29953,  2869, 29961,   833,\n","         29947, 30080,  2673,  5636, 30069, 29951, 29962, 29950,  6653, 29947,\n","         13380, 29948,   106,    15,  1363, 29948,     5, 25806, 30154, 29964,\n","         29950,   713, 30042, 29972,  1062,  6073, 29953, 16813, 24596, 21447,\n","         30432, 29958,    18,    23, 30027, 30052, 30031, 30086,    43,  5636,\n","         30067, 29952,   575, 29960,   392, 29987,  2673,  2396,  6973,  3112,\n","         29961, 23105,  6973, 29972,    45,  9563,  1833, 30201, 29948,     5,\n","            33, 30851,  1066, 29950,   105, 25806, 30154, 29964, 29953,  2348,\n","          5044, 30004, 29961,   645, 30078, 29954,   109, 30190, 29948,   106,\n","            94,   105,  2348,   911, 29947, 29991, 29955,  2768, 30049, 11769,\n","           621, 29950,   116, 29948,   106,    15,   103, 29987, 29948,     5,\n","           174, 30455, 31005, 29980, 11578, 29950,   136,   618, 29982,  2434,\n","          6396, 29951, 29962,  1062,   286, 30704, 29036, 29958,  6635, 30153,\n","            62,  1140, 21979, 29947,   929, 29954, 29955,  1390,   343,   150,\n","         30071, 30067,    57, 29998, 26432, 29970, 30185, 30054,    36,   343,\n","             1,    39,    17,   422, 30097, 29959, 29973, 21906,   256, 29952,\n","         16696, 30190, 29948,     5,    33, 30851,  1066, 29950,   105, 11578,\n","         29956,  4584, 30049,   117,  1160,  8234, 30679, 29947,    96,  1603,\n","           952,    95,   232, 28824, 18103, 29965,   147, 29954,   930, 29948,\n","           106,    15,   103, 29987, 29948,     5,     6,   736, 29958,  4404,\n","         14004, 30044, 29990,  8150,   121, 30044,    55, 23589,  2748, 30044,\n","         29947,   432,  1403, 29987, 29948,     5,     3,   736,  4398, 29953,\n","         15261, 29950,   420,     3,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]]), 'start_logits': tensor([[-2.9897,  5.7409,  4.3064,  5.4782, -1.9085, -4.3124, -4.3779, -8.0854,\n","         -8.4453, -5.7912, -9.0314, -7.7450, -3.3620, -5.3412, -7.0955, -8.1686,\n","         -6.3796, -8.6714, -3.4366, -8.3015, -8.0428, -8.7235, -5.3001, -9.1865,\n","         -9.0817, -5.4046, -8.5772, -9.0455, -8.3719, -9.4289, -8.5588, -0.9132,\n","         -7.1550, -9.2551, -5.8762, -8.7684, -7.8331, -9.0598, -9.1864, -8.6101,\n","         -6.3471, -8.9364, -9.0266, -9.6577, -8.6336, -9.5900, -6.3530, -9.3112,\n","         -7.5326, -8.6966, -9.2490, -2.3394, -6.3965, -8.3788, -2.9491, -7.8122,\n","         -5.4393, -7.6948, -8.1924, -9.7003, -7.7313, -5.5817, -8.7375, -9.4437,\n","         -9.7111, -8.9371, -9.4040, -6.9125, -5.1399, -8.0512, -7.5496, -8.7129,\n","         -9.1970, -9.2792, -9.4184, -9.7327, -9.1433, -9.6876, -9.2272, -5.8644,\n","         -9.2144, -5.1018, -6.7076, -7.0382, -8.9498, -8.1099, -8.5273, -5.2291,\n","         -8.9793, -8.6743, -9.3885, -7.0823, -9.7087, -9.6409, -6.5676, -9.3788,\n","         -7.8282, -9.3188, -9.6610, -8.8540, -9.1664, -9.0043, -9.6598, -8.7861,\n","         -9.5290, -8.7565, -9.6263, -9.3638, -4.4402, -7.7588, -8.3393, -9.7014,\n","         -5.9949, -3.5685, -8.2484, -8.0430, -8.9338, -5.5373, -9.2457, -9.2530,\n","         -3.2605, -4.3014, -7.0645, -7.3573, -9.2726, -7.6333, -9.2904, -8.3429,\n","         -4.8310, -8.1560, -4.4561, -8.3465, -9.1775, -9.3187, -7.8311, -9.3550,\n","         -8.0017, -8.8983, -7.1993, -5.1379, -7.2614, -3.3217, -5.7012, -7.6436,\n","         -8.1327, -8.1555, -5.7055, -9.1965, -5.7269, -9.4601, -7.5210, -9.1640,\n","         -7.6000, -9.9066, -7.7506, -9.9115, -8.1607, -9.5709, -9.4277, -4.9234,\n","         -8.9864, -8.4913, -9.4471, -6.1533, -9.6205, -8.5773, -9.2092, -8.8147,\n","         -9.6895, -9.6973, -8.6755, -9.4872, -8.6964, -9.4995, -9.7437, -9.5307,\n","         -8.3701, -9.5594, -6.4837, -5.6100, -7.8991, -8.1464, -8.3618, -4.2974,\n","         -8.3994, -8.0067, -8.4830, -5.3834, -9.0810, -7.4344, -9.3313, -9.3329,\n","         -9.5020, -4.4798, -7.0870, -8.3437, -8.8118, -8.6175, -6.8104, -9.5821,\n","         -8.3949, -9.4494, -8.6104, -9.3687, -8.6958, -9.5476, -8.9180, -4.7515,\n","         -8.5404, -8.5496, -8.3833, -0.8833, -5.0156, -4.8478,  2.0566, -1.2406,\n","         -4.2486,  1.8291, -2.6338, -0.6463, -3.3699, -6.2467, -5.8297, -5.4276,\n","         -7.4090, -7.3936, -8.0977, -8.0466, -7.4431, -5.3484, -8.6393, -9.2870,\n","         -7.4462, -8.1192, -8.1944, -8.6266, -9.1031, -5.4513, -7.6984, -7.0555,\n","         -9.0325, -6.1306, -8.3165, -9.1439, -8.8634, -9.5282, -8.3313, -9.3787,\n","         -9.2727, -8.8161, -3.5045, -7.4626, -8.3625, -9.8205, -6.1642, -5.3708,\n","         -8.6480, -8.7487, -9.1334, -6.4737, -8.6050, -9.6118, -9.8142, -8.4358,\n","         -9.9558, -9.5074, -9.1239, -9.7760, -9.8641, -8.9076, -9.1565, -3.8853,\n","         -4.7754, -7.8343, -9.6081, -9.3982, -9.8395, -8.4134, -9.6140, -8.3302,\n","         -8.6911, -9.8217, -9.1101, -9.9120, -8.9025, -9.5217, -9.0398, -9.4101,\n","         -9.4138, -7.5487,  1.7500, -2.7173, -5.3401, -5.5169, -2.8765, -6.4096,\n","         -0.6487, -1.4030, -3.4121,  8.4746,  7.8178, -2.5465, -2.6323,  8.2426,\n","          7.8890,  1.7155,  3.4081, -2.8131, -2.1793, -3.6585, -4.2368,  0.0374,\n","         -2.5953, -7.9152, -5.7138, -7.3054, -6.9419, -4.7646, -1.2504, -3.5577,\n","         -5.2440, -6.0072,  1.7605, -3.7598, -4.8530, -5.1341, -4.7828, -1.1016,\n","         -1.4641,  4.9381,  6.3680,  0.2542, -3.1852,  0.5492, -5.1378, -6.0453,\n","         -6.2901,  6.9371,  2.8747, -5.3797, -3.8728, -7.9317, -6.9482, -5.0635,\n","         -1.0659, -5.9637, -6.9657, -9.1726, -1.7507, -3.4540, -7.3813, -3.3841,\n","         -8.1254, -8.1037,  1.2512, -4.4753, -5.3870, -7.4178,  1.0802,  0.8126,\n","         -6.8930, -6.7904, -7.7267, -5.1436, -8.6560, -9.5551, -8.4832, -8.7242,\n","         -8.4101, -9.1842, -7.1197, -8.6725, -7.6533, -8.7113, -9.1320, -8.6443,\n","         -7.6613, -7.3081, -8.9470, -6.6167, -6.3949, -9.2639, -9.4981, -6.9754,\n","         -7.3253, -9.5119, -8.6466, -6.7746, -6.5199, -9.3022, -9.3585, -7.6920,\n","         -6.8842, -9.2242, -9.2488, -8.1166, -8.2528, -8.1502, -8.0657, -8.9387,\n","         -7.8552, -8.7535, -8.4241, -8.6141, -3.8637, -3.8321, -3.7841, -4.2406,\n","         -3.4237, -3.5058, -3.4843, -3.6557, -3.7437, -3.6770, -3.5468, -3.5939,\n","         -3.7377, -3.5150, -3.5807, -3.5540, -3.7132, -3.7203, -3.7128, -3.7370,\n","         -3.7552, -3.5927, -3.5999, -3.9665, -3.9463, -3.8656, -3.8700, -3.8571,\n","         -3.7853, -4.1959, -3.7896, -3.8128, -3.9052, -3.7767, -3.5304, -3.3618,\n","         -3.1824, -3.0669, -2.8344, -2.7990, -2.8700, -2.8033, -2.9277, -2.9434,\n","         -3.3873, -3.2203, -2.9790, -3.0109, -3.0802, -3.1022, -3.3411, -3.3586,\n","         -3.1499, -3.1771, -3.3152, -3.2890, -3.3468, -3.4666, -3.5288, -3.5798,\n","         -3.5664, -3.5824, -3.5214, -3.5466, -3.5006, -3.4751, -3.5279, -3.3860,\n","         -3.2621, -3.3392, -3.3384, -3.2908, -3.2495, -3.2724, -3.3650, -3.4983,\n","         -3.5442, -3.4483, -3.4504, -3.4915, -3.7391, -4.0065, -4.1737, -4.2100,\n","         -4.1964, -4.1780, -4.1017, -4.2846, -4.3998, -4.2430, -4.1855, -4.1262,\n","         -4.1836, -4.1730, -3.9836, -4.0143, -3.9926, -3.9939, -3.9919, -4.0139,\n","         -4.0716, -4.2393, -4.1710, -3.9188, -3.9683, -4.0072, -4.2048, -2.9895]]), 'end_logits': tensor([[ -4.4457,   1.7435,   2.3153,   4.0857,  -0.9578,  -5.4868,  -7.4409,\n","          -7.8512,  -8.7738,  -7.6466,  -9.0709,  -8.8251,  -7.5346,  -7.6066,\n","          -7.2552,  -5.5548,  -6.5022,  -8.0127,  -7.9045,  -8.2387,  -6.3010,\n","          -8.9230,  -8.5079,  -9.0389,  -9.0451,  -6.8873,  -9.8158,  -9.4967,\n","          -9.4482,  -9.5781,  -9.3635,  -3.9836,  -8.2020,  -9.5946,  -8.2698,\n","          -6.8795,  -9.4707, -10.0196,  -8.9433,  -7.5537,  -8.8069,  -8.8532,\n","          -9.4350,  -9.8182, -10.1771,  -9.5813,  -8.0805,  -9.6908,  -9.0685,\n","          -9.7638,  -9.2860,  -4.8920,  -7.5080,  -8.8997,  -7.0635,  -7.0076,\n","          -7.6533,  -6.0284,  -8.1820,  -9.0129,  -8.9153,  -8.8126,  -9.7971,\n","          -7.9140,  -9.3806,  -9.7472,  -9.8941,  -9.0010,  -8.5488,  -8.7527,\n","          -9.4215,  -9.9614,  -9.3309,  -9.3987,  -8.3128,  -9.7239,  -9.7340,\n","         -10.2092,  -9.8586,  -7.5836,  -9.5928,  -8.1412,  -6.0067,  -8.1813,\n","          -8.3338,  -7.9831,  -8.7986,  -8.8301,  -8.9690,  -7.5759,  -9.6716,\n","          -9.5295,  -9.4245,  -9.9324,  -8.1943,  -9.9447,  -9.1724, -10.0896,\n","          -9.4798,  -9.9285,  -9.8921, -10.3068,  -9.5911,  -8.8701,  -9.7184,\n","          -9.8777,  -9.6357,  -8.4790,  -8.1928,  -7.8744,  -8.3681,  -9.5125,\n","          -8.4877,  -8.0069,  -8.8894,  -6.1754,  -8.8748,  -8.8018,  -9.3654,\n","          -9.6041,  -5.9260,  -7.6895,  -9.6888,  -5.7249,  -9.0967,  -9.0893,\n","          -8.7675,  -8.0675,  -6.5679,  -9.4649,  -7.6371,  -9.4906,  -8.3303,\n","         -10.0037,  -9.4795,  -8.8247,  -7.8550,  -9.2064,  -8.5659,  -8.1625,\n","          -8.6048,  -7.3847,  -4.9812,  -8.5314,  -8.5226,  -8.8718,  -7.4688,\n","          -9.4408,  -7.7057,  -9.6310,  -9.6396,  -8.9608,  -9.0813,  -9.4309,\n","          -9.2418,  -9.8217,  -9.0217,  -8.9079,  -9.1016,  -8.5745,  -9.1053,\n","          -7.4646,  -9.5964,  -7.8887,  -9.7150,  -9.2139, -10.0266, -10.2549,\n","          -9.8011,  -9.1686,  -8.4692,  -9.6722,  -9.9191, -10.2116,  -9.6025,\n","          -8.4885, -10.0455, -10.1094,  -9.1091,  -8.5929,  -8.9388, -10.4231,\n","          -8.7453,  -8.5273,  -8.7770,  -6.9852,  -9.9566,  -7.5848,  -9.8768,\n","          -8.7658,  -9.5832,  -9.1306,  -8.8520,  -7.9049,  -6.1869,  -9.4066,\n","          -9.2992,  -9.3601,  -8.4975,  -9.8704,  -9.5968,  -9.1381,  -8.6657,\n","          -9.8725, -10.3556,  -9.6192,  -7.8175,  -8.8409,  -8.7931,  -7.8305,\n","          -9.4492,  -5.6020,  -3.4715,  -4.2640,  -0.7914,  -2.1949,  -4.9715,\n","          -3.2866,  -2.5126,  -3.6081,   1.0161,  -2.5547,  -3.4896,  -8.9429,\n","          -8.9088,  -8.9385,  -9.4052,  -8.3391,  -7.7524,  -8.0087,  -8.3112,\n","          -9.6855,  -9.4617,  -9.3608,  -9.3130,  -9.5084,  -8.4805,  -7.6333,\n","          -8.9064,  -8.3781,  -9.9171,  -8.5010,  -7.2597,  -8.4515,  -9.2083,\n","          -9.1883,  -9.6429,  -9.9651,  -9.4201,  -7.6007,  -7.4133,  -6.5818,\n","          -8.2781,  -9.4418,  -8.9125,  -8.8466,  -9.1773,  -7.9424,  -9.9374,\n","          -8.6615,  -9.7930,  -9.0520,  -9.9107,  -9.6708,  -9.7944, -10.4758,\n","         -10.5279, -10.1271,  -9.4437,  -8.8818,  -9.3473,  -7.5632,  -7.7279,\n","          -7.8670,  -9.8600,  -9.4544,  -9.0447,  -9.6520, -10.1727,  -9.2874,\n","          -8.9637,  -9.9234, -10.1104,  -9.6320,  -8.6103,  -9.6423,  -9.9313,\n","         -10.2683,  -9.2089,  -6.3581,  -4.6525,  -5.7420,  -5.2276,  -1.4578,\n","          -3.8953,  -6.2604,  -5.4967,  -5.2575,  -2.4253,   4.5521,   6.9805,\n","           0.5114,   0.8165,   3.6471,   1.0292,  -0.7107,   6.4073,   2.2205,\n","          -2.1933,  -2.9222,  -3.7125,  -4.6403,  -4.8406,  -8.4229,  -9.0586,\n","          -8.8015,  -7.7025,  -6.0666,  -7.3282,  -7.5987,  -6.9697,  -7.2150,\n","          -5.2239,  -7.1815,  -6.9380,  -4.0653,  -6.4489,   1.8299,  -5.8260,\n","          -2.3494,   4.3343,   2.8270,  -3.4864,  -4.1517,  -3.9541,  -3.2259,\n","          -4.7214,   1.9119,   4.8980,  -3.0741,  -5.9468,  -7.9710,  -6.5879,\n","          -4.0674,  -5.7242,  -3.0793,  -6.4881,  -8.2753,  -5.9530,  -5.4411,\n","          -7.9267,  -5.1651,  -9.0994,  -8.6758,  -2.2399,  -7.4162,  -2.9705,\n","          -7.7064,  -5.1158,  -4.1552,  -4.1842,  -2.9352,  -8.0675,  -7.6792,\n","          -8.1809,  -9.4130,  -9.5743,  -9.9910,  -9.7775,  -8.2089,  -6.2199,\n","          -8.7725,  -8.9821,  -9.6968,  -8.4996,  -6.7389,  -9.1765,  -8.3066,\n","          -9.1116,  -8.3445,  -8.7932,  -8.7239,  -9.3862,  -8.0300,  -9.0993,\n","          -8.5719,  -9.6127,  -8.6189,  -8.7517,  -8.8566, -10.1444,  -9.2931,\n","          -8.0269,  -9.5336,  -8.6269,  -6.8945,  -8.0830, -10.0612,  -9.8783,\n","         -10.1719,  -9.8760,  -9.9714,  -9.8642,  -9.6312,  -5.4349,  -5.3401,\n","          -5.2874,  -5.9047,  -4.8653,  -4.9428,  -4.8731,  -5.1116,  -5.2380,\n","          -5.1822,  -5.0455,  -5.0761,  -5.2889,  -4.9562,  -5.0197,  -4.9670,\n","          -5.1844,  -5.2050,  -5.1833,  -5.1808,  -5.2483,  -5.0218,  -5.0142,\n","          -5.5462,  -5.5291,  -5.4190,  -5.4383,  -5.4089,  -5.2969,  -5.8374,\n","          -5.3810,  -5.4160,  -5.5168,  -5.3504,  -4.9796,  -4.7191,  -4.4618,\n","          -4.2809,  -4.0273,  -3.9915,  -4.0364,  -3.9573,  -4.0996,  -4.1270,\n","          -4.6553,  -4.3721,  -4.1640,  -4.1356,  -4.2314,  -4.2911,  -4.5882,\n","          -4.6038,  -4.3180,  -4.3333,  -4.5688,  -4.4756,  -4.5767,  -4.7787,\n","          -4.8676,  -4.9442,  -4.8803,  -4.8878,  -4.8519,  -4.8840,  -4.8071,\n","          -4.7769,  -4.8445,  -4.6308,  -4.4459,  -4.5219,  -4.6070,  -4.5404,\n","          -4.4870,  -4.5257,  -4.6504,  -4.8033,  -4.8583,  -4.7018,  -4.7697,\n","          -4.7685,  -5.1056,  -5.5063,  -5.7477,  -5.7888,  -5.7423,  -5.7287,\n","          -5.6541,  -5.8920,  -6.0750,  -5.8631,  -5.7909,  -5.6965,  -5.7292,\n","          -5.7146,  -5.4833,  -5.5631,  -5.5769,  -5.5554,  -5.5733,  -5.6026,\n","          -5.6637,  -5.9056,  -5.8417,  -5.5010,  -5.5709,  -5.5854,  -5.8591,\n","          -4.4450]]), 'tokenizer_name': 'monologg/koelectra-small-v2-distilled-korquad-384', 'guid': '906631384e91493ebe1c7f34aea6f241'}, {'input_ids': tensor([[    2,   390,    32, 29959, 29955,   617, 29961,   528, 29958,   247,\n","          4374,   795, 29972,   503, 29972,  1000, 15757, 29956,   828, 30201,\n","         29948,     5,  2939, 30033, 12438, 30054, 29972,    18,  3386,    55,\n","           527,  2849,    36,  1853,    39,   261, 29951,   180, 11749,   284,\n","         30007,  1181, 29948,     5,   247,   349, 10007, 29954, 20236, 29950,\n","           105,  2061,  2028, 29972, 29369,  7810, 29956,   247, 29951, 29962,\n","            32, 29959, 29950,   569, 29998, 30044, 29953,  4796, 29952,   458,\n","          9563,  4320, 11601, 29965,  5783,    96,  1202, 30027,    32, 29959,\n","         29955,   617, 29961,   569, 29963,   528,    95,    17,   828, 29987,\n","         29948,   106,    15,   313, 29982,    36,   919,  6973,    39,   908,\n","         29987, 29948,     5,   503, 29972,  1000, 15757, 29950,  1166, 30027,\n","         29951,   487,   215,   224, 30424, 29958,    23, 30008, 29951,  1385,\n","         29948,     5,    12, 29950,    32, 29947,  1975, 29981, 29955,    32,\n","         29947,  4196, 29947,    24,  2673,    18,   295,    32, 29959, 29950,\n","           258,  3782, 12152, 12078,   613,  8820,    37,    24,  1312,    45,\n","            55, 29947,   951,  3782,   503, 29972,  1000, 15757, 29951,  1985,\n","         29959, 29950,  9402,   621, 30222, 29948,     5,    78, 30598, 29964,\n","            54, 30188, 29369,  7810,  1899, 29961,   105,   503, 29972,  1000,\n","         15757,   951, 29992, 29961,   453,   717,    45, 29952,  8820,    37,\n","            24, 29955,  1679, 30006, 29972,    32, 29947,   204, 29989,   989,\n","         29967,  9798, 29957,   192, 29947,   116,  2499,   499, 29987, 29948,\n","           106,    94,   105,   547,  1123, 29961,   528, 29965, 24543,   157,\n","         29951, 29967,   731,  3112, 29951,  1096, 29947,   179,   106,    15,\n","           103, 29987, 29948,     5,  2939, 29956,    28, 30008, 29965,   978,\n","         29987, 29948,     5,  2939,   951, 29992, 29961,  3813, 29959, 29955,\n","           666, 29957,    32, 29952,  2387,    12, 13956,    43,   345,    37,\n","         30266, 29998, 30044, 29953,  2955, 29992, 29990,  2072, 30049,    37,\n","            24,  1312,   217, 29952,   528, 29951,  2143, 29955,   617, 29961,\n","           621, 29958,  1545, 30190, 29948,     5,  2939, 29951,   487, 12438,\n","         30054, 29972, 29990,  3386, 29947,   857,    57, 30008,    18,    85,\n","         30008, 29965,   978, 29959, 29950,    55,  1853,   261, 29953,  3712,\n","         29967,   461, 29951,  3024, 30080, 29948,     5, 29369,  7810, 29950,\n","           105,  4183,   569,   563,   635, 30031, 29956,  1853,   261,   106,\n","           336, 30053,   105,  1417,   166, 26639,  2793, 29965,  3135, 29959,\n","         29955,    18,   864, 29953,  2793, 29965, 11152, 24639,   109, 29960,\n","           205,   662, 29959, 29950,    45, 29947,   166,  2307, 30006, 29972,\n","           261,  3208, 29952,   429, 29960,   396,   847,  9563,  2193, 29955,\n","            24, 29948,   106,    15,   515, 29987, 29948,     5,  1552, 30027,\n","           628,    32, 29959, 29955,   617, 29961,   528, 29965,   828, 29973,\n","           524, 29959, 29955,    24, 29950, 29369,  7810, 29950,  1166, 30027,\n","           313, 30086,   628,   136, 30124, 30108, 29954,   528, 29951,   180,\n","          5934,    18,  1773,  9912,  1113,  1929,    18, 18329,  1440,   521,\n","         29953,  2544,    18,  4930, 29951,   180,   499,    55,   462, 30031,\n","         29953,  1483,  9563,   723, 30077,  4320, 11601, 29965,   716, 29987,\n","         29948,     5, 29369,  7810, 29950,   105, 11507,  3782,  1099,   528,\n","         29951, 29962,    32, 30049, 29954,   564, 29959, 29950,   335, 26639,\n","           527, 29965,    54, 29950,  1014,   106,   482,   105,   454,   798,\n","         29951, 29962,    32, 29959, 29950,   951, 29953,   499, 24545,   217,\n","         29951, 29962,  7114, 29951,  1059,   261, 29992, 29961,  9086,     3,\n","          1202, 30027,    32, 29959, 29955,   617, 29961,   569, 29963,   528,\n","            62, 29951, 29962,    85, 30008, 29958,   828, 30077,   261, 29961,\n","           420,     3]]), 'start_logits': tensor([[-4.5185e+00, -3.5639e+00, -4.8933e+00, -8.0808e+00, -8.2283e+00,\n","         -6.7441e+00, -7.1458e+00, -1.7364e+00, -5.7847e+00,  6.0185e-01,\n","         -9.4870e-03, -7.5434e-01, -1.5109e+00,  5.9728e+00, -1.9431e+00,\n","         -5.7772e-01,  4.6076e-01, -4.1767e+00, -5.5412e+00, -7.6329e+00,\n","         -7.8268e+00, -7.0043e+00,  5.1009e-01, -6.4612e+00, -1.3730e+00,\n","         -4.1928e+00, -5.6239e+00, -5.6566e+00, -3.2363e-01, -4.8682e+00,\n","         -1.2663e+00, -3.1040e+00, -4.7228e+00,  2.5096e-01, -3.3500e+00,\n","         -1.6922e+00, -7.2057e+00, -7.1320e+00, -5.7041e+00, -7.5002e+00,\n","         -8.6133e+00, -7.2012e+00, -8.1689e+00, -7.5691e+00,  4.8129e-02,\n","         -6.9670e-01, -5.6394e+00, -4.7014e+00, -5.7704e-01, -6.7735e+00,\n","         -2.2596e+00,  1.4209e-01, -3.0486e+00, -4.3312e+00,  4.6832e+00,\n","         -1.8493e+00, -5.8334e+00, -2.6198e+00, -6.9307e+00, -7.0564e+00,\n","         -4.3319e+00, -7.5530e+00, -7.8735e+00, -3.9155e+00, -6.6526e+00,\n","         -7.4941e+00, -7.6484e+00, -3.9370e+00, -8.3557e+00, -6.5415e+00,\n","         -8.6436e+00, -3.0477e+00, -7.4030e+00, -8.6171e+00, -7.4338e+00,\n","          1.6471e+00, -2.4388e-01, -5.5337e+00, -3.4202e+00, -7.0948e+00,\n","         -7.5726e+00, -5.9091e+00, -6.6418e+00, -2.0765e+00, -4.7542e+00,\n","         -9.7262e-02, -3.5793e+00, -4.2836e+00, -6.1479e+00, -8.0005e+00,\n","         -8.3466e+00, -5.7974e+00, -7.2987e+00, -3.1466e+00, -7.6942e+00,\n","         -4.1799e+00, -4.4692e+00, -7.5953e+00, -5.3277e+00, -5.6831e+00,\n","         -8.3234e+00, -8.4332e+00, -7.4340e+00,  6.3506e+00, -1.3057e+00,\n","          1.0606e+00,  1.2463e+00, -4.5130e+00, -1.7265e+00, -5.7629e+00,\n","         -6.8899e+00, -4.0630e+00, -1.3467e+00, -5.3380e+00, -6.3083e+00,\n","         -6.1071e+00, -1.2889e+00, -6.0638e+00, -7.7697e+00, -6.5463e+00,\n","         -7.6483e+00, -7.3999e+00, -1.6094e+00, -8.3299e+00, -4.7553e+00,\n","         -8.4453e+00, -4.4358e+00, -8.6256e+00, -8.6659e+00, -4.1776e+00,\n","         -8.7730e+00, -5.6558e+00, -9.0520e+00, -8.2929e+00, -8.8475e+00,\n","         -8.0681e+00, -4.8264e+00, -5.1950e+00, -8.3535e+00, -8.6970e+00,\n","         -6.3448e+00, -7.9008e+00, -5.0430e+00, -8.7101e+00, -6.0554e+00,\n","         -5.3990e+00, -8.5424e+00, -8.4485e+00, -8.6103e+00, -8.4972e+00,\n","         -7.4663e+00, -8.2938e+00, -5.0198e+00, -7.4835e+00,  2.9739e+00,\n","         -4.0738e+00, -7.4126e-01, -6.0918e-01, -8.1698e+00, -6.2430e+00,\n","         -8.9859e+00, -9.2267e+00, -5.9423e+00, -6.9323e+00, -8.7283e+00,\n","         -8.6720e+00, -8.0233e+00,  3.2937e+00, -1.8430e+00, -2.5917e+00,\n","          2.2237e+00, -3.1439e+00,  4.0539e+00, -1.1575e+00, -4.2415e+00,\n","         -7.3644e+00, -2.5051e+00,  3.7699e+00, -2.9187e+00, -6.6976e-01,\n","          1.2043e-01, -5.0030e+00, -7.1577e+00, -8.3499e+00, -5.5078e+00,\n","         -3.4629e+00, -7.6206e+00, -8.8586e+00, -6.1474e+00, -8.4351e+00,\n","         -8.4739e+00, -8.7656e+00, -4.1507e+00, -8.5613e+00, -8.5248e+00,\n","         -5.8941e+00, -8.8512e+00, -7.7340e+00, -8.3577e+00, -3.3282e+00,\n","         -7.1612e+00, -4.6061e+00, -8.3621e+00, -5.6234e+00, -8.6525e+00,\n","         -7.3691e+00, -8.3958e+00, -6.8925e+00, -8.5059e+00, -8.6333e+00,\n","         -6.8444e+00, -7.8762e+00, -3.9267e+00, -5.6395e+00, -5.9732e+00,\n","         -8.7690e+00, -2.5575e-01, -7.7913e+00, -5.3255e+00, -7.2424e+00,\n","         -8.1233e+00, -6.9045e+00, -3.5832e+00, -5.7948e+00, -8.7852e+00,\n","         -7.2740e+00, -9.1947e+00, -8.6060e+00, -6.3790e+00, -8.0548e+00,\n","         -7.3828e+00, -8.5016e+00, -8.3759e+00, -7.1052e+00,  4.1134e+00,\n","         -4.1201e+00, -1.5822e+00, -5.3838e+00, -7.5130e+00, -5.5556e+00,\n","         -7.9032e+00, -7.6458e+00, -6.8434e+00,  3.6512e+00, -4.0127e+00,\n","         -6.2607e+00, -7.5425e+00, -3.6928e+00, -8.2332e+00, -8.2563e+00,\n","         -5.3348e+00, -8.0201e+00, -4.6949e+00, -8.3398e+00, -4.5833e+00,\n","         -6.9052e+00, -8.4886e+00, -4.8049e+00, -6.2359e+00, -4.9483e+00,\n","         -7.1150e+00, -7.6266e+00, -7.3467e+00, -7.8649e+00, -4.9299e+00,\n","         -7.2223e+00, -7.5106e+00, -5.8039e+00, -8.7206e+00, -8.4495e+00,\n","         -8.3945e+00, -8.3618e+00, -7.1299e+00, -8.1520e+00,  6.9254e-01,\n","         -7.4375e+00, -6.2047e+00, -8.2911e+00, -7.8139e+00, -8.8950e+00,\n","         -5.8366e+00, -8.7805e+00, -6.4842e+00, -8.9692e+00, -8.4414e+00,\n","         -7.1205e+00,  3.9189e+00, -6.5582e+00, -4.1784e+00,  6.1794e+00,\n","          3.2969e+00, -6.4881e-01,  1.3742e+00,  7.2130e+00, -2.8516e+00,\n","         -2.1878e+00, -2.0266e+00, -5.7010e+00, -6.5936e+00, -3.2010e+00,\n","         -6.0874e+00, -7.6293e+00, -5.9349e+00, -7.7335e+00, -7.4876e+00,\n","         -3.6041e+00,  4.5242e+00,  1.0359e-01, -6.2448e+00, -3.9194e+00,\n","         -7.5964e+00, -6.2173e+00, -9.0759e+00, -7.9916e+00, -8.2710e+00,\n","         -8.2077e+00, -7.1351e+00,  3.4179e+00, -2.6896e+00, -7.1656e+00,\n","         -2.1953e+00, -3.0903e+00, -4.5042e+00, -5.1723e+00, -1.9850e+00,\n","         -6.5868e+00, -6.6365e+00,  2.3868e+00, -2.5029e+00, -5.1872e+00,\n","         -6.2323e+00, -8.1611e+00, -5.1807e+00, -5.3159e+00, -6.3422e+00,\n","         -5.7588e+00, -5.3619e+00, -8.8720e+00, -7.0394e+00, -8.6687e+00,\n","         -9.1747e+00, -8.4250e+00, -4.5113e+00, -7.6316e+00, -4.9553e+00,\n","         -8.5381e+00, -6.2706e+00, -7.9734e+00, -8.4146e+00, -8.5445e+00,\n","         -8.2877e+00, -5.5964e+00, -8.6872e+00, -8.9723e+00, -8.2590e+00,\n","         -8.4819e+00, -6.3907e+00, -5.5074e+00, -8.8599e+00, -8.8047e+00,\n","         -3.0740e+00, -7.5361e+00, -9.0948e+00, -7.8345e+00, -8.7482e+00,\n","         -8.7448e+00, -7.4645e+00, -9.4689e+00, -8.1982e+00, -9.1972e+00,\n","         -8.6810e+00, -9.1390e+00, -6.6073e+00, -8.5837e+00, -7.2280e+00,\n","         -8.7098e+00, -8.9053e+00, -8.2618e+00, -4.2555e+00, -7.3991e+00,\n","         -7.0665e+00, -5.6173e+00, -8.4795e+00, -8.7253e+00, -6.7893e+00,\n","         -8.2485e+00, -2.1968e+00, -6.7647e+00, -6.0453e+00, -8.7959e+00,\n","         -5.8692e+00, -8.5953e+00, -9.1154e+00, -8.1828e+00, -8.4476e+00,\n","          2.6371e+00, -3.5837e+00, -7.4106e+00, -3.9669e+00, -7.4009e+00,\n","         -4.7744e+00, -7.8916e+00, -7.3836e+00, -5.5476e+00, -7.4975e+00,\n","         -7.4074e+00, -7.2502e+00, -2.0645e+00, -7.9421e+00, -7.5175e+00,\n","         -4.7811e+00, -8.7588e+00, -4.9379e+00, -8.7161e+00, -5.7010e+00,\n","         -7.2578e+00, -8.7102e+00, -5.4307e+00, -4.6972e+00, -7.7705e+00,\n","         -8.4847e+00, -6.9703e+00, -8.9278e+00, -4.2056e+00, -8.9606e+00,\n","         -8.4961e+00, -7.2371e+00, -8.4647e+00, -4.4986e+00, -8.1755e+00,\n","         -8.8439e+00, -7.4021e+00, -9.3382e+00, -7.2936e+00, -9.1760e+00,\n","         -5.1037e+00, -8.3173e+00, -9.0950e+00, -8.5033e+00, -8.7399e+00,\n","         -9.0046e+00, -8.6068e+00,  1.1868e+00, -4.2445e+00, -7.7134e+00,\n","         -5.7615e+00, -5.3911e+00, -7.8599e+00, -6.3192e+00, -3.1011e+00,\n","         -8.0871e+00, -7.7391e+00, -6.4569e+00, -9.0008e+00, -9.0911e+00,\n","         -7.9171e+00, -9.0907e+00, -9.2468e+00, -8.6816e+00, -6.8684e+00,\n","         -7.7309e+00, -9.5525e+00, -7.9587e+00, -9.2791e+00, -7.8083e+00,\n","         -7.9394e+00, -8.3818e+00, -7.1145e+00, -7.8176e+00, -5.3703e+00,\n","         -8.7924e+00, -8.5200e+00, -6.5735e+00, -8.8310e+00, -9.0444e+00,\n","         -5.8493e+00, -8.7828e+00, -7.3986e+00, -8.9839e+00, -8.3217e+00,\n","         -8.9961e+00, -8.5612e+00, -6.1389e+00, -9.1273e+00, -7.8084e+00,\n","         -4.8753e+00, -7.9282e+00, -8.7313e+00, -5.8722e+00, -8.6201e+00,\n","         -6.1415e+00, -7.9674e+00, -6.8173e+00, -8.8420e+00, -8.9410e+00,\n","         -8.6369e+00, -8.7450e+00, -6.2431e+00, -7.7306e+00, -5.1719e+00,\n","         -7.6792e+00, -8.6877e+00, -8.1400e+00, -5.3469e+00, -7.8889e+00,\n","         -8.7699e+00, -7.8303e+00, -8.5027e+00, -5.8936e+00, -8.5259e+00,\n","         -7.4839e+00, -4.5189e+00]]), 'end_logits': tensor([[-5.8489e+00, -7.2129e+00, -7.6588e+00, -9.5941e+00, -9.0192e+00,\n","         -7.8069e+00, -6.9224e+00, -1.2954e+00, -5.1558e+00, -3.4631e+00,\n","         -3.8654e+00, -9.1994e-01, -4.5133e+00, -3.6540e-01,  1.3980e+00,\n","          1.1854e+00,  4.3426e+00, -4.5760e-01, -7.0796e+00, -8.4582e+00,\n","         -7.5150e+00, -5.1689e+00, -2.0554e+00, -6.3813e+00, -5.1854e+00,\n","         -5.7166e+00, -3.2326e+00, -6.7401e+00, -1.7907e+00, -5.5896e+00,\n","         -5.6941e+00, -1.3995e+00, -7.0893e+00, -1.5645e+00, -1.4072e+00,\n","         -8.8383e-01, -6.3685e+00, -8.2890e+00, -7.5431e+00, -9.2405e+00,\n","         -8.8520e+00, -9.2133e+00, -8.6761e+00, -6.3667e+00, -3.8656e+00,\n","         -4.6775e+00, -6.7874e+00, -4.2055e+00, -1.7908e+00, -4.8728e+00,\n","         -6.0362e+00, -4.0206e+00, -3.0748e+00, -6.1079e+00, -1.3967e+00,\n","          3.2964e+00, -3.2685e+00, -4.6890e+00, -7.5055e+00, -7.1967e+00,\n","         -6.4922e+00, -8.9864e+00, -8.5754e+00, -7.6222e+00, -6.6628e+00,\n","         -5.7502e+00, -6.8480e+00, -5.2675e+00, -8.2009e+00, -7.9567e+00,\n","         -8.7604e+00, -6.9360e+00, -6.5731e+00, -8.4401e+00, -8.0322e+00,\n","         -4.8501e+00, -4.8252e+00, -4.8568e+00, -6.4829e+00, -8.9248e+00,\n","         -8.7538e+00, -7.5267e+00, -6.7808e+00, -5.1500e+00, -4.3434e+00,\n","          6.6270e-01, -1.1105e+00, -3.9342e+00, -6.8516e+00, -8.7675e+00,\n","         -7.7431e+00, -5.5127e+00, -8.2644e+00, -6.6308e+00, -6.9271e+00,\n","         -7.9864e+00, -7.8923e+00, -7.5657e+00, -6.3933e+00, -7.5266e+00,\n","         -9.2889e+00, -8.2542e+00, -6.4224e+00,  7.9376e-01,  2.6393e+00,\n","          1.6849e+00,  4.8032e+00, -1.7000e-02, -5.2383e+00, -4.3851e+00,\n","         -7.3603e+00, -6.4212e+00, -5.6977e+00, -7.2760e+00, -5.6436e+00,\n","         -7.3529e+00, -4.6021e+00, -4.9386e+00, -6.5147e+00, -7.8774e+00,\n","         -7.5346e+00, -5.9939e+00, -5.6397e+00, -8.3071e+00, -5.6619e+00,\n","         -9.1164e+00, -8.2545e+00, -9.6106e+00, -8.6807e+00, -5.5807e+00,\n","         -9.5151e+00, -7.4136e+00, -9.3977e+00, -9.5014e+00, -8.5456e+00,\n","         -7.8195e+00, -7.2702e+00, -6.6729e+00, -9.0734e+00, -8.9258e+00,\n","         -7.5271e+00, -7.5259e+00, -7.7680e+00, -8.5630e+00, -8.7767e+00,\n","         -7.1907e+00, -9.2247e+00, -9.5148e+00, -8.5938e+00, -8.5176e+00,\n","         -8.6154e+00, -9.1081e+00, -7.0297e+00, -7.6847e+00, -2.2337e+00,\n","         -1.2979e+00, -1.1476e+00,  1.9810e+00, -7.4520e+00, -7.9094e+00,\n","         -9.6845e+00, -9.8455e+00, -7.4712e+00, -7.7659e+00, -8.9992e+00,\n","         -8.8098e+00, -6.9644e+00, -2.5194e+00,  1.2938e-04,  1.2382e+00,\n","         -2.8663e+00, -1.3174e+00, -1.0381e+00,  3.0623e+00, -3.4248e+00,\n","         -5.5793e+00, -6.4666e+00, -1.2072e+00,  9.5995e-01,  2.9699e-01,\n","          2.6532e+00, -4.9565e+00, -4.6877e+00, -8.2098e+00, -8.1064e+00,\n","         -6.9773e+00, -7.6575e+00, -9.2025e+00, -7.6125e+00, -9.5899e+00,\n","         -9.6758e+00, -8.9501e+00, -7.2222e+00, -8.1534e+00, -9.0651e+00,\n","         -6.2279e+00, -9.3285e+00, -9.1122e+00, -8.5504e+00, -6.8961e+00,\n","         -8.3048e+00, -7.3716e+00, -8.8576e+00, -6.3892e+00, -9.3207e+00,\n","         -9.1456e+00, -7.9425e+00, -7.6717e+00, -9.2443e+00, -8.3482e+00,\n","         -5.7600e+00, -7.9627e+00, -6.4306e+00, -8.2687e+00, -7.3047e+00,\n","         -8.9431e+00, -1.1825e+00, -7.4953e+00, -7.0525e+00, -7.9570e+00,\n","         -8.9342e+00, -8.0571e+00, -6.2303e+00, -6.6656e+00, -9.0003e+00,\n","         -8.7880e+00, -9.2766e+00, -8.6029e+00, -5.8982e+00, -8.9737e+00,\n","         -8.8626e+00, -9.7729e+00, -8.6232e+00, -5.9636e+00,  2.6335e+00,\n","         -3.7349e+00, -4.3733e+00, -4.1997e+00, -6.9878e+00, -6.3259e+00,\n","         -8.7212e+00, -7.5233e+00, -5.2831e+00,  2.2544e+00, -4.2150e+00,\n","         -4.5776e+00, -7.5046e+00, -6.8284e+00, -9.7247e+00, -9.0500e+00,\n","         -7.2835e+00, -8.3599e+00, -4.9871e+00, -8.6962e+00, -6.3842e+00,\n","         -8.1768e+00, -7.7880e+00, -8.2028e+00, -7.3543e+00, -8.9265e+00,\n","         -9.2785e+00, -7.5711e+00, -6.1715e+00, -7.7455e+00, -6.0007e+00,\n","         -6.9755e+00, -8.2047e+00, -6.7851e+00, -8.8718e+00, -8.9488e+00,\n","         -9.0444e+00, -8.1170e+00, -7.0656e+00, -8.4656e+00, -5.0502e-01,\n","         -6.1951e+00, -6.6667e+00, -8.2064e+00, -8.0860e+00, -8.8460e+00,\n","         -6.5978e+00, -8.0444e+00, -8.7540e+00, -8.9692e+00, -8.1853e+00,\n","         -5.4721e+00,  2.9780e+00, -4.9069e+00, -5.6457e+00,  3.6392e-01,\n","         -6.4364e-01,  3.4017e+00, -1.1543e+00,  6.5773e+00,  1.9127e-01,\n","         -3.5092e+00, -4.3707e+00, -4.3835e+00, -5.4423e+00, -5.4704e+00,\n","         -5.1535e+00, -6.3188e+00, -6.1287e+00, -8.0376e+00, -7.7956e+00,\n","         -4.5642e+00,  1.3700e+00,  1.5805e+00, -5.5257e+00, -4.7600e+00,\n","         -6.8434e+00, -8.4426e+00, -9.5344e+00, -8.9055e+00, -8.8927e+00,\n","         -7.7939e+00, -5.3321e+00, -2.1289e+00,  2.3849e+00, -4.3324e+00,\n","         -5.5860e+00, -5.3942e+00, -5.4953e+00, -6.5388e+00, -5.2069e+00,\n","         -4.0590e+00, -5.9794e+00, -5.7440e-01, -6.6165e-01, -3.1320e+00,\n","         -7.6813e+00, -7.0172e+00, -7.0656e+00, -7.3047e+00, -9.1227e+00,\n","         -8.1874e+00, -6.2042e+00, -8.9059e+00, -7.7485e+00, -9.7031e+00,\n","         -8.8401e+00, -8.2560e+00, -6.7439e+00, -7.9931e+00, -6.3488e+00,\n","         -8.7365e+00, -8.4338e+00, -8.4929e+00, -9.6795e+00, -9.4286e+00,\n","         -8.3409e+00, -6.7868e+00, -9.1892e+00, -9.2678e+00, -8.2838e+00,\n","         -9.2251e+00, -9.0621e+00, -7.8933e+00, -8.4320e+00, -9.1135e+00,\n","         -5.3851e+00, -7.5522e+00, -9.2172e+00, -9.0521e+00, -9.4375e+00,\n","         -9.3825e+00, -8.0664e+00, -9.5598e+00, -9.6750e+00, -9.7014e+00,\n","         -9.9660e+00, -9.0962e+00, -5.6289e+00, -8.7945e+00, -8.8368e+00,\n","         -9.4373e+00, -8.4400e+00, -6.9240e+00, -7.7674e+00, -5.2476e+00,\n","         -7.7300e+00, -7.3298e+00, -9.3433e+00, -9.2732e+00, -8.6562e+00,\n","         -8.1733e+00, -2.6885e+00, -5.8954e+00, -7.6274e+00, -8.8858e+00,\n","         -7.6499e+00, -9.7276e+00, -9.2543e+00, -9.9377e+00, -8.5132e+00,\n","         -3.6360e+00,  1.1988e+00, -4.7021e+00, -7.8461e+00, -7.3357e+00,\n","         -7.8157e+00, -7.9581e+00, -7.8914e+00, -8.6041e+00, -7.9219e+00,\n","         -9.5555e+00, -7.1669e+00, -3.5915e+00, -8.2282e+00, -9.5297e+00,\n","         -7.2702e+00, -9.4031e+00, -7.5468e+00, -9.2051e+00, -7.3377e+00,\n","         -7.7176e+00, -9.3491e+00, -7.1303e+00, -6.1871e+00, -8.8633e+00,\n","         -9.4022e+00, -8.4009e+00, -9.3159e+00, -5.4474e+00, -9.4752e+00,\n","         -9.5320e+00, -7.9494e+00, -9.6138e+00, -7.4583e+00, -6.5311e+00,\n","         -8.8941e+00, -8.5347e+00, -9.3681e+00, -8.7113e+00, -9.3178e+00,\n","         -8.4005e+00, -8.5040e+00, -9.3814e+00, -9.6317e+00, -9.7829e+00,\n","         -8.9691e+00, -7.6763e+00, -3.5761e+00, -8.5210e-02, -5.8646e+00,\n","         -8.1958e+00, -7.4034e+00, -7.7193e+00, -8.5327e+00, -4.1452e+00,\n","         -8.4778e+00, -7.9206e+00, -7.5146e+00, -9.8767e+00, -8.0997e+00,\n","         -8.8877e+00, -1.0155e+01, -1.0195e+01, -9.8102e+00, -9.5142e+00,\n","         -8.7686e+00, -9.7764e+00, -9.6505e+00, -1.0165e+01, -8.6495e+00,\n","         -8.2602e+00, -9.2706e+00, -8.6466e+00, -9.4888e+00, -7.5247e+00,\n","         -9.3596e+00, -8.6810e+00, -7.5906e+00, -9.5271e+00, -9.2062e+00,\n","         -7.1654e+00, -8.8852e+00, -8.3617e+00, -8.9967e+00, -9.1906e+00,\n","         -9.7453e+00, -9.9256e+00, -7.8598e+00, -9.0874e+00, -9.4078e+00,\n","         -6.4847e+00, -8.0829e+00, -8.9426e+00, -8.1357e+00, -8.1036e+00,\n","         -9.2166e+00, -8.3443e+00, -9.0930e+00, -9.9514e+00, -9.6847e+00,\n","         -9.6541e+00, -8.8280e+00, -8.6054e+00, -7.4396e+00, -6.2083e+00,\n","         -9.0026e+00, -9.3298e+00, -9.4239e+00, -7.9035e+00, -8.2040e+00,\n","         -8.4679e+00, -8.8578e+00, -9.0071e+00, -7.4377e+00, -8.7534e+00,\n","         -8.7249e+00, -5.8492e+00]]), 'tokenizer_name': 'monologg/koelectra-small-v2-distilled-korquad-384', 'guid': '35e61dcb479643448a2cb7d326ae50a6'}, {'input_ids': tensor([[    2,   390,    32, 29959, 29955,   617, 29961,   528, 29958,   247,\n","          4374,   795, 29972,   503, 29972,  1000, 15757, 29956,   828, 30201,\n","         29948,     5,  2939, 30033, 12438, 30054, 29972,    18,  3386,    55,\n","           527,  2849,    36,  1853,    39,   261, 29951,   180, 11749,   284,\n","         30007,  1181, 29948,     5,   247,   349, 10007, 29954, 20236, 29950,\n","           105,  2061,  2028, 29972, 29369,  7810, 29956,   247, 29951, 29962,\n","            32, 29959, 29950,   569, 29998, 30044, 29953,  4796, 29952,   458,\n","          9563,  4320, 11601, 29965,  5783,    96,  1202, 30027,    32, 29959,\n","         29955,   617, 29961,   569, 29963,   528,    95,    17,   828, 29987,\n","         29948,   106,    15,   313, 29982,    36,   919,  6973,    39,   908,\n","         29987, 29948,     5,   503, 29972,  1000, 15757, 29950,  1166, 30027,\n","         29951,   487,   215,   224, 30424, 29958,    23, 30008, 29951,  1385,\n","         29948,     5,    12, 29950,    32, 29947,  1975, 29981, 29955,    32,\n","         29947,  4196, 29947,    24,  2673,    18,   295,    32, 29959, 29950,\n","           258,  3782, 12152, 12078,   613,  8820,    37,    24,  1312,    45,\n","            55, 29947,   951,  3782,   503, 29972,  1000, 15757, 29951,  1985,\n","         29959, 29950,  9402,   621, 30222, 29948,     5,    78, 30598, 29964,\n","            54, 30188, 29369,  7810,  1899, 29961,   105,   503, 29972,  1000,\n","         15757,   951, 29992, 29961,   453,   717,    45, 29952,  8820,    37,\n","            24, 29955,  1679, 30006, 29972,    32, 29947,   204, 29989,   989,\n","         29967,  9798, 29957,   192, 29947,   116,  2499,   499, 29987, 29948,\n","           106,    94,   105,   547,  1123, 29961,   528, 29965, 24543,   157,\n","         29951, 29967,   731,  3112, 29951,  1096, 29947,   179,   106,    15,\n","           103, 29987, 29948,     5,  2939, 29956,    28, 30008, 29965,   978,\n","         29987, 29948,     5,  2939,   951, 29992, 29961,  3813, 29959, 29955,\n","           666, 29957,    32, 29952,  2387,    12, 13956,    43,   345,    37,\n","         30266, 29998, 30044, 29953,  2955, 29992, 29990,  2072, 30049,    37,\n","            24,  1312,   217, 29952,   528, 29951,  2143, 29955,   617, 29961,\n","           621, 29958,  1545, 30190, 29948,     5,  2939, 29951,   487, 12438,\n","         30054, 29972, 29990,  3386, 29947,   857,    57, 30008,    18,    85,\n","         30008, 29965,   978, 29959, 29950,    55,  1853,   261, 29953,  3712,\n","         29967,   461, 29951,  3024, 30080, 29948,     5, 29369,  7810, 29950,\n","           105,  4183,   569,   563,   635, 30031, 29956,  1853,   261,   106,\n","           336, 30053,   105,  1417,   166, 26639,  2793, 29965,  3135, 29959,\n","         29955,    18,   864, 29953,  2793, 29965, 11152, 24639,   109, 29960,\n","           205,   662, 29959, 29950,    45, 29947,   166,  2307, 30006, 29972,\n","           261,  3208, 29952,   429, 29960,   396,   847,  9563,  2193, 29955,\n","            24, 29948,   106,    15,   515, 29987, 29948,     5,  1552, 30027,\n","           628,    32, 29959, 29955,   617, 29961,   528, 29965,   828, 29973,\n","           524, 29959, 29955,    24, 29950, 29369,  7810, 29950,  1166, 30027,\n","           313, 30086,   628,   136, 30124, 30108, 29954,   528, 29951,   180,\n","          5934,    18,  1773,  9912,  1113,  1929,    18, 18329,  1440,   521,\n","         29953,  2544,    18,  4930, 29951,   180,   499,    55,   462, 30031,\n","         29953,  1483,  9563,   723, 30077,  4320, 11601, 29965,   716, 29987,\n","         29948,     5, 29369,  7810, 29950,   105, 11507,  3782,  1099,   528,\n","         29951, 29962,    32, 30049, 29954,   564, 29959, 29950,   335, 26639,\n","           527, 29965,    54, 29950,  1014,   106,   482,   105,   454,   798,\n","         29951, 29962,    32, 29959, 29950,   951, 29953,   499, 24545,   217,\n","         29951, 29962,  7114, 29951,  1059,   261, 29992, 29961,     3, 20236,\n","         29953,  1202, 30027,    32, 29959, 29955,   617, 29961,   569, 29963,\n","           528,   400, 29951, 29962,    85, 30008, 29965,    14,   261, 29961,\n","           420,     3]]), 'start_logits': tensor([[-4.5133, -3.8142, -5.3131, -8.2367, -8.4635, -7.0350, -7.2531, -1.7483,\n","         -5.7375,  0.4617, -0.0922, -0.9580, -1.8592,  5.6490, -1.8665, -0.5353,\n","          0.4349, -4.3914, -5.3357, -7.9250, -8.0983, -7.1050,  0.3829, -6.4024,\n","         -1.3883, -4.0464, -5.4376, -5.5061,  0.0107, -4.6935, -1.1604, -2.6461,\n","         -4.5278,  0.5859, -2.9319, -1.4922, -7.1624, -7.2974, -6.2791, -7.7803,\n","         -8.7762, -7.4421, -8.3888, -7.5908,  0.0172, -0.2858, -5.7967, -4.2741,\n","          0.1579, -6.5462, -1.6659,  0.3693, -2.9895, -4.2715,  4.7549, -1.7690,\n","         -5.7213, -2.7163, -7.2579, -7.2562, -4.6349, -7.6554, -7.9880, -4.1956,\n","         -6.9196, -7.6679, -7.7581, -4.1350, -8.4637, -6.7371, -8.7323, -3.4914,\n","         -7.8225, -8.6730, -7.4456,  1.9111, -0.2209, -5.6505, -3.9117, -7.4441,\n","         -7.9094, -6.2551, -6.5508, -2.2169, -4.6445,  0.2903, -3.4878, -4.3837,\n","         -6.1132, -8.2174, -8.4830, -5.6757, -7.3010, -3.6648, -7.8284, -4.5730,\n","         -4.9652, -7.9736, -5.4586, -6.1126, -8.5032, -8.6156, -7.4716,  6.2595,\n","         -1.1024,  1.0291,  1.3335, -4.6402, -2.3862, -6.2296, -7.3000, -4.4709,\n","         -2.1208, -5.7877, -6.6895, -6.5228, -2.0649, -6.6377, -8.0591, -6.7909,\n","         -7.9218, -7.5535, -2.2187, -8.5409, -5.4342, -8.6758, -5.0993, -8.8457,\n","         -8.8805, -4.8364, -8.9656, -6.3050, -9.2205, -8.5053, -9.0334, -8.2455,\n","         -5.2299, -5.7592, -8.5699, -8.8871, -6.7705, -8.2004, -5.7660, -8.9200,\n","         -6.4328, -5.9143, -8.7896, -8.7057, -8.8684, -8.8025, -7.8005, -8.4888,\n","         -5.5419, -7.7461,  3.0208, -3.9665, -0.6151, -0.5391, -8.4597, -6.8565,\n","         -9.1640, -9.3622, -6.0551, -7.4280, -8.9001, -8.8577, -8.1342,  3.3237,\n","         -1.5938, -2.5880,  2.2107, -3.1454,  4.0961, -1.0666, -4.5767, -7.3980,\n","         -2.4978,  3.8059, -2.7838, -0.5479,  0.3327, -5.3807, -7.3538, -8.5218,\n","         -5.8396, -3.8754, -7.9698, -9.0676, -6.5621, -8.6528, -8.6891, -8.9789,\n","         -4.7791, -8.8642, -8.7828, -6.4518, -9.0581, -8.0057, -8.6028, -3.8438,\n","         -7.4020, -5.3112, -8.6075, -6.1572, -8.8965, -7.7342, -8.6843, -7.3669,\n","         -8.7068, -8.8489, -7.0451, -8.0786, -3.9523, -5.8427, -6.4069, -8.9212,\n","         -0.1915, -7.9584, -5.6288, -7.5451, -8.3213, -6.9890, -3.7730, -6.2226,\n","         -8.9852, -7.5956, -9.3411, -8.7596, -6.5672, -8.3243, -7.7053, -8.7048,\n","         -8.5870, -7.0872,  4.5153, -3.9946, -2.2065, -6.1472, -7.6985, -5.9043,\n","         -8.1273, -7.8116, -6.7375,  3.9749, -4.1703, -6.1983, -7.5171, -4.3399,\n","         -8.4635, -8.5559, -5.8366, -8.2861, -5.3210, -8.5628, -5.1284, -7.2080,\n","         -8.6394, -5.1636, -6.5351, -5.2332, -7.3820, -7.9146, -7.6446, -8.0731,\n","         -5.3852, -7.5101, -7.7389, -6.2987, -8.8787, -8.6899, -8.6078, -8.5623,\n","         -7.5544, -8.3375,  0.8510, -7.4946, -6.4197, -8.4797, -8.1623, -9.1167,\n","         -6.3715, -8.9277, -6.8009, -9.1204, -8.5920, -7.0930,  3.5041, -6.9690,\n","         -4.4011,  6.5812,  4.0064, -0.1341,  1.7406,  7.7254, -3.1453, -2.5053,\n","         -3.1318, -6.3944, -6.9179, -4.0315, -6.6305, -7.8132, -6.3278, -7.8617,\n","         -7.6230, -3.5190,  5.0025,  0.3078, -6.1785, -4.6562, -7.8024, -6.5436,\n","         -9.2045, -8.1658, -8.3743, -8.3372, -7.0699,  3.2633, -2.7054, -7.1646,\n","         -2.2785, -3.4702, -4.6321, -5.5322, -2.9040, -6.8240, -6.8217,  2.6438,\n","         -2.6655, -5.1416, -6.3462, -8.2277, -5.3913, -5.6389, -6.7276, -6.2545,\n","         -5.9499, -9.1203, -7.3769, -8.8604, -9.4087, -8.6355, -4.7114, -7.8107,\n","         -5.5469, -8.7738, -6.7069, -8.2048, -8.6566, -8.8159, -8.6031, -6.3196,\n","         -8.9204, -9.2087, -8.6351, -8.7728, -6.8419, -6.5300, -9.1570, -9.0914,\n","         -3.4607, -8.0642, -9.3622, -8.2225, -9.0405, -9.0606, -8.0766, -9.6307,\n","         -8.3897, -9.3563, -8.8797, -9.3116, -6.7400, -8.7943, -7.5342, -8.8606,\n","         -9.0639, -8.3503, -4.6326, -7.5846, -7.3117, -6.1413, -8.6589, -8.9356,\n","         -7.0828, -8.2962, -2.5089, -7.0099, -6.2289, -9.0989, -6.6116, -8.7683,\n","         -9.2409, -8.3474, -8.4636,  2.1437, -3.9298, -7.5650, -4.4972, -7.6852,\n","         -5.4892, -8.2055, -7.6867, -5.9874, -7.8046, -7.6289, -7.3641, -2.2128,\n","         -8.0655, -7.8942, -6.2947, -8.9915, -5.6529, -8.9479, -6.3245, -7.8651,\n","         -8.9747, -5.9581, -5.1897, -8.1278, -8.7719, -7.5497, -9.1493, -4.3821,\n","         -9.1336, -8.7258, -7.7657, -8.6941, -5.2400, -8.4377, -9.0543, -7.8986,\n","         -9.4636, -7.5093, -9.2921, -5.5775, -8.6135, -9.2055, -8.6244, -8.9207,\n","         -9.1660, -8.7622,  0.8450, -4.5930, -7.9529, -5.9699, -5.7236, -8.0209,\n","         -6.7579, -3.5516, -8.4602, -8.0498, -7.0846, -9.1805, -9.2222, -8.2685,\n","         -9.2422, -9.4072, -8.9444, -7.2957, -8.1048, -9.6805, -8.1418, -9.3995,\n","         -8.1571, -8.0806, -8.4985, -7.1731, -7.9145, -5.9191, -9.0225, -8.7529,\n","         -7.2232, -8.9980, -9.2109, -6.3880, -8.9463, -7.8995, -9.1639, -8.6347,\n","         -9.1522, -8.7624, -6.4649, -9.2168, -7.9517, -5.5796, -7.8804, -8.6397,\n","         -7.6931, -3.3322, -7.5380, -6.2698, -7.8425, -7.0339, -8.8817, -9.0873,\n","         -8.5995, -8.7184, -6.1602, -7.6346, -4.8469, -7.5432, -8.8617, -8.2550,\n","         -6.2129, -8.2393, -9.0463, -7.8344, -6.2419, -8.6154, -7.5172, -4.5138]]), 'end_logits': tensor([[ -5.8755,  -7.4755,  -7.9477,  -9.7565,  -9.2270,  -8.1858,  -7.2850,\n","          -1.5113,  -5.5293,  -3.5225,  -3.8986,  -1.1142,  -4.7461,  -0.3936,\n","           1.3382,   1.0556,   4.1168,  -0.7866,  -7.4041,  -8.6899,  -7.8030,\n","          -5.5007,  -2.1189,  -6.3924,  -5.2152,  -5.6884,  -3.1399,  -6.5379,\n","          -1.4399,  -5.2918,  -5.5963,  -0.8980,  -6.8941,  -1.1532,  -0.9724,\n","          -0.7316,  -6.2678,  -8.4347,  -8.1280,  -9.4406,  -9.0479,  -9.4140,\n","          -8.9047,  -6.5193,  -3.8279,  -4.3473,  -6.7214,  -3.2001,  -1.4009,\n","          -4.8953,  -5.7741,  -3.8663,  -3.0398,  -6.1556,  -1.2585,   3.4270,\n","          -3.1716,  -4.7872,  -7.6468,  -7.3843,  -6.7800,  -9.1422,  -8.7688,\n","          -7.8807,  -6.9375,  -5.9126,  -6.9607,  -5.4631,  -8.2471,  -8.0576,\n","          -8.8473,  -7.1905,  -7.2824,  -8.6271,  -8.1438,  -4.5785,  -4.8339,\n","          -5.0200,  -6.7466,  -8.9322,  -8.8266,  -7.9754,  -6.8570,  -5.5520,\n","          -4.5049,   1.0098,  -0.7091,  -3.8088,  -6.9727,  -9.0098,  -7.9064,\n","          -5.6182,  -8.2271,  -6.9313,  -7.1418,  -8.1948,  -8.0954,  -7.9172,\n","          -6.2975,  -7.8892,  -9.4645,  -8.4133,  -6.4924,   0.8908,   2.7540,\n","           1.6985,   4.7490,  -0.1419,  -5.7704,  -4.9752,  -7.7223,  -6.8889,\n","          -6.1554,  -7.5402,  -6.0921,  -7.7320,  -5.1998,  -5.6950,  -6.9356,\n","          -8.1444,  -7.7528,  -6.2008,  -6.0440,  -8.5287,  -6.3253,  -9.3723,\n","          -8.7094,  -9.8631,  -9.0360,  -6.2080,  -9.7328,  -8.0588,  -9.5994,\n","          -9.7629,  -8.8523,  -8.0386,  -7.5884,  -7.1317,  -9.2592,  -9.1073,\n","          -7.8801,  -7.8119,  -8.3126,  -8.8821,  -9.0927,  -7.6665,  -9.4771,\n","          -9.7657,  -8.8955,  -8.8449,  -8.8988,  -9.3057,  -7.4652,  -7.9328,\n","          -2.0188,  -1.1171,  -0.9331,   2.0297,  -7.7651,  -8.5642,  -9.9078,\n","         -10.0549,  -7.6035,  -8.2708,  -9.2471,  -9.0423,  -7.1606,  -2.3134,\n","           0.2227,   1.2987,  -2.7808,  -1.3489,  -0.9659,   3.0317,  -3.7563,\n","          -5.4171,  -6.4447,  -1.0332,   1.0326,   0.3810,   2.7512,  -5.3641,\n","          -4.8087,  -8.3067,  -8.3498,  -7.2651,  -7.9439,  -9.3775,  -8.0307,\n","          -9.7959,  -9.8849,  -9.2035,  -7.7151,  -8.4983,  -9.3065,  -6.8023,\n","          -9.5509,  -9.3754,  -8.7942,  -7.2807,  -8.5456,  -7.9304,  -9.1154,\n","          -6.9690,  -9.5572,  -9.4692,  -8.2963,  -8.1926,  -9.4531,  -8.6080,\n","          -6.0775,  -8.1395,  -6.4450,  -8.3553,  -7.7947,  -9.0827,  -1.1431,\n","          -7.6154,  -7.2862,  -8.1994,  -9.1022,  -8.1214,  -6.2600,  -7.1206,\n","          -9.2577,  -9.0975,  -9.4779,  -8.8499,  -6.1686,  -9.1524,  -9.0892,\n","          -9.9113,  -8.8129,  -5.9530,   3.0165,  -3.3897,  -4.7740,  -5.0672,\n","          -7.0597,  -6.6671,  -8.8937,  -7.6587,  -5.1913,   2.5934,  -4.2894,\n","          -4.2812,  -7.2253,  -7.2659,  -9.8694,  -9.2953,  -7.7008,  -8.5645,\n","          -5.5018,  -8.8178,  -6.9163,  -8.4641,  -7.9824,  -8.4306,  -7.5922,\n","          -9.0610,  -9.3938,  -7.7371,  -6.4256,  -7.8849,  -6.4083,  -7.2840,\n","          -8.3509,  -7.2214,  -8.9831,  -9.1221,  -9.2845,  -8.3258,  -7.2977,\n","          -8.5755,  -0.3485,  -6.1717,  -6.8247,  -8.2765,  -8.3865,  -9.0161,\n","          -7.0480,  -8.2445,  -9.0275,  -9.1343,  -8.3178,  -5.3436,   2.5984,\n","          -5.4885,  -6.3664,   0.4693,  -0.2354,   3.8988,  -0.7678,   7.0301,\n","           0.4779,  -3.6943,  -5.3157,  -5.5210,  -5.7041,  -6.2162,  -5.9243,\n","          -6.5520,  -6.6011,  -8.1282,  -7.8754,  -4.4662,   1.9138,   2.0597,\n","          -5.0761,  -5.3592,  -6.9699,  -8.6240,  -9.6731,  -9.0303,  -9.0140,\n","          -7.8826,  -5.1184,  -2.1210,   2.3518,  -4.2147,  -5.6693,  -5.9602,\n","          -5.7304,  -6.9372,  -5.9532,  -4.3965,  -6.1833,  -0.2801,  -0.8627,\n","          -2.9666,  -7.6932,  -6.9988,  -7.1401,  -7.4988,  -9.4010,  -8.5570,\n","          -6.7193,  -9.1291,  -8.1040,  -9.8624,  -9.0848,  -8.4526,  -6.8333,\n","          -8.0727,  -6.8167,  -8.8965,  -8.7306,  -8.7324,  -9.8366,  -9.6835,\n","          -8.6939,  -7.3843,  -9.3894,  -9.4857,  -8.6268,  -9.4342,  -9.3572,\n","          -8.7081,  -8.7094,  -9.3272,  -5.6539,  -8.0751,  -9.4380,  -9.3686,\n","          -9.7032,  -9.6480,  -8.6416,  -9.7562,  -9.8149,  -9.8579, -10.1176,\n","          -9.2801,  -5.8386,  -8.9048,  -9.0530,  -9.5411,  -8.5773,  -7.0151,\n","          -7.9507,  -5.4626,  -7.9505,  -7.7227,  -9.4989,  -9.4203,  -8.9787,\n","          -8.3248,  -3.1456,  -6.1587,  -7.9975,  -9.0869,  -8.2610,  -9.8744,\n","          -9.4953, -10.1175,  -8.6839,  -3.9401,   0.7649,  -4.8628,  -8.1325,\n","          -7.6205,  -8.3638,  -8.3706,  -8.2917,  -8.8910,  -8.2803,  -9.6822,\n","          -7.3653,  -3.8104,  -8.3837,  -9.7376,  -8.5251,  -9.7057,  -8.0788,\n","          -9.3955,  -7.9148,  -8.3386,  -9.5902,  -7.5628,  -6.6462,  -9.2018,\n","          -9.6332,  -8.9327,  -9.5410,  -5.6100,  -9.6406,  -9.6788,  -8.4422,\n","          -9.8463,  -7.9967,  -6.9508,  -9.1124,  -8.9523,  -9.6220,  -9.0451,\n","          -9.5487,  -8.6758,  -8.8321,  -9.5806,  -9.7939,  -9.9969,  -9.2135,\n","          -7.9703,  -3.8541,  -0.6856,  -6.3927,  -8.4265,  -7.6686,  -7.9336,\n","          -8.9349,  -4.6622,  -8.9212,  -8.4171,  -8.0375, -10.0734,  -8.4252,\n","          -9.2348, -10.3002, -10.3439, -10.0735,  -9.8882,  -9.1347,  -9.9188,\n","          -9.8903, -10.2863,  -9.0144,  -8.7194,  -9.4830,  -8.8040,  -9.6304,\n","          -8.1346,  -9.6515,  -9.0970,  -8.1897,  -9.7936,  -9.5394,  -7.7329,\n","          -9.1486,  -8.9147,  -9.2630,  -9.4702,  -9.8814, -10.0679,  -8.3571,\n","          -9.4121,  -9.6836,  -7.3022,  -8.0117,  -8.5747,  -8.1604,  -5.4284,\n","          -8.0581,  -9.2419,  -8.6173,  -9.1607, -10.0988,  -9.8266,  -9.7767,\n","          -9.0523,  -8.7559,  -7.7946,  -5.9543,  -9.1161,  -9.5895,  -9.8237,\n","          -8.5811,  -8.8301,  -9.2481,  -9.4380,  -7.8463,  -8.8812,  -8.6515,\n","          -5.8759]]), 'tokenizer_name': 'monologg/koelectra-small-v2-distilled-korquad-384', 'guid': '075e761b370040cb9041eecd39afc27c'}, {'input_ids': tensor([[    2, 22862, 29958, 29962,  5311,  9564, 29965, 18627, 29959, 30153,\n","          6419, 30027, 12268, 19245,  3051, 29950,   238, 30173, 30554, 30120,\n","         30228, 29961,  1328, 29952,  1593, 29950, 29948,     5,   910,  7635,\n","         16445,  2226, 29952,   147, 29961,    45, 29947, 29948,     5,   416,\n","            46, 29950, 16244, 29965,  5052, 29950, 13873,   542, 29951,  1041,\n","          7244, 30006,  9563, 14988, 29956,   163, 29955,    18,  1155, 29951,\n","          2306, 30049,    37,    24, 30007,   179,     5,  2306,   378, 15984,\n","         29958,  5601, 29947, 17348, 29959, 30007,    75, 29986,   204, 29961,\n","           258, 29992, 29951, 30007, 13254, 29952,  7476,   440,    18,  6703,\n","         30027,    40, 12268, 19245,  3051, 16445,  2618,    40,    10,  1384,\n","          1050, 16445,  1133, 29992, 29953, 14284, 29965,   332, 29959, 29955,\n","          3427, 29961, 10120,   876, 29951, 29962,  1506, 29965,  2460, 29950,\n","            55,   384,  4638, 29951,  9203, 29959, 29955,    24, 29948,     5,\n","           578, 29931,  1043, 29972, 12268, 19245,  3051, 30033, 18052, 30283,\n","         30087,  1043, 29972,  6319, 23513,    25, 30892, 29955, 29950,  6986,\n","         29972,  1290, 29951,   246,  2100,    18,   830,  2434, 29953,   475,\n","         30006,   451,  9563,  1463,   521, 29956,   300, 29954,   930, 29948,\n","             5, 16445, 13873, 29952,    12, 30007,    73, 19245,  3051, 29950,\n","           765, 30077, 10383,   987, 30033, 18697,  6241,  9563,   349, 30006,\n","          2157, 29952,  1432, 29950, 29948,     5,    46,   117, 19245,  3051,\n","         29950,  6791, 29951,  1139, 29957,  9600, 30050, 29964, 16445,  2618,\n","         29947,   481, 29959, 29950,   995, 29947,    24,  1312,    45, 29952,\n","           227, 30007,    75, 29955,  1764, 29958,   987, 29965,   147, 29989,\n","           753, 29952,  1340,  1086,     5, 14988, 30188, 29975, 29952,   147,\n","         29961, 19245,  3051, 29950,  9600, 30050, 29964,  2618, 29951,  1039,\n","         13661, 29950,   701,  9563,  2585,  1408, 29947,    75, 29960,   396,\n","          1664, 29965,  3295, 29950, 30090,    18, 18529, 29997, 30041,  9600,\n","         30050, 29964,  2618, 29961,  6319, 23513,    25, 30892, 29955, 29956,\n","          1384, 29957,  2618, 29947, 30080, 29948,     5,    25, 30892, 29955,\n","         29956,     6,  2618, 29952,  1384, 29957,  2721, 29950, 12268, 19245,\n","          3051, 29953,   511, 29952,   987, 29973, 29995, 29960,   396,    45,\n","         29947, 30080, 29948,     5,  6986, 29972, 19245,  3051, 29953,  6333,\n","         29947,  7660, 29954,   109, 12173,  8721,  9563,  1096, 29952,    54,\n","         30103, 29987, 30153,    45,     5, 19245,  3051, 29950,    25, 30892,\n","         29955, 29953,  6465, 29951,  3837, 29987, 29955,    46,   378, 29958,\n","           932, 29961, 12350, 29957,  1108, 29956,   179,     5, 19245,  3051,\n","         29956, 16445,  2618, 29952,  1384, 29959, 30007,    73,    45, 29967,\n","          1935, 29947,  1798, 29956,    75, 30080, 29948,     5,     3, 12268,\n","         19245,  3051, 29956,  2618, 29953,  1096, 29952,   147, 29989,   511,\n","         29952,   987, 29957,   995, 29953, 15236, 29950,   420,     3,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]]), 'start_logits': tensor([[-5.0368e+00, -6.6617e+00, -9.4831e+00, -9.1667e+00, -7.2744e+00,\n","         -7.1253e+00, -9.1616e+00, -8.5997e+00, -8.6118e+00, -8.3407e+00,\n","         -6.4129e+00, -8.6215e+00, -4.7673e+00, -6.7521e+00, -8.6068e+00,\n","         -9.0928e+00, -6.3324e+00, -8.6119e+00, -8.9982e+00, -9.3574e+00,\n","         -9.5275e+00, -9.5533e+00, -8.7946e+00, -9.6607e+00, -8.7879e+00,\n","         -9.4027e+00, -9.5090e+00, -9.4128e+00, -7.5456e+00, -5.5109e+00,\n","         -7.0554e+00, -8.4253e+00, -9.6214e+00, -8.9087e+00, -9.6303e+00,\n","         -9.0548e+00, -9.3367e+00, -9.3122e+00, -9.3773e+00, -8.0221e+00,\n","         -7.9545e+00, -9.2681e+00, -7.1202e+00, -9.4446e+00, -8.9643e+00,\n","         -9.1988e+00, -7.3586e+00, -8.9126e+00, -9.5022e+00, -7.9001e+00,\n","         -7.3325e+00, -9.7875e+00, -9.5648e+00, -7.2766e+00, -9.6421e+00,\n","         -9.2688e+00, -9.5183e+00, -9.1040e+00, -5.1348e+00, -9.1266e+00,\n","         -7.8579e+00, -9.5067e+00, -9.3891e+00, -9.3403e+00, -9.4914e+00,\n","         -9.4399e+00, -9.3685e+00, -6.6346e+00, -8.5285e+00, -7.4384e+00,\n","         -9.4069e+00, -7.4529e+00, -9.5568e+00, -8.0023e+00, -9.4163e+00,\n","         -9.5229e+00, -9.4812e+00, -9.6682e+00, -8.1673e+00, -9.5739e+00,\n","         -8.8246e+00, -9.5528e+00, -9.6404e+00, -9.5199e+00, -7.6565e+00,\n","         -9.7594e+00, -8.9313e+00, -9.6259e+00, -9.4111e+00, -6.2298e+00,\n","         -8.3605e+00, -3.4862e+00, -2.7603e+00, -5.5890e+00, -8.1724e+00,\n","         -6.2928e+00, -6.9260e+00, -7.3236e+00, -7.9195e+00, -7.0329e+00,\n","         -9.2129e+00, -5.9929e+00, -8.5420e+00, -9.0183e+00, -8.9337e+00,\n","         -7.4074e+00, -9.6218e+00, -8.8324e+00, -9.3327e+00, -9.7049e+00,\n","         -7.3872e+00, -9.1631e+00, -6.8631e+00, -8.1235e+00, -9.5775e+00,\n","         -9.3959e+00, -7.6990e+00, -9.7645e+00, -8.8956e+00, -9.4587e+00,\n","         -8.8829e+00, -7.4148e+00, -8.5672e+00, -9.6967e+00, -8.7885e+00,\n","         -9.2657e+00, -9.5120e+00, -9.0967e+00, -9.5104e+00, -9.5158e+00,\n","         -8.1505e+00, -7.7222e-01, -7.3713e+00, -7.9402e+00, -4.0182e+00,\n","         -6.6404e+00, -8.2989e+00, -8.5283e+00, -4.2651e+00, -8.1031e+00,\n","         -7.1019e+00, -7.9420e+00, -8.3200e+00, -3.7593e+00, -7.4110e+00,\n","         -5.5987e+00, -8.3866e+00, -9.0511e+00, -9.2150e+00, -6.9352e+00,\n","         -9.6257e+00, -8.5231e+00, -9.7081e+00, -6.5172e+00, -8.3895e+00,\n","         -9.5393e+00, -8.7115e+00, -7.2269e-01, -7.7920e+00, -6.9595e+00,\n","         -9.3941e+00, -8.6485e+00, -9.6888e+00, -8.2810e+00, -8.0048e+00,\n","         -9.6009e+00, -8.5643e+00, -9.5203e+00, -8.8663e+00, -9.4289e+00,\n","         -9.3022e+00, -4.1244e+00, -7.7125e+00, -9.4603e+00, -8.4448e+00,\n","         -9.0345e+00, -8.5380e+00, -4.1307e+00, -8.2993e+00, -8.4529e+00,\n","         -7.3089e+00, -9.3424e+00, -5.5364e+00, -8.5428e+00, -9.3224e+00,\n","         -6.6204e+00, -8.5747e+00, -9.5270e+00, -7.3254e+00, -9.5981e+00,\n","         -8.5664e+00, -9.7212e+00, -8.7143e+00, -9.3140e+00, -9.3673e+00,\n","         -9.0355e+00, -7.4331e+00, -8.5468e+00, -3.5438e+00, -8.2395e+00,\n","         -7.2047e+00,  8.7076e+00, -5.6027e-01, -9.7401e-02, -1.8180e+00,\n","          2.4244e+00, -3.5831e+00, -5.6903e+00, -2.7133e+00, -2.7683e+00,\n","         -5.7715e+00, -3.5405e+00, -7.1930e+00, -6.9610e+00, -2.8041e+00,\n","         -6.2001e+00, -5.5376e+00, -8.1604e+00, -8.7754e+00, -9.4624e+00,\n","         -7.7723e+00, -9.2608e+00, -9.2076e+00, -9.0687e+00, -7.6851e+00,\n","         -9.6627e+00, -7.5842e+00, -9.5681e+00, -8.5890e+00, -8.9135e+00,\n","         -7.0294e+00, -9.5221e+00, -8.5002e+00, -8.9466e+00, -8.9678e+00,\n","         -6.7551e+00, -9.1109e+00, -9.6023e+00, -9.3843e+00, -8.4973e+00,\n","         -9.2531e+00, -3.7026e+00, -8.4103e+00, -8.7961e+00, -6.4449e-01,\n","         -6.7331e+00, -8.0809e+00, -4.9029e+00, -8.8841e+00, -7.7930e+00,\n","         -8.7213e+00, -9.7709e+00, -8.9405e+00, -9.6928e+00, -6.8355e+00,\n","         -8.4420e+00, -9.5272e+00, -9.3268e+00, -9.1074e+00, -9.2654e+00,\n","         -8.5266e+00, -9.6560e+00, -8.9545e+00, -9.2523e+00, -9.6948e+00,\n","         -8.7841e+00, -6.9187e+00, -8.7920e+00, -9.1017e+00, -1.7248e-01,\n","         -7.3094e+00, -8.5027e+00, -5.1801e+00, -8.1989e+00,  1.1545e+00,\n","         -5.0743e+00,  7.9482e-02, -5.1551e+00, -5.3877e+00, -7.3678e+00,\n","         -6.0932e+00, -8.1276e+00, -4.7326e+00, -8.6419e+00, -8.9813e+00,\n","         -9.3071e+00, -9.0927e+00, -1.5719e-03, -6.6085e+00, -6.8702e+00,\n","         -8.4677e+00, -6.8960e+00, -5.8077e+00, -8.7435e+00, -6.7616e+00,\n","         -9.0272e+00, -7.6803e+00, -9.0052e+00, -2.6202e+00, -5.2707e+00,\n","         -8.0702e+00, -8.7676e+00, -6.8936e+00, -9.1123e+00, -7.6837e+00,\n","         -9.1065e+00, -9.1039e+00, -8.9576e+00, -8.8442e+00, -8.6620e+00,\n","         -9.1612e+00, -9.0275e+00, -9.3137e+00, -9.3092e+00, -5.8381e+00,\n","         -8.7559e+00, -4.3695e+00, -8.4173e+00, -9.0170e+00, -7.1794e+00,\n","         -9.4722e+00, -8.3822e+00, -9.5289e+00, -9.1916e+00, -9.6318e+00,\n","         -7.8493e+00, -9.9749e+00, -8.0827e+00, -9.7568e+00, -8.6057e+00,\n","         -9.5717e+00, -9.2523e+00, -9.4003e+00, -9.0670e+00, -9.3895e+00,\n","         -6.0967e+00, -8.9302e+00, -9.4552e+00, -2.3098e+00, -7.7097e+00,\n","         -8.5936e+00, -9.3257e+00, -7.8246e+00, -9.7128e+00, -8.9029e+00,\n","         -9.5641e+00, -9.9690e+00, -8.5879e+00, -8.6928e+00, -9.2943e+00,\n","         -7.9832e+00, -9.6447e+00, -7.5365e+00, -9.5154e+00, -8.0127e+00,\n","         -9.5839e+00, -9.4864e+00, -9.5819e+00, -6.1947e+00, -9.1384e+00,\n","         -9.1987e+00, -6.3206e+00, -7.4641e+00, -9.4962e+00, -8.3835e+00,\n","         -9.5443e+00, -9.4965e+00, -9.2857e+00, -9.4257e+00, -9.7135e+00,\n","         -8.8716e+00, -9.9078e+00, -8.7341e+00, -9.8057e+00, -9.3189e+00,\n","         -9.6627e+00, -9.7357e+00, -9.5639e+00, -9.2966e+00, -6.0133e+00,\n","         -7.8430e+00, -9.2348e+00, -9.0037e+00, -7.9109e+00, -9.5248e+00,\n","         -8.8652e+00, -9.5709e+00, -9.0630e+00, -9.3733e+00, -8.0906e+00,\n","         -9.5422e+00, -8.7226e+00, -9.2273e+00, -7.4851e+00, -9.1210e+00,\n","         -7.3022e+00, -8.8271e+00, -8.1011e+00, -8.7091e+00, -4.2320e+00,\n","         -4.2277e+00, -4.1795e+00, -4.1394e+00, -4.1733e+00, -4.2327e+00,\n","         -4.2406e+00, -4.2071e+00, -4.3718e+00, -4.6622e+00, -4.3839e+00,\n","         -4.3660e+00, -4.3584e+00, -4.3272e+00, -4.3610e+00, -4.2540e+00,\n","         -4.2933e+00, -4.4966e+00, -4.4136e+00, -4.3419e+00, -4.3507e+00,\n","         -4.3240e+00, -4.3109e+00, -4.3599e+00, -4.3235e+00, -4.3014e+00,\n","         -4.4278e+00, -4.2971e+00, -4.2168e+00, -4.1526e+00, -4.1808e+00,\n","         -4.2060e+00, -4.2421e+00, -4.2323e+00, -4.2050e+00, -4.1377e+00,\n","         -4.1287e+00, -4.1046e+00, -4.0955e+00, -4.2201e+00, -4.2386e+00,\n","         -4.2359e+00, -4.2056e+00, -4.1166e+00, -4.1544e+00, -4.2019e+00,\n","         -4.2173e+00, -4.2106e+00, -4.1459e+00, -4.1831e+00, -4.1556e+00,\n","         -4.1505e+00, -4.1460e+00, -4.1553e+00, -4.1788e+00, -4.1890e+00,\n","         -4.1469e+00, -4.1245e+00, -4.1372e+00, -4.2038e+00, -4.1724e+00,\n","         -4.2022e+00, -4.1810e+00, -4.1620e+00, -4.2108e+00, -4.2428e+00,\n","         -4.2648e+00, -4.2039e+00, -4.1705e+00, -4.1139e+00, -4.2569e+00,\n","         -4.3577e+00, -4.2867e+00, -4.2589e+00, -4.2337e+00, -4.2346e+00,\n","         -4.1855e+00, -4.2515e+00, -4.2622e+00, -4.2604e+00, -4.2534e+00,\n","         -4.2605e+00, -4.2689e+00, -4.2435e+00, -4.2508e+00, -4.2865e+00,\n","         -4.2656e+00, -4.2930e+00, -4.2922e+00, -4.2524e+00, -4.2464e+00,\n","         -4.2217e+00, -4.1632e+00, -4.1201e+00, -4.1576e+00, -4.2017e+00,\n","         -4.2268e+00, -4.2646e+00, -4.3129e+00, -4.3807e+00, -4.3019e+00,\n","         -4.2462e+00, -4.2396e+00, -4.2371e+00, -4.2228e+00, -4.2793e+00,\n","         -4.3144e+00, -4.2957e+00, -4.2208e+00, -4.2285e+00, -4.2718e+00,\n","         -4.3411e+00, -5.0341e+00]]), 'end_logits': tensor([[ -6.6566,  -8.5801,  -9.7507,  -9.1866,  -9.4098,  -9.1156,  -9.8756,\n","          -9.1179,  -9.8443,  -9.5279,  -9.0784,  -8.2511,  -8.0642,  -8.9418,\n","          -7.4604,  -8.9455,  -9.2148,  -9.5467,  -9.1019,  -9.1254, -10.1186,\n","          -9.8657,  -9.5482, -10.0018, -10.2574, -10.3638,  -9.9299,  -8.9838,\n","          -9.8920,  -8.5000,  -8.2231,  -9.0402,  -9.7270,  -9.7332,  -9.7464,\n","          -9.7330,  -9.8787,  -9.4826,  -8.6568,  -9.2720,  -9.6586,  -9.7631,\n","          -8.9308, -10.3956,  -9.8265, -10.0847,  -8.9274,  -9.9001,  -9.7149,\n","          -9.7929, -10.0500,  -9.5851,  -9.8707,  -9.1020,  -9.8409,  -9.8148,\n","          -9.6593,  -9.2506,  -6.9175,  -8.8500,  -8.7655,  -9.8786, -10.0379,\n","         -10.1121,  -9.8210,  -9.8193,  -8.7769,  -8.9159,  -9.1707,  -9.7109,\n","         -10.0077,  -9.1881, -10.2264,  -9.3552,  -9.9085,  -9.8204, -10.0526,\n","         -10.0542, -10.4719, -10.2844,  -9.9587,  -9.9960, -10.2934, -10.0653,\n","          -9.4795, -10.0278,  -9.9913,  -9.4829,  -9.2311,  -8.6724,  -7.3563,\n","          -8.0598,  -6.8968,  -8.0767,  -7.0731,  -7.5109,  -6.5077,  -5.8381,\n","          -8.0537,  -8.2100,  -9.4755,  -8.7996,  -9.1595,  -9.6072, -10.1537,\n","          -8.8398,  -9.9243,  -9.5882, -10.0715,  -9.5330,  -9.6986,  -9.8248,\n","          -8.9207,  -8.3874,  -9.3552,  -9.3967,  -9.1208,  -9.9486,  -9.6301,\n","          -9.9535,  -9.7714,  -9.3075,  -9.3211,  -9.7390,  -9.4376, -10.0359,\n","          -9.8280, -10.1451,  -9.7325,  -8.8857,  -9.2263,  -2.4421,  -7.5755,\n","          -8.4633,  -7.4653,  -8.6892,  -6.9513,  -8.7355,  -6.7595,  -8.2618,\n","          -4.6671,  -8.1036,  -9.2142,  -7.9598,  -6.2653,  -7.3567,  -8.3465,\n","          -6.0219,  -8.0047,  -8.7625,  -9.5119,  -9.8566,  -9.4183,  -9.0988,\n","          -9.1615,  -9.7005,  -9.2110,  -2.3476,  -8.0168,  -8.6184,  -9.0571,\n","          -8.6030,  -9.7808,  -9.2276,  -9.6152, -10.2356,  -9.8617, -10.2040,\n","          -9.9890,  -9.6059,  -8.3736,  -6.7523,  -8.3627,  -9.5189,  -9.7922,\n","          -9.3675,  -9.3987,  -8.0648,  -5.9926,  -8.2202, -10.0559,  -9.6168,\n","          -8.2977,  -8.8553,  -9.7863,  -8.4808,  -8.3864,  -9.7042,  -9.5955,\n","          -9.7268,  -9.4503,  -9.9327,  -9.7178, -10.2765,  -9.5972,  -8.0602,\n","          -9.5643,  -9.2982,  -8.0109,  -5.7558,  -7.5056,   7.1244,   1.5681,\n","           1.8421,  -1.6204,  -2.9692,  -3.4422,  -1.8166,  -5.4800,  -2.4847,\n","          -4.9202,  -4.4523,  -8.7648,  -7.5341,  -2.3825,  -4.8984,  -6.8198,\n","          -8.3706,  -9.4234,  -9.8639,  -9.9243,  -9.7614, -10.3840,  -9.8109,\n","          -9.2660,  -9.2115,  -8.4105,  -9.6689,  -9.7019,  -9.4834,  -9.1202,\n","         -10.2279,  -9.4208,  -9.7895,  -8.1958,  -9.0565,  -9.7347,  -8.7294,\n","         -10.0151, -10.1006,  -9.7409,  -8.2019,  -6.4462,  -8.3570,  -5.1762,\n","          -5.0403,  -4.3944,  -3.6251,  -7.9714,  -9.0049,  -9.1646, -10.0978,\n","          -9.4250,  -9.5500,  -9.1007,  -8.9154,  -9.8124,  -9.5591,  -9.8579,\n","          -9.6134,  -9.3638, -10.0618, -10.0379, -10.2880,  -9.7222,  -8.7940,\n","          -9.9765,  -9.9828,  -9.1482,  -5.2673,  -6.8256,  -5.9527,  -3.5662,\n","          -7.4126,  -5.2680,  -3.7049,  -5.0292,  -6.5258,   0.3661,  -4.9141,\n","          -6.1941,  -8.3663,  -5.9620,  -8.8588,  -9.0553,  -8.8196,  -8.0509,\n","          -5.8675,  -7.0726,  -1.5209,  -8.2371,  -9.4661,  -7.5024,  -8.7965,\n","          -8.4286,  -9.4037,  -9.0452,  -9.5414,  -6.5175,  -7.2260,  -4.8674,\n","          -8.2056,  -8.6362,  -9.6190,  -8.8889,  -9.2784,  -9.1206,  -9.4683,\n","          -9.0494,  -9.4036,  -9.5054,  -9.4490,  -9.3964,  -8.3878,  -8.4926,\n","          -9.3762,  -8.3799,  -6.7678,  -9.3945,  -9.0591, -10.1383,  -9.1545,\n","         -10.1069, -10.2232,  -9.7614,  -9.6377,  -9.7082,  -9.5015,  -9.9271,\n","          -9.9213,  -9.0864,  -9.7806,  -9.7223,  -9.6785,  -8.8306,  -9.3916,\n","          -7.8180,  -9.5880,  -7.4045,  -8.1067,  -4.0951,  -9.2221,  -9.5531,\n","         -10.0764,  -9.9358, -10.1723,  -9.7610, -10.1765,  -9.9229, -10.1753,\n","         -10.2653, -10.1798,  -9.8170, -10.1764,  -9.2960,  -9.6315, -10.0217,\n","          -9.0803,  -9.4032,  -8.7335, -10.0974,  -9.0893,  -8.0518,  -9.7719,\n","          -9.1039, -10.2165, -10.0381, -10.3680, -10.5611, -10.3455, -10.4953,\n","         -10.2869, -10.3419, -10.2671, -10.3820, -10.2590, -10.0916,  -9.5230,\n","          -9.6259,  -8.8964,  -9.8406,  -9.5661, -10.2891,  -9.5963, -10.4264,\n","         -10.6368, -10.5720, -10.8699, -10.4497, -10.1595, -10.4796, -10.2312,\n","         -10.1546,  -8.9384,  -9.5860,  -8.9238,  -9.5334,  -9.2405,  -9.4453,\n","          -5.5996,  -5.6658,  -5.6402,  -5.5409,  -5.5663,  -5.7022,  -5.6681,\n","          -5.6254,  -5.7245,  -5.9952,  -5.7653,  -5.7183,  -5.7100,  -5.6758,\n","          -5.7368,  -5.6683,  -5.6827,  -5.8863,  -5.8030,  -5.7113,  -5.7225,\n","          -5.6971,  -5.7192,  -5.7691,  -5.6946,  -5.6484,  -5.7813,  -5.6668,\n","          -5.6280,  -5.5170,  -5.5329,  -5.6455,  -5.6718,  -5.6272,  -5.5768,\n","          -5.5198,  -5.5326,  -5.4932,  -5.4798,  -5.6413,  -5.6173,  -5.6004,\n","          -5.5255,  -5.3754,  -5.4519,  -5.5061,  -5.5253,  -5.5292,  -5.4420,\n","          -5.5051,  -5.4107,  -5.3485,  -5.4221,  -5.4340,  -5.4995,  -5.5113,\n","          -5.4462,  -5.3912,  -5.3716,  -5.4654,  -5.4613,  -5.5045,  -5.5042,\n","          -5.4913,  -5.5695,  -5.5748,  -5.6041,  -5.5026,  -5.4684,  -5.3706,\n","          -5.5535,  -5.7360,  -5.6753,  -5.5852,  -5.5506,  -5.5060,  -5.5038,\n","          -5.5681,  -5.5959,  -5.5933,  -5.5998,  -5.6107,  -5.5774,  -5.5498,\n","          -5.6022,  -5.6856,  -5.6983,  -5.7573,  -5.7682,  -5.7337,  -5.7059,\n","          -5.7102,  -5.7007,  -5.6617,  -5.6398,  -5.6964,  -5.7109,  -5.7428,\n","          -5.7436,  -5.8206,  -5.7798,  -5.7257,  -5.7431,  -5.7005,  -5.6991,\n","          -5.7724,  -5.7874,  -5.8098,  -5.7045,  -5.7312,  -5.7582,  -5.8839,\n","          -6.6534]]), 'tokenizer_name': 'monologg/koelectra-small-v2-distilled-korquad-384', 'guid': 'e67ed38f3dd944be94d5b4c53731f334'}]\n"]},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["### downloading pickle ###\n","\n","with open('input_ids_and_logits.pickle', 'rb') as handle:\n","    list_dict_all = pickle.load(handle)\n","    print(list_dict_all[0][\"start_logits\"])\n","\n","### downloading pickle ###"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bf71sz8nupsd","executionInfo":{"status":"ok","timestamp":1673405508753,"user_tz":-540,"elapsed":1862,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"924ffec9-0527-4833-fa58-278db3b2bdc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.5115,  0.2288, -4.9412, -5.9033, -4.1217, -3.2736, -7.5873, -7.1568,\n","         -6.6073, -1.3735, -2.3471, -7.4038, -7.1942, -8.4602, -6.7935, -7.2751,\n","         -6.8009,  4.4649,  5.0458,  1.2103,  3.6921, -3.5664, -3.1414, -0.7975,\n","         -2.6163, -4.0001,  1.8790, -4.4590, -7.7809, -7.1812, -7.9790, -6.4454,\n","          0.6724,  4.0979,  3.1321,  4.8998, -0.9844, -1.3978,  0.3366,  0.8822,\n","          3.9530,  3.5037, -1.1915, -2.2816, -0.7325, -2.3441, -3.8921,  2.1452,\n","          2.8504, -2.0891, -3.7333, -4.4564,  0.6263, -2.9716, -4.1664, -3.9551,\n","          0.3231, -3.0926, -4.3894, -3.9628,  1.3553, -2.1750, -3.4298, -3.3669,\n","         -2.6919, -6.7965, -6.4902, -1.4383, -6.9111, -3.3695, -5.6931, -3.3315,\n","         -6.7219, -7.4102, -7.0883,  0.2665, -1.7349, -4.3393, -6.4791, -6.7425,\n","         -4.1272, -4.5313, -6.6087, -7.3083, -0.6621, -6.1877, -6.5420, -4.2792,\n","         -7.6332, -3.9419, -8.2834, -6.2232, -8.6102, -2.7479, -7.4158, -8.9321,\n","         -6.8927, -8.9587, -5.9866, -9.1383, -7.6201, -9.2802, -7.4849, -6.3044,\n","         -9.0975, -9.5414, -7.4844, -9.4883, -7.5879, -8.0420, -7.3955, -0.9534,\n","          4.1339,  0.8251, -4.7544, -2.5840,  1.9203,  0.5142, -4.2515,  3.5921,\n","         -0.8443, -2.1656, -1.2453, -6.2336, -0.5992, -7.1798, -4.9680,  1.3560,\n","         -4.7714, -3.3420, -4.6364, -0.2193, -5.5799, -4.2126, -5.1714, -4.5204,\n","          0.6156, -3.4616, -5.3984, -1.1698, -6.1359, -4.1513, -4.5076, -4.2017,\n","         -7.7192, -5.5148, -7.6235, -7.7159, -6.6173,  1.6805, -4.3677, -6.7097,\n","         -4.7568, -6.8811, -6.2033,  4.1545, -3.8869, -1.9013, -5.3832,  3.8332,\n","          3.7594, -1.7742,  4.7920, -0.4735,  3.7381, -0.3451, -1.4203, -4.0281,\n","         -2.6856, -0.8432, -3.4324, -4.1634, -7.4850, -2.8132, -7.6212, -4.4986,\n","         -8.2819, -3.8997, -7.7534, -3.3220, -7.9719, -1.2640, -7.2714, -8.7865,\n","         -5.9770, -8.9320, -7.2765, -8.7768, -8.1151, -8.9605, -6.6794, -8.4464,\n","         -7.4332, -5.6933,  4.1786,  1.8233, -0.4738, -1.4498, -4.8632, -3.3516,\n","         -5.0554, -4.5817,  4.6663, -0.7579, -5.0888,  4.0344, -2.0153,  5.1098,\n","         -0.7935,  2.8179, -0.1526, -2.0168, -4.9035, -3.4655, -0.5893, -3.0483,\n","         -3.8360, -5.3589, -7.0189, -5.7038, -1.2621, -6.9586, -7.4159, -6.0592,\n","         -8.9406, -4.3946, -8.0263, -9.0073, -6.3870, -8.8204, -7.4646, -5.1506,\n","          6.5422,  4.5023, -1.7286,  5.9640,  1.6690, -0.2638, -0.0173,  0.0455,\n","          2.4449, -3.9672, -1.4378, -0.3145, -1.5266,  5.7068, -1.9199,  1.8072,\n","         -2.8781, -3.6541, -5.1201, -0.7398, -2.9613, -5.6375, -2.4100, -5.0798,\n","         -4.8921, -4.4313,  1.6278, -3.2383,  0.6102, -4.4585, -4.4754, -0.8423,\n","         -2.4326,  6.6816, -0.2326,  3.4859, -2.0413, -2.9374, -4.4545, -1.5795,\n","         -5.5526, -3.3014, -5.9876, -4.2264, -8.6567, -5.8296, -8.3949, -5.0087,\n","         -8.3212, -6.3269, -7.4195, -8.6178, -6.6659, -3.9659, -2.1873, -7.5037,\n","         -2.3542, -5.9777, -8.0001, -5.0160, -8.1633, -3.9356, -8.0424, -8.8813,\n","         -6.4973, -6.3908, -4.5652,  6.9727,  5.0143, -1.6154,  5.9593,  1.2218,\n","         -0.4630,  0.0235, -0.1868,  1.9666, -4.2144, -1.3799, -0.7888, -1.0953,\n","          6.7217,  4.6918,  1.2967, -1.4742,  5.7943,  1.6493, -0.4019,  0.0459,\n","         -3.7573, -2.0216, -1.5356, -3.8536,  4.7859,  0.7410, -1.2033, -5.3680,\n","         -2.2066, -4.2328, -4.0384, -2.7920,  7.4224,  5.6085, -1.4129, -1.5507,\n","          6.3976,  3.1679,  0.6910,  0.9480,  4.0876,  6.0587, -0.5223,  0.8476,\n","          0.0833, -0.7661,  4.7291, -2.8736, -2.5145,  2.3429,  1.4975, -1.7513,\n","         -5.6778, -3.4010, -5.2792, -4.4551, -3.1236,  2.5005, -6.6782, -6.3573,\n","         -6.3540,  4.3742, -5.4368, -6.7989, -0.6450, -6.2910, -1.3494, -6.6361,\n","         -3.6247, -7.0307, -5.9472,  4.8333, -2.6290, -2.5706,  2.4321, -0.0367,\n","         -5.1774,  1.4265, -4.5093, -7.0204, -4.9647, -6.4706, -5.4453,  4.4356,\n","          3.3346, -4.6173, -2.3753, -5.1163, -5.6100, -4.1952, -7.0435, -5.8335,\n","         -3.1898,  7.0044,  5.3359, -2.0001,  4.4866, -2.7071, -2.2415, -2.7594,\n","          4.7004,  0.0203, -1.8656,  4.7427, -0.3671, -0.4505, -0.0669,  0.5045,\n","          3.0937, -3.1254, -0.3118, -0.9855, -2.6830, -2.8274, -7.5049, -5.6870,\n","         -8.9330, -6.0859, -8.6615, -0.2336, -7.3642, -6.5391, -6.5555, -6.6934,\n","         -8.9038, -7.0191, -9.0970, -7.4595, -7.5445,  3.4024, -2.9024, -5.3994,\n","         -2.5392, -4.3165, -7.4683, -4.6877, -7.1036, -6.3479, -5.8623, -6.7495,\n","          2.0392, -4.6660, -5.5934, -5.2587, -8.3176,  0.3636,  0.4091, -6.0880,\n","          1.2179, -3.2900, -0.3059, -4.5160, -4.1429, -6.9412, -5.1870, -8.5382,\n","         -6.3619, -8.7665, -8.8848, -8.1667, -8.3606, -7.6652, -6.5119, -9.3143,\n","         -9.5343, -9.7197, -8.7970, -9.8278, -8.6597, -9.6011, -9.1416, -9.1808,\n","         -7.8329, -7.3796, -4.6422, -8.1518, -7.2562, -7.9972, -7.7875, -7.5800,\n","         -7.0312, -8.9521, -8.0384, -8.7110, -6.4047, -8.6534, -7.9533, -7.8347,\n","         -3.7006, -3.6890, -3.7721, -3.9014, -3.1493, -3.5434, -3.4201, -3.5497,\n","         -3.8646, -4.5967, -4.5387, -3.8711, -3.1963, -3.3167, -3.3150, -3.0680,\n","         -2.8465, -3.3488, -3.1402, -2.6315, -2.3204, -2.2653, -2.3607, -1.5134]])\n","\n"]}]},{"cell_type":"code","source":["import csv\n","f = open('monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv','w', newline='')\n","wr = csv.writer(f)\n","wr.writerow(['Id','Predicted'])\n","\n","for tp in pred_answers:\n","    wr.writerow([tp[0],tp[1]])\n","\n","f.close()"],"metadata":{"id":"-Es9B1ZFjMbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Levenshtein_distance (Evaluation)\n","\n","import numpy \n","import torch\n","import os\n","\n","def levenshtein_distance(s1,s2, debug=False): #레벤슈타인 거리 eval / 정답 s1과 도출한 모델 s2 비교 평가\n","    if len(s1) < len(s2):\n","        return levenshtein_distance(s2, s1, debug)\n","\n","    if len(s2) == 0:\n","        return len(s1)\n","\n","    previous_row = range(len(s2) + 1)\n","    for i, c1 in enumerate(s1):\n","        current_row = [i + 1]\n","        for j, c2 in enumerate(s2):\n","            insertions = previous_row[j + 1] + 1\n","            deletions = current_row[j] + 1\n","            substitutions = previous_row[j] + (c1 != c2)\n","            current_row.append(min(insertions, deletions, substitutions))\n","\n","        if debug:\n","            print(current_row[1:])\n","\n","        previous_row = current_row\n","\n","    return previous_row[-1] # levenshtein_distance 값 출력력\n","\n","\n","def LD_SCORE(start_positions, end_positions, input_ids, STA_logits, END_logits):\n","\n","    answer1 = [] # 정답 저장\n","    answer2 = [] # 예측 정답 저장\n","\n","    if len(input_ids) != BATCH_SIZE: #오류 해결\n","       print(\"input_ids ERROR\")\n","       return 0\n","\n","    for i in range(BATCH_SIZE): # 기존 정답 // index 1 is out of bounds for dimension 0 with size 1 오류 발생\n","        if input_ids[i] == [] :\n","            print(\"input_ids ERROR\")\n","            continue       \n","        else:\n","            PRED_IDE = input_ids[i][start_positions[i]: end_positions[i] + 1]\n","            PRED_ANS = tokenizer.decode(PRED_IDE)\n","            answer1.append(PRED_ANS)\n","            #print(PRED_ANS)\n","\n","    for i in range(BATCH_SIZE): # 예측 정답\n","        if input_ids[i] == [] :\n","            print(\"input_ids ERROR\")\n","            continue\n","        else:\n","            TK_start_index, TK_end_index = STA_logits.argmax(dim=-1), END_logits.argmax(dim=-1)\n","            PRED_IDE2 = input_ids[i][TK_start_index[i]: TK_end_index[i] + 1]\n","            PRED_ANS2 = tokenizer.decode(PRED_IDE2)\n","            answer2.append(PRED_ANS2)\n","            # print(PRED_ANS2)\n","\n","    batch_score = LD_comparison(answer1, answer2)\n","\n","    return batch_score\n","\n","\n","def LD_comparison(answer1,answer2):\n","\n","    # 배치마다 레벤슈타인 거리 평균 구해서 출력. (train, valid 과정에서 배치마다 평균거리 구하고.)\n","    # train 전체 평균 거리\n","    # valid 전체 평균 거리\n","\n","    batch_LD_score = []\n","\n","    for i in range(BATCH_SIZE):\n","        if answer1[i] == answer2[i]: # 같으면 LD 구하는 과정 생략.\n","            batch_LD_score.append(0)\n","        else:\n","            batch_LD_score.append(levenshtein_distance(answer1[i],answer2[i]))\n","\n","    sum_LD_score = sum(batch_LD_score)\n","    LD_avg = sum_LD_score / BATCH_SIZE # 배치의 레벤슈타인 거리 평균\n","    print(LD_avg)\n","\n","    return LD_avg\n","\n","\n","\n","'''\n","levenshtein_distance 값이 튀는 현상 방지.\n"," - 길이가 너무 긴 정답 삭제 max_length = 20\n"," - 정답과 어느정도 길이차이나는 값 삭제(위와 동일) 5.9 -> 2정도 차이나는 값 삭제 7.9\n"," \n","\n","자연어처리\n","자연어처리과정 2\n","0 5\n","\n","정답 길이보다 예측 정답 길이가 길지만 2배이상 차이가 나지 않는 경우에\n","0으로 처리하면 LD_SCORE가 더 안나옴\n","따라서 위 상황에서는 1.5 ~ 1.8 정도 해당하는 길이로 잘라서 반환.\n","\n","test 답 X\n","train 과정 나온 답 -> 바꿔서 바꾼 데이터로 \n","\n","\n","** max_len = 5.9 * 2 = 12\n","\n","train 2번\n","1 train 원래 데이터.\n","2 train LD 변환한 데이터로 한번.\n","\n","'''\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"znO7xNhXh-JG","executionInfo":{"status":"ok","timestamp":1673335090019,"user_tz":-540,"elapsed":21,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"b687fe62-0979-4f7d-a735-c70ff4f0fce4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nlevenshtein_distance 값이 튀는 현상 방지.\\n - 길이가 너무 긴 정답 삭제 max_length = 20\\n - 정답과 어느정도 길이차이나는 값 삭제(위와 동일) 5.9 -> 2정도 차이나는 값 삭제 7.9\\n \\n\\n자연어처리\\n자연어처리과정 2\\n0 5\\n\\n정답 길이보다 예측 정답 길이가 길지만 2배이상 차이가 나지 않는 경우에\\n0으로 처리하면 LD_SCORE가 더 안나옴\\n따라서 위 상황에서는 1.5 ~ 1.8 정도 해당하는 길이로 잘라서 반환.\\n\\ntest 답 X\\ntrain 과정 나온 답 -> 바꿔서 바꾼 데이터로 \\n\\n\\n** max_len = 5.9 * 2 = 12\\n\\ntrain 2번\\n1 train 원래 데이터.\\n2 train LD 변환한 데이터로 한번.\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["# pred_answers에서 도출한 정답 비교\n","import csv\n","\n","def calculate_Leven(source, ref, result_file):\n","    with open(source, 'r') as input1:\n","        with open(ref, 'r') as input2:\n","            with open(result_file, 'w') as csvoutput:\n","                reader1 = csv.reader(input1)\n","                reader2 = list(csv.reader(input2))\n","                writer = csv.writer(csvoutput)\n","                result = []\n","                mean = []\n","                headers = next(reader1)\n","                result.append(headers)\n","                index = 0\n","                for row1 in reader1:\n","                    #print(\"First row\")\n","                    #print(row1[1])\n","                    index+=1\n","                    #print(reader2[index][1])\n","                    a = levenshtein_distance(row1[1], reader2[index][1])\n","                    #print(row1[1],'////',reader2[index][1])\n","                    '''\n","                    max = 0\n","                    while max < 1:\n","                        for row2 in reader2:\n","                            a = distance(row1[1],row2[1])\n","                            print(a)\n","                            b = 1 - a/len(row1[1])\n","                            if b > max:\n","                                max = b\n","                                SKU = row2[1]\n","                    '''\n","                    mean.append(a)\n","                    row1.append(a)\n","                    result.append(row1)\n","                mean1 = sum(mean) / len(mean)\n","                print(mean1)\n","                writer.writerows(result)"],"metadata":{"id":"vPg9ohQOiQ-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":184},"id":"idYSu_idiRt1","executionInfo":{"status":"ok","timestamp":1673335169335,"user_tz":-540,"elapsed":49724,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"5d1ceff6-1cd5-4ffa-b802-3ce618fa733e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-bf7cce49-70fc-4b6c-989d-72ab3d324749\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-bf7cce49-70fc-4b6c-989d-72ab3d324749\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving ainize_klue-bert-base-mrc.csv to ainize_klue-bert-base-mrc.csv\n","Saving ainize_klue-bert-base-mrc_10truncation_real.csv to ainize_klue-bert-base-mrc_10truncation_real.csv\n","Saving ainize_klue-bert-base-mrc-10truncation.csv to ainize_klue-bert-base-mrc-10truncation.csv\n","Saving klue_10trunc_postprocess.csv to klue_10trunc_postprocess.csv\n"]}]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc_LogitPRED.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acfGFS9_iioA","executionInfo":{"status":"ok","timestamp":1673335094560,"user_tz":-540,"elapsed":481,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"d6f5e65c-f054-4518-911f-d2632699b959"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.290668662674651\n"]}]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9r2Xca6Vi5ZB","executionInfo":{"status":"ok","timestamp":1673335219372,"user_tz":-540,"elapsed":21,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"95ac9286-6135-465e-e469-556dda4d9588"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11.175399201596806\n"]}]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc_10truncation_real.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ne9qu_j7jBjh","executionInfo":{"status":"ok","timestamp":1673335219373,"user_tz":-540,"elapsed":14,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"5cd2ddfb-283a-46fc-ba63-7e5bf9411ff3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.7564870259481036\n"]}]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc-10truncation.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XM5queVvjCIj","executionInfo":{"status":"ok","timestamp":1673335219374,"user_tz":-540,"elapsed":10,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"120f3036-c2ad-4dec-8145-d015ee6e43f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.042165668662675\n"]}]},{"cell_type":"code","source":["calculate_Leven('klue_10trunc_postprocess.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RObH3voEjCnf","executionInfo":{"status":"ok","timestamp":1673335220835,"user_tz":-540,"elapsed":12,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"5d1ff765-1809-44eb-f7c2-b50d6f0aabd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.7926646706586826\n"]}]}]}