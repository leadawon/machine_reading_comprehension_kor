{"cells":[{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"jqSvDBCcOD5J","executionInfo":{"status":"error","timestamp":1673414856591,"user_tz":-540,"elapsed":6702,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"f8364d70-4212-48e7-a49f-5b6e26997944"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-0e021dae-8744-4e59-aaa3-ff0a3c84f43c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-0e021dae-8744-4e59-aaa3-ff0a3c84f43c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   \"\"\"\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    145\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    146\u001b[0m           input_id=input_id, output_id=output_id))\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"s4_sULZvOP0d","executionInfo":{"status":"aborted","timestamp":1673414856594,"user_tz":-540,"elapsed":12,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4euzcqrOuMh","executionInfo":{"status":"aborted","timestamp":1673414856595,"user_tz":-540,"elapsed":11,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"I5JxfHVARuja"},"source":["## gogo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yskKCUsOuIw"},"outputs":[],"source":["tokenizer_name = 'snunlp/KR-Medium'\n","model_name = 'snunlp/KR-Medium'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQr5Ivl7OuGZ"},"outputs":[],"source":["import json\n","import random\n","\n","import torch\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kXdeER8O9Jp"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qS8G0_kBhMhW"},"outputs":[],"source":["import re\n","def remove_post(text):\n","        ''' 불필요한 기호 제거 '''\n","        text = text.strip()\n","        text = re.sub(\"'\", \"\", text)\n","        text = re.sub('\"', \"\", text)\n","        text = re.sub('《', \"\", text)\n","        text = re.sub('》', \"\", text)\n","        text = re.sub('<', \"\", text)\n","        text = re.sub('>', \"\", text)\n","        text = re.sub('〈', \"\", text)\n","        text = re.sub('〉', \"\", text)\n","        text = re.sub(\"\\(\", \"\", text)\n","        text = re.sub(\"\\)\", \"\", text)\n","        text = re.sub(\"‘\", \"\", text)\n","        text = re.sub(\"’\", \"\", text)\n","        text = re.sub(\"  \", \" \", text)\n","        text = re.sub(\"#\", \"\", text)\n","        return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HmQRZQp1NKT"},"outputs":[],"source":["'''\n","idea  \n","틀린 답을 바로 빈칸으로 내보내는게 과연 이득일까?\n","logit 확률값을 적용해서 틀린답이면 다음으로 높은 확률값이 정답일수도 있지않을까?\n","top 5의 확률값을 다 적용해도 틀린 답이라면 그때 빈칸을 내보내도 괜찮을듯.\n","'''\n","# start, end logit의 확률값을 이용한 예측 정답값\n","# logit의 상위 5개 확률을 리스트로 뽑아 틀린 정답이었다면 다음 확률로 넘어가서 확인.\n","\n","def to_list(tensor):\n","    return tensor.detach().cpu().tolist()\n","\n","def logits_change(input_ids, STA_logits, END_logits):\n","\n","    # 로짓의 확률값 ~ 상위 5개를 선택 \n","    # 틀린 추론이었다면 다음 선택 (틀린 추론 : start > end, 길이가 너무 긴 문장.)\n","    change_logit = 0\n","    cnt = 0\n","    \n","    # 기존 정답\n","    save_s = STA_logits\n","    save_e = END_logits\n","\n","    STK_start_index, STK_end_index = save_s.argmax(dim=-1), save_e.argmax(dim=-1)\n","    save_pred_ids = tokenizer.decode(input_ids[0][STK_start_index: STK_end_index + 1])\n","    #print(save_pred_ids) \n","\n","    # 바뀐 정답\n","    # Tensor형태의 logit의 확률값을 리스트로 만들어줌 \n","    STA_logits = to_list(STA_logits)[0]\n","    END_logits = to_list(END_logits)[0]\n","\n","    # 리스트로 만든 확률값 -> 큰 순서대로 정렬 + 인덱스 \n","    start_idx_and_logit = sorted(enumerate(STA_logits), key=lambda x: x[1], reverse=True)\n","    end_idx_and_logit = sorted(enumerate(END_logits), key=lambda x: x[1], reverse=True)\n","\n","    # 확률값 큰 순서대로 Top 5 \n","    start_idx_and_logit = start_idx_and_logit[:5]\n","    end_idx_and_logit = end_idx_and_logit[:5]\n","\n","    TK_start_index, TK_end_index = start_idx_and_logit, end_idx_and_logit\n","\n","    # 확률이 높은 순서대로 점검. 틀린 값이면 다음 확률로 넘어가고 맞는 답이면 저장후 반복문 종료\n","    for i in range(5):\n","        if TK_start_index[i][0] > TK_end_index[i][0] or TK_end_index[i][0] - TK_start_index[i][0] > 10 : \n","            cnt += 1\n","            continue\n","        else : \n","            change_logit += 1\n","            pred_ids = input_ids[0][TK_start_index[i][0]: TK_end_index[i][0] + 1]\n","            pred_ids = tokenizer.decode(pred_ids)\n","            #print(pred_ids, 'change')\n","            break\n","\n","    if change_logit == 0 :\n","        return save_pred_ids\n","    elif cnt == 5:\n","        return ''\n","    else : \n","        if pred_ids == save_pred_ids:\n","            #print('same answer')\n","            return pred_ids\n","        else :\n","            #print('different answer')\n","            return pred_ids\n","\n","    \n","\n","# start_logits , end_logits\n","# index를 추적하면서 시작, 종료 index에 대한 확률이 가장 높은것을 선택하는 방법.\n","# 만약에 차이가 큰 start, end 값을 반환할때 이 정보들을 저장하지 않고 넘긴다면? \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXMI6CaEmKlM"},"outputs":[],"source":["# pred_answers에서 도출한 정답 비교\n","import csv\n","\n","def calculate_Leven(source, ref, result_file):\n","    with open(source, 'r') as input1:\n","        with open(ref, 'r') as input2:\n","            with open(result_file, 'w') as csvoutput:\n","                reader1 = csv.reader(input1)\n","                reader2 = list(csv.reader(input2))\n","                writer = csv.writer(csvoutput)\n","                result = []\n","                mean = []\n","                headers = next(reader1)\n","                result.append(headers)\n","                index = 0\n","                for row1 in reader1:\n","                    #print(\"First row\")\n","                    #print(row1[1])\n","                    index+=1\n","                    #print(reader2[index][1])\n","                    a = levenshtein_distance(row1[1], reader2[index][1])\n","                    print(row1[1],'////',reader2[index][1])\n","                    '''\n","                    max = 0\n","                    while max < 1:\n","                        for row2 in reader2:\n","                            a = distance(row1[1],row2[1])\n","                            print(a)\n","                            b = 1 - a/len(row1[1])\n","                            if b > max:\n","                                max = b\n","                                SKU = row2[1]\n","                    '''\n","                    mean.append(a)\n","                    row1.append(a)\n","                    result.append(row1)\n","                mean1 = sum(mean) / len(mean)\n","                print(mean1)\n","                writer.writerows(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKbGAvSZmRyu"},"outputs":[],"source":["calculate_Leven('klue.csv', 'sangrimlee_bert-base-multilingual-cased-korquad_validation_pred_truncation.csv', 'result_file.csv')"]},{"cell_type":"code","source":["# logit 값에 대한 soft voting - 3 model\n","\n","def to_list(tensor):\n","    return tensor.detach().cpu().tolist()\n","\n","def logits_voting(A_model, B_model, C_model):\n","    # 각 모델마다 input_ids, start_logits, end_logits값 저장. 순서대로 저장 리스트에 + guids // context 필요.\n","    # 모델 logit 확률 top 5 구해서 모델 1 top1 모델 2 top1 모델3 top1 모델1 top2 순으로 체크.\n","    # print(list_dict_all[0][\"start_logits\"]) pickle\n","    # A_model\n","\n","    ind = 0\n","    RESULT = []\n","\n","    if len(A_model)!= len(B_model) or len(A_model) != len(C_model) or len(B_model) != len(C_model):\n","        print('error')\n","    else:\n","        llogit = len(A_model)\n","\n","    while 1:\n","        # input_ids\n","        A_input_ids = A_model[ind]['input_ids']\n","        B_input_ids = B_model[ind]['input_ids']\n","        C_input_ids = C_model[ind]['input_ids']\n","\n","        # guid\n","        A_guid = A_model[ind]['guid']\n","        B_guid = A_model[ind]['guid']\n","        C_guid = A_model[ind]['guid']\n","\n","        if A_input_ids != B_input_ids or B_input_ids != C_input_ids or A_input_ids != C_input_ids:\n","            print('input_error')\n","        if A_guid != B_guid or B_guid != C_guid or A_guid != C_guid:\n","            print('guid_error')\n","\n","        # logit 값 순서대로 불러오기기\n","        A_start_logit = A_model[ind]['start_logits']\n","        A_end_logit = A_model[ind]['end_logits']\n","        B_start_logit = B_model[ind]['start_logits']\n","        B_end_logit = B_model[ind]['end_logits']\n","        C_start_logit = C_model[ind]['start_logits']\n","        C_end_logit = C_model[ind]['end_logits']\n","\n","        # 로짓값 -> 확률 큰 순서대로 리스트형태 + 인덱스 -> top 5 자르기기\n","        A_start_idx_and_logit = (sorted(enumerate(A_start_logit), key=lambda x: x[1], reverse=True))[:5]\n","        A_end_idx_and_logit = (sorted(enumerate(A_end_logit), key=lambda x: x[1], reverse=True))[:5]\n","        B_start_idx_and_logit = (sorted(enumerate(B_start_logit), key=lambda x: x[1], reverse=True))[:5]\n","        B_end_idx_and_logit = (sorted(enumerate(B_end_logit), key=lambda x: x[1], reverse=True))[:5]\n","        C_start_idx_and_logit = (sorted(enumerate(C_start_logit), key=lambda x: x[1], reverse=True))[:5]\n","        C_end_idx_and_logit = (sorted(enumerate(C_end_logit), key=lambda x: x[1], reverse=True))[:5]\n","\n","\n","        cnt = 0\n","        for i in range(5):\n","            # 모델 A, B, C 에 대한 각각의 로짓값 저장해서 확률 5 리스트로 저장 후 비교.\n","            # A->B->C->A 순? A2 > B1 ? 어떤 순서대로 비교할건지 \n","            # 정답인 경우 멈추고 값 저장 후 종료\n","            # 토크나이저 다 다른데 어떻게 비교함? -> 정답 context \n","            # soft voting -> start + end 확률값 더해서 순위대로 정렬 후 정답인지 확인 -> 정답일때는 해당 모델에 대한 input 불러와서 answer, guid 저장.\n","\n","            if A_start_idx_and_logit[i][0] < A_end_idx_and_logit[i][0] or A_end_idx_and_logit[i][0] - A_start_idx_and_logit[i][0] <= 10 : \n","                cnt += 1\n","                pred_ids = A_input_ids[A_start_idx_and_logit[i][0]: A_end_idx_and_logit[i][0] + 1] # 해당 정답에 대한 인덱스 ~> context 변환 하는 과정 필요.\n","                # 토큰 -> 정답 변경.\n","                A_token = A_model['tokenizer_name'] # 저장형태 확인 // 근데 이렇게하면 decode가 되나? 해봐야 될듯?\n","                tokenizer = AutoTokenizer.from_pretrained(A_token)\n","                pred_ids = tokenizer.decode(pred_ids)\n","                guid = A_guid\n","                break\n","\n","            elif B_start_idx_and_logit[i][0] < B_end_idx_and_logit[i][0] or B_end_idx_and_logit[i][0] - B_start_idx_and_logit[i][0] <= 10 : \n","                cnt += 1\n","                pred_ids = B_input_ids[B_start_idx_and_logit[i][0]: B_end_idx_and_logit[i][0] + 1]\n","                B_token = B_model['tokenizer_name']\n","                tokenizer = AutoTokenizer.from_pretrained(B_token)\n","                pred_ids = tokenizer.decode(pred_ids)\n","                guid = B_guid\n","                break\n","\n","            elif C_start_idx_and_logit[i][0] < C_end_idx_and_logit[i][0] or C_end_idx_and_logit[i][0] - C_start_idx_and_logit[i][0] <= 10 : \n","                cnt += 1\n","                pred_ids = C_input_ids[C_start_idx_and_logit[i][0]: C_end_idx_and_logit[i][0] + 1]\n","                C_token = C_model['tokenizer_name']\n","                tokenizer = AutoTokenizer.from_pretrained(C_token)\n","                pred_ids = tokenizer.decode(pred_ids)\n","                guid = C_guid\n","                break\n","\n","\n","                 \n","\n","        # guids??? 저장해야함.\n","        if cnt == 0:\n","           tp = (guid,'')\n","           RESULT.append(tp)\n","        else:\n","           tp = (guid,pred_ids)\n","           RESULT.append(tp)\n","\n","        if llogit == ids:\n","            break\n","        ids += 1\n","\n","    return RESULT\n","            # 1 23 맞는 정답만 도출.\n","\n","\n"],"metadata":{"id":"zbHhanYXUDpY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### downloading pickle ###\n","import pickle\n","\n","with open('input_ids_and_logits.pickle1111', 'rb') as handle:\n","    pickle1 = pickle.load(handle)\n","\n","with open('input_ids_and_logits.pickle2222', 'rb') as handle:\n","    pickle2 = pickle.load(handle)\n","\n","with open('input_ids_and_logits.pickle3333', 'rb') as handle:\n","    pickle3 = pickle.load(handle)\n","    "],"metadata":{"id":"3SZw4RHSZvzn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JWLboBIRomqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77},"id":"HdHPKA55U_Ae","executionInfo":{"status":"ok","timestamp":1673416007172,"user_tz":-540,"elapsed":636652,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"1f8696a2-971b-4eb3-a009-bdda3e94be8b"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-462471dd-2210-45a9-b9db-1d8bb4228301\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-462471dd-2210-45a9-b9db-1d8bb4228301\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving input_ids_and_logits.pickle to input_ids_and_logits.pickle\n"]}]},{"cell_type":"code","source":["pred_answers = logits_voting(pickle1,pickle2,pickle3)"],"metadata":{"id":"8jLDGeKWt7b3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pred_answers[:10])"],"metadata":{"id":"995Gi4Lqt7_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import csv\n","f = open('voting1.csv','w', newline='')\n","wr = csv.writer(f)\n","wr.writerow(['Id','Predicted'])\n","\n","for tp in pred_answers:\n","    wr.writerow([tp[0],tp[1]])\n","\n","f.close()"],"metadata":{"id":"e93WvAIdaL_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 레벤슈타인거리 함수\n","# pred_answers에서 도출한 정답 비교\n","import csv\n","\n","def calculate_Leven(source, ref, result_file):\n","    with open(source, 'r') as input1:\n","        with open(ref, 'r') as input2:\n","            with open(result_file, 'w') as csvoutput:\n","                reader1 = csv.reader(input1)\n","                reader2 = list(csv.reader(input2))\n","                writer = csv.writer(csvoutput)\n","                result = []\n","                mean = []\n","                headers = next(reader1)\n","                result.append(headers)\n","                index = 0\n","                for row1 in reader1:\n","                    #print(\"First row\")\n","                    #print(row1[1])\n","                    index+=1\n","                    #print(reader2[index][1])\n","                    a = levenshtein_distance(row1[1], reader2[index][1])\n","                    #print(row1[1],'////',reader2[index][1])\n","                    '''\n","                    max = 0\n","                    while max < 1:\n","                        for row2 in reader2:\n","                            a = distance(row1[1],row2[1])\n","                            print(a)\n","                            b = 1 - a/len(row1[1])\n","                            if b > max:\n","                                max = b\n","                                SKU = row2[1]\n","                    '''\n","                    mean.append(a)\n","                    row1.append(a)\n","                    result.append(row1)\n","                mean1 = sum(mean) / len(mean)\n","                print(mean1)\n","                writer.writerows(result)\n","\n","# Levenshtein_distance (Evaluation)\n","\n","import numpy \n","import torch\n","import os\n","\n","def levenshtein_distance(s1,s2, debug=False): #레벤슈타인 거리 eval / 정답 s1과 도출한 모델 s2 비교 평가\n","    if len(s1) < len(s2):\n","        return levenshtein_distance(s2, s1, debug)\n","\n","    if len(s2) == 0:\n","        return len(s1)\n","\n","    previous_row = range(len(s2) + 1)\n","    for i, c1 in enumerate(s1):\n","        current_row = [i + 1]\n","        for j, c2 in enumerate(s2):\n","            insertions = previous_row[j + 1] + 1\n","            deletions = current_row[j] + 1\n","            substitutions = previous_row[j] + (c1 != c2)\n","            current_row.append(min(insertions, deletions, substitutions))\n","\n","        if debug:\n","            print(current_row[1:])\n","\n","        previous_row = current_row\n","\n","    return previous_row[-1] # levenshtein_distance 값 출력력\n","\n","\n","def LD_SCORE(start_positions, end_positions, input_ids, STA_logits, END_logits):\n","\n","    answer1 = [] # 정답 저장\n","    answer2 = [] # 예측 정답 저장\n","\n","    if len(input_ids) != BATCH_SIZE: #오류 해결\n","       print(\"input_ids ERROR\")\n","       return 0\n","\n","    for i in range(BATCH_SIZE): # 기존 정답 // index 1 is out of bounds for dimension 0 with size 1 오류 발생\n","        if input_ids[i] == [] :\n","            print(\"input_ids ERROR\")\n","            continue       \n","        else:\n","            PRED_IDE = input_ids[i][start_positions[i]: end_positions[i] + 1]\n","            PRED_ANS = tokenizer.decode(PRED_IDE)\n","            answer1.append(PRED_ANS)\n","            #print(PRED_ANS)\n","\n","    for i in range(BATCH_SIZE): # 예측 정답\n","        if input_ids[i] == [] :\n","            print(\"input_ids ERROR\")\n","            continue\n","        else:\n","            TK_start_index, TK_end_index = STA_logits.argmax(dim=-1), END_logits.argmax(dim=-1)\n","            PRED_IDE2 = input_ids[i][TK_start_index[i]: TK_end_index[i] + 1]\n","            PRED_ANS2 = tokenizer.decode(PRED_IDE2)\n","            answer2.append(PRED_ANS2)\n","            # print(PRED_ANS2)\n","\n","    batch_score = LD_comparison(answer1, answer2)\n","\n","    return batch_score\n","\n","\n","def LD_comparison(answer1,answer2):\n","\n","    # 배치마다 레벤슈타인 거리 평균 구해서 출력. (train, valid 과정에서 배치마다 평균거리 구하고.)\n","    # train 전체 평균 거리\n","    # valid 전체 평균 거리\n","\n","    batch_LD_score = []\n","\n","    for i in range(BATCH_SIZE):\n","        if answer1[i] == answer2[i]: # 같으면 LD 구하는 과정 생략.\n","            batch_LD_score.append(0)\n","        else:\n","            batch_LD_score.append(levenshtein_distance(answer1[i],answer2[i]))\n","\n","    sum_LD_score = sum(batch_LD_score)\n","    LD_avg = sum_LD_score / BATCH_SIZE # 배치의 레벤슈타인 거리 평균\n","    print(LD_avg)\n","\n","    return LD_avg\n","\n","\n","\n","'''\n","levenshtein_distance 값이 튀는 현상 방지.\n"," - 길이가 너무 긴 정답 삭제 max_length = 20\n"," - 정답과 어느정도 길이차이나는 값 삭제(위와 동일) 5.9 -> 2정도 차이나는 값 삭제 7.9\n"," \n","\n","자연어처리\n","자연어처리과정 2\n","0 5\n","\n","정답 길이보다 예측 정답 길이가 길지만 2배이상 차이가 나지 않는 경우에\n","0으로 처리하면 LD_SCORE가 더 안나옴\n","따라서 위 상황에서는 1.5 ~ 1.8 정도 해당하는 길이로 잘라서 반환.\n","\n","test 답 X\n","train 과정 나온 답 -> 바꿔서 바꾼 데이터로 \n","\n","\n","** max_len = 5.9 * 2 = 12\n","\n","train 2번\n","1 train 원래 데이터.\n","2 train LD 변환한 데이터로 한번.\n","\n","'''\n","\n"],"metadata":{"cellView":"form","id":"_nvbRG4uaaeR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"QrKmcyl_aebQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc_LogitPRED.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"id":"adM7w3vbaQJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"id":"bJWP6I4LaS8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc_10truncation_real.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"id":"WbnxGJ0paUmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_Leven('ainize_klue-bert-base-mrc-10truncation.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"id":"AaAsKSL7aWbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_Leven('klue_10trunc_postprocess.csv', 'monologg_koelectra-small-v2-distilled-korquad-384_Logitpred_8trunc.csv', 'result_file.csv')"],"metadata":{"id":"EWolmtQcaYIM"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"torch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"c044c91b12eb47f047c895d462d020aa8e4307e7bfafc2c2e5cdad580c7ef67a"}}},"nbformat":4,"nbformat_minor":0}