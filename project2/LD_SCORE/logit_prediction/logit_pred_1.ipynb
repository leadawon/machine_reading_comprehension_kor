{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5gUu-qOx95"
      },
      "source": [
        "## Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "LAL888NDOj2V",
        "outputId": "5b7e4513-5194-4074-fd1f-077e37af2a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0bf42d8c-8feb-4397-80a2-b53ab9024056\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0bf42d8c-8feb-4397-80a2-b53ab9024056\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"jeonhyotaek\",\"key\":\"d2ddaf4c586e0bf63051e1a4c6a74dd4\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNoJ4AkSOuVI",
        "outputId": "a64975ac-01df-4f83-fa2b-ab896bd056e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ],
      "source": [
        "ls -1ha kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qU0E6zxLOuTa"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4LYW2I4OuRD",
        "outputId": "adb1ced1-686c-471b-9c17-1da3676b01fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading 6th-goorm-project-2-korean-mrc.zip to /content\n",
            " 33% 5.00M/15.3M [00:00<00:00, 28.1MB/s]\n",
            "100% 15.3M/15.3M [00:00<00:00, 69.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c 6th-goorm-project-2-korean-mrc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qDBFgn5OuOx",
        "outputId": "7b13c92b-d028-4368-c456-d2e9b77bb581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  6th-goorm-project-2-korean-mrc.zip\n",
            "  inflating: baseline.csv            \n",
            "  inflating: blank.csv               \n",
            "  inflating: test.json               \n",
            "  inflating: train.json              \n"
          ]
        }
      ],
      "source": [
        "!unzip 6th-goorm-project-2-korean-mrc.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkiNxKnFO05Z"
      },
      "source": [
        "## data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4euzcqrOuMh",
        "outputId": "c497d575-221a-425c-a216-cddec2f578a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5JxfHVARuja"
      },
      "source": [
        "## gogo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_yskKCUsOuIw"
      },
      "outputs": [],
      "source": [
        "tokenizer_name = \"monologg/koelectra-small-v2-distilled-korquad-384\"\n",
        "model_name = \"monologg/koelectra-small-v2-distilled-korquad-384\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "DQr5Ivl7OuGZ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkWsSNujOuER",
        "outputId": "03832fb2-0ca4-4880-923b-e99eb9a12141"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': '제주도 장마 시작 … 중부는 이달 말부터',\n",
              " 'paragraphs': [{'context': '올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.',\n",
              "   'qas': [{'question': '북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?',\n",
              "     'answers': [{'text': '한 달가량', 'answer_start': 478},\n",
              "      {'text': '한 달', 'answer_start': 478}],\n",
              "     'guid': '798db07f0b9046759deed9d4a35ce31e'}]}],\n",
              " 'news_category': '종합',\n",
              " 'source': 'hankyung'}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "with open(\"train.json\", 'rb') as f:\n",
        "    input_dict = json.load(f)\n",
        "input_dict[\"data\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DxIyRfTOuCI",
        "outputId": "fef12f1b-d996-4525-e6ee-9c6eb29c3ca9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': '부산정보산업진흥원, 과기부 지역SW서비스사업화 지원사업 4개 과제 선정',\n",
              " 'paragraphs': [{'context': '부산시와 (재)부산정보산업진흥원(원장 이인숙)이 ‘2020~2021년 지역SW서비스사업화 지원사업’ 공모사업에 4개 과제가 선정되어 본격적인 사업 착수에 나선다. 과학기술정보통신부가 주관하는 ‘지역SW서비스사업화 지원사업’은 강소SW기업 및 초기 스타트업의 SW서비스 사업화 지원과 신시장 진출 지원을 통해 기업 경쟁력 강화와 지역경제 활성화를 도모하는 사업이다. 올해부터 2개년으로 진행되며, 국비와 시비, 민자 등 2년간 약 37억원의 예산이 투입된다. 앞서 진흥원은 부산의 미래 먹거리산업인 스마트해양, 지능형기계, 지능정보서비스 분야로 사전 수요조사를 진행했고, 평가를 통해 선정된 5개 과제를 공모사업에 신청했다. 그 결과 부산의 4개 과제가 최종 선정되는 쾌거를 거뒀다. 당 사업은 전국 진흥기관을 대상으로 공모를 시작해, 총 17개 지역에서 42개 과제가 선정되었으며, 4개 과제가 선정된 곳은 부산과 강원지역 뿐이다. 금번 선정된 과제들은 ‘인공지능융합센서와 서보 이송 로봇을 이용한 전단보강재의 자동용접시스템 개발’ 등 총 4개 과제다. 부산시가 지원하고, 부산정보산업진흥원과 지역기업, 대학, 연구소 등이 컨소시엄을 구성하여 기술개발 및 사업화 지원을 추진한다. 2개의 Track으로 구분되는 이번사업은 Track 1(SW중소기업)에서 ㈜에이아이플랫폼, 엔컴(주), Track 2(스타트업)에서는 ㈜토즈, 삼보테크놀로지를 지원한다. ○ ‘Track 1‘의 (주)에이아이플랫폼이 주관기업으로 진행하는 <인공지능 기반 망막 내 아밀로이드 플라크 영상 분석을 통한 치매조기진단 플랫폼 상용화>는 치매 확진의 원인이 되는 중요 단백질(아밀로이드 플라크)을 자체개발 관측장비로 진단한다. 이를 통해 치매를 조기 발견하여, 각종 경제적 비용과 치료 및 예방 등 사회적 문제를 해 결하고 시민들이 쉽게 접근 가능한 실효성 있는 치매관리체계 개발을 목표로 한다. ○ 엔컴(주)이 주관기업으로 참여하는 <AI영상분석 기반 가공철근 생산성 향상 시스템 기술개발 및 사업화>는 산업안전, 환경규제, 생산체계의 변화로 침체된 부산 핵심 산업인 철강업 활성화에 나선다. 실시간으로 절곡되어 나오는 가공철근의 형상을 인식하고 불량 형상 판단 시 적합한 교정 값을 절곡설비에 전달함으로써, 무중단 생산이 가능한 영상분석 기술과 생산설비 자동화 제어기술을 개발한다. ○ ‘Track 2’의 ㈜토즈는 자립기반이 약한 국내 중소형 조선소의 산업기술 변화에 혁신적인 대응을 위해 <가상현실 기반 원격 다자간 선박 및 해양구조물 사전 검사 시스템>을 개발한다. 선박 건조 前, 설계 단계에서 설계자 뿐만 아니라 생산관리자, 품질관리자, 선급검사관, 선주감독관 등의 이해관계자가 공동으로 가상의 환경에서 선박 및 해양구조물의 자재 배치와 간섭, 작업성, 설계 오작 등에 대한 검사를 진행할 수 있는 기술을 확보하여 조선소의 업무효율을 극대화 할 예정이다. ○ 삼보테크놀로지는 재래식 건설 부자재의 시공성, 안전성, 내구성 등의 문제점을 보완하여 시민 안전과 건설근로자의 환경개선, 생산성 및 수익성 향상을 위해 <인공지능융합센서와 새들형 토치 서보 이송 로봇을 이용한 고속 SRD 전단보강재 자동용접시스템>을 개발한다. 로봇응용 SRD 용접자동화 설비를 제작하고, 용접 모니터링 및 품질검사 소프트웨어를 개발하여 건설분야에 4차산업 대비 지능형 생산자동화 기반기술을 확보할 예정이다. (재)부산정보산업진흥원 이인숙 원장은 “이번 코로나19 사태로 인해 부산 기업들이 매출과 고용유지, 자재수급 등에 큰 타격을 입었지만, 지역SW서비스사업화 지원사업을 통해 지역과 기업차원에서 기반을 다지는 계기가 됐으면 좋겠다‘며 ”진흥원은 어려운 사태를 대비해 지역 기업들을 지원할 수 있는 다른 방편을 계속 모색 중이며, 더욱 성장해 나갈 수 있도록 적극 지원하겠다“고 전했다.',\n",
              "   'qas': [{'question': '지능형 생산자동화 기반기술을 개발중인 스타트업은?',\n",
              "     'answers': [{'text': '삼보테크놀로지', 'answer_start': 1422}],\n",
              "     'guid': '67c85e4f86ae43939b807684537c909c'}]}],\n",
              " 'news_category': '경제',\n",
              " 'source': 'acrofan'}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "input_dict[\"data\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "2EvB1moGOt55"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "def split_input_dict(input_dict, ratio = 0.1, seed = 42):\n",
        "    split_point = int(len(input_dict['data']) * ratio)\n",
        "    random.seed(seed)\n",
        "    random.shuffle(input_dict['data'])\n",
        "    valid_dict = deepcopy(input_dict)\n",
        "    train_dict = input_dict\n",
        "\n",
        "    valid_dict['data'] = input_dict['data'][:split_point]\n",
        "    train_dict['data'] = input_dict['data'][split_point:]\n",
        "    return train_dict, valid_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "DHJppuYaO9Nl"
      },
      "outputs": [],
      "source": [
        "def read_input(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        input_dict = json.load(f)\n",
        "    train_dict,valid_dict =split_input_dict(input_dict)\n",
        "    train_contexts = []\n",
        "    train_questions = []\n",
        "    train_answers = []\n",
        "    for group in tqdm(train_dict['data']):       #딕셔너리 하나씩 꺼낸다.\n",
        "        for passage in group['paragraphs']:     #딕셔너리의 paragraphs\n",
        "            context = passage['context']        #paragraphs의 context\n",
        "            for qa in passage['qas']:           #paragraphs의 qas\n",
        "                question = qa['question']       #paragraphs의 question\n",
        "                for answer in qa['answers']:    #question의 answers\n",
        "                    ### context 넘겨서 자르기 ###\n",
        "                    target_context = context\n",
        "                    if answer['answer_start'] > 1400:\n",
        "                        target_context = target_context[1200:]\n",
        "                        answer['answer_start'] -= 1200 \n",
        "                    elif answer['answer_start'] > 1200:\n",
        "                        target_context = target_context[1000:]\n",
        "                        answer['answer_start'] -= 1000\n",
        "                    elif answer['answer_start'] > 1000:\n",
        "                        target_context = target_context[800:]\n",
        "                        answer['answer_start'] -= 800\n",
        "                    elif answer['answer_start'] > 800:\n",
        "                        target_context = target_context[600:]\n",
        "                        answer['answer_start'] -= 600\n",
        "                    \n",
        "                    \n",
        "                    train_contexts.append(target_context)    #answers의 한 answer당 해당하는 context 저장\n",
        "                    ### context 넘겨서 자르기 ###\n",
        "                    train_questions.append(question)  #answers의 한 answer당 해당하는 question 저장\n",
        "                    train_answers.append(answer)      #answers의 한 answer 저장\n",
        "  \n",
        "    valid_contexts = []\n",
        "    valid_questions = []\n",
        "    valid_answers = []\n",
        "    for group in tqdm(valid_dict['data']):       #딕셔너리 하나씩 꺼낸다.\n",
        "        for passage in group['paragraphs']:     #딕셔너리의 paragraphs\n",
        "            context = passage['context']        #paragraphs의 context\n",
        "            for qa in passage['qas']:           #paragraphs의 qas\n",
        "                question = qa['question']       #paragraphs의 question\n",
        "                for answer in qa['answers']:    #question의 answers\n",
        "                    ### context 넘겨서 자르기 ###\n",
        "                    target_context = context\n",
        "                    if answer['answer_start'] > 1400:\n",
        "                        target_context = target_context[1200:]\n",
        "                        answer['answer_start'] -= 1200 \n",
        "                    elif answer['answer_start'] > 1200:\n",
        "                        target_context = target_context[1000:]\n",
        "                        answer['answer_start'] -= 1000\n",
        "                    elif answer['answer_start'] > 1000:\n",
        "                        target_context = target_context[800:]\n",
        "                        answer['answer_start'] -= 800\n",
        "                    elif answer['answer_start'] > 800:\n",
        "                        target_context = target_context[600:]\n",
        "                        answer['answer_start'] -= 600\n",
        "\n",
        "                    \n",
        "                    valid_contexts.append(target_context)    #answers의 한 answer당 해당하는 context 저장\n",
        "                    ### context 넘겨서 자르기 ###\n",
        "                    valid_questions.append(question)  #answers의 한 answer당 해당하는 question 저장\n",
        "                    valid_answers.append(answer)      #answers의 한 answer 저장\n",
        "\n",
        "    return train_contexts, train_questions, train_answers, valid_contexts, valid_questions, valid_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "vKGCz_4WO9Lg"
      },
      "outputs": [],
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            print(\"there is an unitended error in dataset\") #이렇게까지 할 필요가 있나?\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            print(\"there is an unitended error in dataset\")\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "1kXdeER8O9Jp"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz1kYCgCO9Hx",
        "outputId": "22b38d38-4a90-422f-b1a7-00865b927124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2, 156, 18876, 8381, 29956, 550, 29982, 2757, 29951, 29962, 392, 30201, 29948, 5, 188, 55, 4473, 4660, 29961, 8674, 29997, 29948, 23326, 30672, 455, 1821, 29961, 6, 30124, 103, 30277, 8381, 29956, 392, 30292, 627, 29947, 29948, 5, 550, 29982, 5337, 29951, 541, 30013, 2757, 4613, 23905, 29951, 24, 29950, 8381, 9972, 29953, 814, 9563, 17196, 2757, 12364, 298, 7418, 16239, 29951, 10954, 21036, 29956, 1358, 29954, 13956, 3196, 29951, 1, 7532, 29959, 29950, 204, 29961, 97, 29956, 2708, 29948, 5, 881, 29953, 8381, 29950, 10062, 29997, 29948, 28, 260, 57, 29982, 18, 136, 29973, 29997, 1312, 989, 5046, 392, 30201, 29948, 5, 8381, 29950, 15024, 29948, 30207, 29957, 299, 10299, 27674, 29990, 14, 30833, 278, 30425, 29957, 84, 30128, 27805, 29973, 27674, 29947, 1028, 2158, 30078, 29950, 8381, 9972, 29951, 29962, 2185, 29950, 97, 29965, 913, 1086, 5, 8381, 9972, 29961, 462, 29982, 2757, 943, 4613, 3306, 9563, 11560, 2883, 90, 29982, 30277, 548, 18521, 29973, 1583, 14726, 30108, 29954, 814, 29952, 397, 45, 9563, 835, 5, 26701, 347, 90, 260, 610, 29982, 3378, 4660, 29951, 29967, 8674, 29997, 29948, 5752, 455, 8381, 29956, 5046, 26845, 627, 29947, 29948, 5, 416, 8381, 9972, 29952, 5551, 19393, 29950, 299, 10299, 3741, 30481, 1874, 29947, 9363, 188, 55, 4473, 4660, 29961, 10062, 29997, 29948, 23326, 30672, 29956, 30293, 1821, 29961, 6, 30124, 103, 628, 8381, 29956, 392, 30292, 45, 29947, 24545, 58, 5337, 29953, 515, 29947, 29948, 5, 8381, 9972, 29961, 378, 14, 148, 29956, 30293, 2355, 9889, 29983, 29965, 17386, 30053, 3196, 29951, 97, 29965, 2240, 30494, 627, 29947, 29948, 5, 409, 346, 30027, 30067, 846, 30055, 29951, 541, 30013, 4473, 4660, 29953, 8381, 392, 29982, 29961, 121, 30086, 9129, 260, 509, 29982, 29947, 30080, 2673, 8381, 29960, 30067, 29961, 1314, 29982, 18, 5293, 29982, 29974, 29950, 550, 5, 28, 29982, 29947, 30080, 29948, 5, 5337, 29961, 5849, 8381, 29960, 30067, 29953, 846, 10210, 29947, 7417, 260, 1, 10062, 29990, 1623, 29959, 8345, 51, 29952, 45, 9563, 4390, 29948, 5, 2423, 1686, 131, 29990, 1263, 29953, 235, 29956, 1428, 29950, 462, 29982, 648, 188, 29961, 4884, 6158, 29947, 613, 1556, 440, 97, 29950, 9628, 109, 29952, 45, 9563, 675, 30340, 1117, 2815, 29951, 29950, 7916, 29947, 116, 29952, 627, 29947, 29948, 5, 3, 299, 10299, 27674, 29990, 84, 30128, 27805, 29973, 27674, 29947, 1028, 417, 29951, 11536, 29950, 655, 29961, 420, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "question = \"북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?\"\n",
        "context = \"올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.\"\n",
        "tokenizer(context, question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "1E9UJAXRO9Fi"
      },
      "outputs": [],
      "source": [
        "class Dataset_base(Dataset):\n",
        "    def __init__(self, contexts, questions, answers, model_max_position_embedings, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.answers = answers\n",
        "        self.questions = questions\n",
        "        self.contexts = contexts\n",
        "        self.model_max_position_embedings = model_max_position_embedings\n",
        "        print(\"Tokenizing ...\")\n",
        "        self.encodings = self.tokenizer(self.contexts, \n",
        "                                        self.questions,\n",
        "                                        max_length=512, #512 truncation // \n",
        "                                        truncation=True,\n",
        "                                        padding=\"max_length\",\n",
        "                                        return_token_type_ids=False)\n",
        "        print(\"Done !!!\")\n",
        "        self.add_token_positions()\n",
        "        \n",
        "    def add_token_positions(self):\n",
        "        start_positions = []\n",
        "        end_positions = []\n",
        "        for i in range(len(self.answers)):\n",
        "            start_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_start']))\n",
        "            end_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_end'] - 1)) # -1으로 : 진짜로 답이 있는 end_position 의 인덱스를 구함.(char_to_token은 인덱스를 구함)\n",
        "            #https://huggingface.co/docs/tokenizers/v0.13.2/en/api/encoding#tokenizers.Encoding.char_to_token\n",
        "\n",
        "            # positions 값이 None 값이라면, answer가 포함된 context가 잘렸다는 의미\n",
        "            if start_positions[-1] is None:\n",
        "                print(\"there is an error 1\")\n",
        "                start_positions[-1] = self.model_max_position_embedings\n",
        "            if end_positions[-1] is None:\n",
        "                print(\"there is an error 2\")\n",
        "                end_positions[-1] = self.model_max_position_embedings\n",
        "\n",
        "        self.encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "        \n",
        "    def get_data(self):\n",
        "        return {\"contexts\":self.contexts, 'questions':self.questions, 'answers':self.answers}\n",
        "    \n",
        "    \n",
        "    def get_encodings(self):\n",
        "        return self.encodings\n",
        "        \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {key:torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "2e280f39b04e4d9aa381d339a1dc6598",
            "a0ea7607aeac4c369cbf3f908630b953",
            "5e827eb6c96f46e486be14e5b0793b18",
            "cfa20ea077c840938d6db35650eaddb9",
            "eb3be64c44b4411cbd87708b04385c14",
            "f49b6d788d164f0a961f018ab5fce0ff",
            "e969cbd598eb4cd2b666dc4bb3ea75c4",
            "9b4d56f8b2ab4de89fafe8a7e21d61d0",
            "3ce498f0fbe044dca96a2a01689c9f51",
            "2925e1539ef44e09a4e7b41b00733026",
            "4d0049ee1098418fbf9bb524afa70246",
            "31c918c5b67d48b7ac32ebae4c3efdda",
            "94293cd9f70a41fe99a0357af72889dc",
            "4b8e593f45304c9786bd3312edc20883",
            "5083be6eb00d4b38861331d60023491f",
            "6adf609d503d480ea7489d988f23397c",
            "7bcd946acd604460a96000b82f0a257c",
            "1a22a08eff354bd2bd3b60c76450e0aa",
            "43c9dc81a5364c5a8188c664b47234d3",
            "5aad5a4cb8ba4c7b8f3cf97702e836c8",
            "914ff81e7a164798b8cce2dcf95783ab",
            "121b0346376f47899b42a05f8caf466f"
          ]
        },
        "id": "ynDpvL5YRujc",
        "outputId": "5154c574-c332-4865-e6d8-6271297b0f81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8811 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e280f39b04e4d9aa381d339a1dc6598"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/978 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31c918c5b67d48b7ac32ebae4c3efdda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing ...\n",
            "Done !!!\n",
            "there is an error 2\n",
            "Tokenizing ...\n",
            "Done !!!\n"
          ]
        }
      ],
      "source": [
        "train_contexts, train_questions, train_answers, valid_contexts, valid_questions, valid_answers = read_input(\"train.json\")\n",
        "add_end_idx(train_answers, train_contexts)                                                      #anwer 마다 answer_end 달아준다.\n",
        "train_dataset = Dataset_base(train_contexts, train_questions, train_answers, 512, tokenizer)\n",
        "\n",
        "add_end_idx(valid_answers, valid_contexts)                                                      #anwer 마다 answer_end 달아준다.\n",
        "valid_dataset = Dataset_base(valid_contexts, valid_questions, valid_answers, 512, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "AcZAGePiPL_I"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "cWXsoBx--_26",
        "outputId": "f1c2af9b-50b9-4482-eba9-3af088fe063c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjeonht98\u001b[0m (\u001b[33mgoorm_project\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDPGeivV_M1w",
        "outputId": "27b6f92a-c067-4f6b-bba7-fb01af34500d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: av91nyj1\n",
            "Sweep URL: https://wandb.ai/goorm_project/uncategorized/sweeps/av91nyj1\n"
          ]
        }
      ],
      "source": [
        "sweep_config = {\n",
        "      'name' : 'project2_TEST1.ipynb',\n",
        "      'method' : 'grid',\n",
        "      'metric':{\n",
        "          'name': 'total_valid_loss',\n",
        "          'goal': 'minimize'  \n",
        "      },\n",
        "      'parameters' : {\n",
        "          'learning_rate' : {\n",
        "              'values' : [1e-4, 2.5e-5, 5e-5, 7.5e-5,1e-5]  \n",
        "          },   \n",
        "          'batch_size' :{\n",
        "              'values' : [4,8,16]\n",
        "          },\n",
        "          'epochs' : {\n",
        "              'values' : [2] \n",
        "          }\n",
        "      }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "rTg8-yjFPL85"
      },
      "outputs": [],
      "source": [
        "EPOCH = 1\n",
        "LEARNING_RATE = 5e-5\n",
        "BATCH_SIZE = 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "NYZrOKTqQDBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "8733aa8a-d29e-4962-ea48-9880bb2076e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlevenshtein_distance 값이 튀는 현상 방지.\\n - 길이가 너무 긴 정답 삭제 max_length = 20\\n - 정답과 어느정도 길이차이나는 값 삭제(위와 동일) 5.9 -> 2정도 차이나는 값 삭제 7.9\\n \\n\\n자연어처리\\n자연어처리과정 2\\n0 5\\n\\n정답 길이보다 예측 정답 길이가 길지만 2배이상 차이가 나지 않는 경우에\\n0으로 처리하면 LD_SCORE가 더 안나옴\\n따라서 위 상황에서는 1.5 ~ 1.8 정도 해당하는 길이로 잘라서 반환.\\n\\ntest 답 X\\ntrain 과정 나온 답 -> 바꿔서 바꾼 데이터로 \\n\\n\\n** max_len = 5.9 * 2 = 12\\n\\ntrain 2번\\n1 train 원래 데이터.\\n2 train LD 변환한 데이터로 한번.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "# Levenshtein_distance (Evaluation)\n",
        "\n",
        "import numpy \n",
        "import torch\n",
        "import os\n",
        "\n",
        "def levenshtein_distance(s1,s2, debug=False): #레벤슈타인 거리 eval / 정답 s1과 도출한 모델 s2 비교 평가\n",
        "    if len(s1) < len(s2):\n",
        "        return levenshtein_distance(s2, s1, debug)\n",
        "\n",
        "    if len(s2) == 0:\n",
        "        return len(s1)\n",
        "\n",
        "    previous_row = range(len(s2) + 1)\n",
        "    for i, c1 in enumerate(s1):\n",
        "        current_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            insertions = previous_row[j + 1] + 1\n",
        "            deletions = current_row[j] + 1\n",
        "            substitutions = previous_row[j] + (c1 != c2)\n",
        "            current_row.append(min(insertions, deletions, substitutions))\n",
        "\n",
        "        if debug:\n",
        "            print(current_row[1:])\n",
        "\n",
        "        previous_row = current_row\n",
        "\n",
        "    return previous_row[-1] # levenshtein_distance 값 출력력\n",
        "\n",
        "\n",
        "def LD_SCORE(start_positions, end_positions, input_ids, STA_logits, END_logits):\n",
        "\n",
        "    answer1 = [] # 정답 저장\n",
        "    answer2 = [] # 예측 정답 저장\n",
        "\n",
        "    if len(input_ids) != BATCH_SIZE: #오류 해결\n",
        "       print(\"input_ids ERROR\")\n",
        "       return 0\n",
        "\n",
        "    for i in range(BATCH_SIZE): # 기존 정답 // index 1 is out of bounds for dimension 0 with size 1 오류 발생\n",
        "        if input_ids[i] == [] :\n",
        "            print(\"input_ids ERROR\")\n",
        "            continue       \n",
        "        else:\n",
        "            PRED_IDE = input_ids[i][start_positions[i]: end_positions[i] + 1]\n",
        "            PRED_ANS = tokenizer.decode(PRED_IDE)\n",
        "            answer1.append(PRED_ANS)\n",
        "            #print(PRED_ANS)\n",
        "\n",
        "    for i in range(BATCH_SIZE): # 예측 정답\n",
        "        if input_ids[i] == [] :\n",
        "            print(\"input_ids ERROR\")\n",
        "            continue\n",
        "        else:\n",
        "            TK_start_index, TK_end_index = STA_logits.argmax(dim=-1), END_logits.argmax(dim=-1)\n",
        "            PRED_IDE2 = input_ids[i][TK_start_index[i]: TK_end_index[i] + 1]\n",
        "            PRED_ANS2 = tokenizer.decode(PRED_IDE2)\n",
        "            answer2.append(PRED_ANS2)\n",
        "            # print(PRED_ANS2)\n",
        "\n",
        "    batch_score = LD_comparison(answer1, answer2)\n",
        "\n",
        "    return batch_score\n",
        "\n",
        "\n",
        "def LD_comparison(answer1,answer2):\n",
        "\n",
        "    # 배치마다 레벤슈타인 거리 평균 구해서 출력. (train, valid 과정에서 배치마다 평균거리 구하고.)\n",
        "    # train 전체 평균 거리\n",
        "    # valid 전체 평균 거리\n",
        "\n",
        "    batch_LD_score = []\n",
        "\n",
        "    for i in range(BATCH_SIZE):\n",
        "        if answer1[i] == answer2[i]: # 같으면 LD 구하는 과정 생략.\n",
        "            batch_LD_score.append(0)\n",
        "        else:\n",
        "            batch_LD_score.append(levenshtein_distance(answer1[i],answer2[i]))\n",
        "\n",
        "    sum_LD_score = sum(batch_LD_score)\n",
        "    LD_avg = sum_LD_score / BATCH_SIZE # 배치의 레벤슈타인 거리 평균\n",
        "    #print(LD_avg)\n",
        "\n",
        "    return LD_avg\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "levenshtein_distance 값이 튀는 현상 방지.\n",
        " - 길이가 너무 긴 정답 삭제 max_length = 20\n",
        " - 정답과 어느정도 길이차이나는 값 삭제(위와 동일) 5.9 -> 2정도 차이나는 값 삭제 7.9\n",
        " \n",
        "\n",
        "자연어처리\n",
        "자연어처리과정 2\n",
        "0 5\n",
        "\n",
        "정답 길이보다 예측 정답 길이가 길지만 2배이상 차이가 나지 않는 경우에\n",
        "0으로 처리하면 LD_SCORE가 더 안나옴\n",
        "따라서 위 상황에서는 1.5 ~ 1.8 정도 해당하는 길이로 잘라서 반환.\n",
        "\n",
        "test 답 X\n",
        "train 과정 나온 답 -> 바꿔서 바꾼 데이터로 \n",
        "\n",
        "\n",
        "** max_len = 5.9 * 2 = 12\n",
        "\n",
        "train 2번\n",
        "1 train 원래 데이터.\n",
        "2 train LD 변환한 데이터로 한번.\n",
        "\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "69QT4ZwJPL4A"
      },
      "outputs": [],
      "source": [
        "# LD SCORE 저장\n",
        "train_LD_avg = [] \n",
        "valid_LD_avg = []\n",
        "\n",
        "def train_runner(model, train_dataset, valid_dataset , batch_size, num_train_epochs, learning_rate):\n",
        "\n",
        "    #wandb.init(project = 'project2_test1',reinit=True)\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    \n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "    valid_dataloader = DataLoader(dataset = valid_dataset, batch_size = batch_size)\n",
        "\n",
        "    lowest_total_valid_loss = 9999.\n",
        "\n",
        "    global_total_step = len(train_dataloader) * num_train_epochs\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0)\n",
        "    print(\"TRAIN START\")\n",
        "    with tqdm(total=global_total_step, unit='step') as t:\n",
        "        total = 0\n",
        "        total_loss = 0\n",
        "        for epoch in range(num_train_epochs):\n",
        "            for iteration,batch in enumerate(train_dataloader):\n",
        "                optimizer.zero_grad()\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                start_positions = batch['start_positions'].to(device)\n",
        "                end_positions = batch['end_positions'].to(device)                \n",
        "\n",
        "                outputs = model(input_ids,\n",
        "                             attention_mask=attention_mask,\n",
        "                             start_positions=start_positions,\n",
        "                             end_positions=end_positions)\n",
        "                \n",
        "                ### LD_SCORE - train\n",
        "                STA_logits, END_logits = outputs.start_logits, outputs.end_logits\n",
        "                score_save1 = LD_SCORE(start_positions, end_positions, input_ids, STA_logits, END_logits)\n",
        "                train_LD_avg.append(score_save1)\n",
        "                #wandb.log({'train_batch_LD':score_save1})\n",
        "\n",
        "                ####\n",
        "                #loss_logit_change(start_positions, end_positions, input_ids, STA_logits, END_logits)\n",
        "                loss = outputs.loss\n",
        "                #wandb loss\n",
        "                #wandb.log({'Train_loss':loss.item()})\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                batch_loss = loss.item() * len(input_ids)\n",
        "                total += len(input_ids)\n",
        "                total_loss += batch_loss\n",
        "                global_total_step += 1\n",
        "                t.set_postfix(loss=\"{:.6f}\".format(total_loss / total), batch_loss=\"{:.6f}\".format(batch_loss))\n",
        "                t.update(1)\n",
        "\n",
        "                # wandb loss\n",
        "                #wandb.log({'Train_batch_loss':batch_loss})\n",
        "                #wandb.log({'LOSS':total_loss / total})\n",
        "                \n",
        "                del input_ids\n",
        "                del attention_mask\n",
        "                del start_positions\n",
        "                del end_positions\n",
        "                del outputs\n",
        "                del loss\n",
        "\n",
        "                ## validation ##\n",
        "                if iteration != 0 and iteration % int(len(train_dataloader) / 5) == 0:\n",
        "                    total_valid_loss = 0\n",
        "                    for batch_val in valid_dataloader:\n",
        "                        model.eval()\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                        input_ids = batch_val['input_ids'].to(device)\n",
        "                        attention_mask = batch_val['attention_mask'].to(device)\n",
        "                        start_positions = batch_val['start_positions'].to(device)\n",
        "                        end_positions = batch_val['end_positions'].to(device)\n",
        "                \n",
        "                        with torch.no_grad():\n",
        "                            outputs = model(input_ids,\n",
        "                                    attention_mask=attention_mask,\n",
        "                                    start_positions=start_positions,\n",
        "                                    end_positions=end_positions)\n",
        "                            \n",
        "                            ### LD_SCORE - valid\n",
        "                            STA_logits, END_logits = outputs.start_logits, outputs.end_logits\n",
        "                            score_save2 = LD_SCORE(start_positions, end_positions, input_ids, STA_logits, END_logits)\n",
        "                            valid_LD_avg.append(score_save2)\n",
        "\n",
        "                            # wandb LD\n",
        "                            #wandb.log({'Valid_batch_LD':score_save2})\n",
        "\n",
        "                            loss = outputs.loss\n",
        "                            total_valid_loss += loss.item()\n",
        "\n",
        "                            # wandb loss\n",
        "                            #wandb.log({'Valid_loss':loss.item()})\n",
        "                            #wandb.log({'total_valid_loss':total_valid_loss})\n",
        "                    \n",
        "                    if total_valid_loss < lowest_total_valid_loss:\n",
        "                        print(f\"lowest_total_valid_loss: {total_valid_loss} epoch : {epoch} iteration : {iteration}\")\n",
        "                        torch.save(model.state_dict(),'./output_model_best')\n",
        "                        lowest_total_valid_loss = total_valid_loss\n",
        "                ## validation ##\n",
        "\n",
        "    #model.save_pretrained(\"./klue_output_model\")\n",
        "    # train, valid 평균 LD 거리\n",
        "    train_AVG = sum(train_LD_avg) / len(train_LD_avg)\n",
        "    valid_AVG = sum(valid_LD_avg) / len(valid_LD_avg)\n",
        "    #wandb.log({'train_AVG_LD':train_AVG})\n",
        "    #wandb.log({'valid_AVG_LD':valid_AVG})\n",
        "\n",
        "    print('train LD average',train_AVG,'valid LD average',valid_AVG)\n",
        "    print(\"TRAIN END\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXl1Yo7y_3JH"
      },
      "outputs": [],
      "source": [
        "# wandb sweep train 실행.\n",
        "\n",
        "# wandb.agent( sweep_id , function=train_runner, count=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "26afe17d1b4945d2b3ee00d27b955975",
            "ac28198bcf244a18a60483c4b5628143",
            "cc16beab8d784092a4b47f52c2276698",
            "09d88b87407c47a183a445dc88a99d83",
            "452631053f0c4292ba06b83b31bb3d41",
            "a71a451d3e8c48819fe545f626958cfa",
            "670b1b3da11c4640844b809b9dea90aa",
            "202b3933d0464b36baaab2adeb68e28b",
            "96d6908b6d054e51aa3a02d576b8af49",
            "74627f3e083e457abc7071b8c44a42ec",
            "f920475979ba4d9fae2a2a0845622d2b"
          ]
        },
        "id": "ywX4WIJXRuje",
        "outputId": "cc0386c2-b0bd-43a1-e222-a694624ccf2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN START\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/497 [00:00<?, ?step/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26afe17d1b4945d2b3ee00d27b955975"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids ERROR\n",
            "lowest_total_valid_loss: 127.19607412815094 epoch : 0 iteration : 99\n",
            "input_ids ERROR\n",
            "lowest_total_valid_loss: 113.00674819946289 epoch : 0 iteration : 198\n",
            "input_ids ERROR\n",
            "lowest_total_valid_loss: 106.80285608768463 epoch : 0 iteration : 297\n",
            "input_ids ERROR\n",
            "lowest_total_valid_loss: 102.56842559576035 epoch : 0 iteration : 396\n",
            "input_ids ERROR\n",
            "lowest_total_valid_loss: 101.88247060775757 epoch : 0 iteration : 495\n",
            "input_ids ERROR\n",
            "train LD average 14.711274509803921 valid LD average 11.375145687645688\n",
            "TRAIN END\n"
          ]
        }
      ],
      "source": [
        "train_runner(model,train_dataset,valid_dataset, BATCH_SIZE, EPOCH, LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he9L3jYZC8Rr",
        "outputId": "cff03462-e772-4944-c571-3a92665d6683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted Train Avgrage LD 5.467939121756487 predicted Valid Avgrage LD 5.530490451388889\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 10\n",
        "\n",
        "# train / valid 과정에서 나온 이상값 제거 (정확한 점수 X)\n",
        "\n",
        "train_LD_avg = [v for v in train_LD_avg if v < MAX_LEN]  \n",
        "TR_AVG = sum(train_LD_avg) / len(train_LD_avg) \n",
        "\n",
        "valid_LD_avg = [v for v in valid_LD_avg if v < MAX_LEN]\n",
        "VA_AVG = sum(valid_LD_avg) / len(valid_LD_avg)\n",
        "\n",
        "print('predicted Train Avgrage LD',TR_AVG,'predicted Valid Avgrage LD',VA_AVG) # 예측값 확인."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ZDVfXLBsPLrQ"
      },
      "outputs": [],
      "source": [
        "def read_dev(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        kdict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    guids = []\n",
        "\n",
        "    for group in tqdm(kdict['data']):\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                guid = qa['guid']\n",
        "                #temp_answer = []\n",
        "                #for answer in qa['answers']:\n",
        "                    #temp_answer.append(answer['text'])\n",
        "                #if len(temp_answer) != 0: # answers의 길이가 0 == 답변할 수 없는 질문\n",
        "                    #contexts.append(context)\n",
        "                    #questions.append(question)\n",
        "                    #answers.append(temp_answer)\n",
        "                contexts.append(context)##\n",
        "                questions.append(question)##\n",
        "                guids.append(guid)\n",
        "\n",
        "    #return contexts, questions, answers\n",
        "    return contexts, questions , guids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "OAg0_WkAPLjw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "face27d143504e2e8c16903a6af6c870",
            "ae552eb2cf56452490573ef78304acab",
            "b7c843d20d0644bc8cbdc0ae0ec11df6",
            "3964a59f2e224e759e734157813e1181",
            "10e8db00a90549319513197e8bda52c0",
            "22d5a75e6cc34d239af47521a0d8b542",
            "44bfb033180145798dac9a8c4b4f5b3b",
            "c6d4454e553343a7985f2f60054bca5a",
            "008a1091ee034ec9a1aee5acef521ef0",
            "43fcb27f56cc4d49a45cafd6537c3261",
            "ebe1c597320b49ffbe7d9ee34a0a8c2e"
          ]
        },
        "outputId": "192ba606-5abe-4675-dd70-ab21a90a9a45"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3709 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "face27d143504e2e8c16903a6af6c870"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#dev_contexts, dev_questions, dev_answers = read_dev(\"test.json\")\n",
        "dev_contexts, dev_questions, dev_guids = read_dev(\"test.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_post(text):\n",
        "        ''' 불필요한 기호 제거 '''\n",
        "        text = text.strip()\n",
        "        text = re.sub(\"'\", \"\", text)\n",
        "        text = re.sub('\"', \"\", text)\n",
        "        text = re.sub('《', \"\", text)\n",
        "        text = re.sub('》', \"\", text)\n",
        "        text = re.sub('<', \"\", text)\n",
        "        text = re.sub('>', \"\", text)\n",
        "        text = re.sub('〈', \"\", text)\n",
        "        text = re.sub('〉', \"\", text)\n",
        "        text = re.sub(\"\\(\", \"\", text)\n",
        "        text = re.sub(\"\\)\", \"\", text)\n",
        "        text = re.sub(\"‘\", \"\", text)\n",
        "        text = re.sub(\"’\", \"\", text)\n",
        "        text = re.sub(\"  \", \" \", text)\n",
        "        text = re.sub(\"#\", \"\", text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "qS8G0_kBhMhW"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "idea  \n",
        "틀린 답을 바로 빈칸으로 내보내는게 과연 이득일까?\n",
        "logit 확률값을 적용해서 틀린답이면 다음으로 높은 확률값이 정답일수도 있지않을까?\n",
        "top 5의 확률값을 다 적용해도 틀린 답이라면 그때 빈칸을 내보내도 괜찮을듯.\n",
        "'''\n",
        "# start, end logit의 확률값을 이용한 예측 정답값\n",
        "# logit의 상위 5개 확률을 리스트로 뽑아 틀린 정답이었다면 다음 확률로 넘어가서 확인.\n",
        "\n",
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        "\n",
        "def logits_change(input_ids, STA_logits, END_logits):\n",
        "\n",
        "    # 로짓의 확률값 ~ 상위 5개를 선택 \n",
        "    # 틀린 추론이었다면 다음 선택 (틀린 추론 : start > end, 길이가 너무 긴 문장.)\n",
        "    change_logit = 0\n",
        "    cnt = 0\n",
        "    \n",
        "    # 기존 정답\n",
        "    save_s = STA_logits\n",
        "    save_e = END_logits\n",
        "\n",
        "    STK_start_index, STK_end_index = save_s.argmax(dim=-1), save_e.argmax(dim=-1)\n",
        "    save_pred_ids = tokenizer.decode(input_ids[0][STK_start_index: STK_end_index + 1])\n",
        "    #print(save_pred_ids) \n",
        "\n",
        "    # 바뀐 정답\n",
        "    # Tensor형태의 logit의 확률값을 리스트로 만들어줌 \n",
        "    STA_logits = to_list(STA_logits)[0]\n",
        "    END_logits = to_list(END_logits)[0]\n",
        "\n",
        "    # 리스트로 만든 확률값 -> 큰 순서대로 정렬 + 인덱스 \n",
        "    start_idx_and_logit = sorted(enumerate(STA_logits), key=lambda x: x[1], reverse=True)\n",
        "    end_idx_and_logit = sorted(enumerate(END_logits), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # 확률값 큰 순서대로 Top 5 \n",
        "    start_idx_and_logit = start_idx_and_logit[:5]\n",
        "    end_idx_and_logit = end_idx_and_logit[:5]\n",
        "\n",
        "    TK_start_index, TK_end_index = start_idx_and_logit, end_idx_and_logit\n",
        "\n",
        "    # 확률이 높은 순서대로 점검. 틀린 값이면 다음 확률로 넘어가고 맞는 답이면 저장후 반복문 종료\n",
        "    for i in range(5):\n",
        "        if TK_start_index[i][0] > TK_end_index[i][0] or TK_end_index[i][0] - TK_start_index[i][0] > 10 : \n",
        "            cnt += 1\n",
        "            continue\n",
        "        else : \n",
        "            change_logit += 1\n",
        "            pred_ids = input_ids[0][TK_start_index[i][0]: TK_end_index[i][0] + 1]\n",
        "            pred_ids = tokenizer.decode(pred_ids)\n",
        "            #print(pred_ids, 'change')\n",
        "            break\n",
        "\n",
        "    if change_logit == 0 :\n",
        "        return save_pred_ids\n",
        "    elif cnt == 5:\n",
        "        return ''\n",
        "    else : \n",
        "        if pred_ids == save_pred_ids:\n",
        "            #print('same answer')\n",
        "            return pred_ids\n",
        "        else :\n",
        "            #print('different answer')\n",
        "            return pred_ids\n",
        "\n",
        "    \n",
        "\n",
        "# start_logits , end_logits\n",
        "# index를 추적하면서 시작, 종료 index에 대한 확률이 가장 높은것을 선택하는 방법.\n",
        "# 만약에 차이가 큰 start, end 값을 반환할때 이 정보들을 저장하지 않고 넘긴다면? \n"
      ],
      "metadata": {
        "id": "4HmQRZQp1NKT"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "rHaddLdiPf5z"
      },
      "outputs": [],
      "source": [
        "def prediction(contexts, questions, guids):\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    model.load_state_dict(torch.load('./output_model_best'))\n",
        "    model.to(device)\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    result = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for context, question, guid in zip(contexts, questions, guids):\n",
        "            encodings = tokenizer(context, question, max_length=512, truncation=True,\n",
        "                                     padding=\"max_length\", return_token_type_ids=False)\n",
        "            encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n",
        "            \n",
        "            input_ids = encodings[\"input_ids\"].to(device)\n",
        "            attention_mask = encodings[\"attention_mask\"].to(device)\n",
        "            \n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
        "\n",
        "            ######\n",
        "            pred =logits_change(input_ids, start_logits, end_logits)\n",
        "            '''\n",
        "            token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n",
        "            pred_ids = input_ids[0][token_start_index: token_end_index + 1]\n",
        "            \n",
        "            if token_start_index > token_end_index:\n",
        "                pred = ''\n",
        "            else:\n",
        "                pred = tokenizer.decode(pred_ids)\n",
        "                pred = pred[:10] # 1.5~1.8\n",
        "            '''\n",
        "            \n",
        "\n",
        "\n",
        "            pred = pred[:8] # 6~12 테스트 결과 8이 가장 좋은 점수.\n",
        "            pred = remove_post(pred)\n",
        "\n",
        "            tp = (guid,pred)\n",
        "            \n",
        "            result.append(tp)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "L20_dlBvPf3p"
      },
      "outputs": [],
      "source": [
        "pred_answers = prediction(dev_contexts, dev_questions, dev_guids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "-FdYepZSPf1i"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "f = open('sangrimlee_bert-base-multilingual-cased-korquad_validation_pred_truncation.csv','w', newline='')\n",
        "wr = csv.writer(f)\n",
        "wr.writerow(['Id','Predicted'])\n",
        "\n",
        "for tp in pred_answers:\n",
        "    wr.writerow([tp[0],tp[1]])\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_answers에서 도출한 정답 비교\n",
        "import csv\n",
        "\n",
        "def calculate_Leven(source, ref, result_file):\n",
        "    with open(source, 'r') as input1:\n",
        "        with open(ref, 'r') as input2:\n",
        "            with open(result_file, 'w') as csvoutput:\n",
        "                reader1 = csv.reader(input1)\n",
        "                reader2 = list(csv.reader(input2))\n",
        "                writer = csv.writer(csvoutput)\n",
        "                result = []\n",
        "                mean = []\n",
        "                headers = next(reader1)\n",
        "                result.append(headers)\n",
        "                index = 0\n",
        "                for row1 in reader1:\n",
        "                    #print(\"First row\")\n",
        "                    #print(row1[1])\n",
        "                    index+=1\n",
        "                    #print(reader2[index][1])\n",
        "                    a = levenshtein_distance(row1[1], reader2[index][1])\n",
        "                    #print(row1[1],'////',reader2[index][1])\n",
        "                    '''\n",
        "                    max = 0\n",
        "                    while max < 1:\n",
        "                        for row2 in reader2:\n",
        "                            a = distance(row1[1],row2[1])\n",
        "                            print(a)\n",
        "                            b = 1 - a/len(row1[1])\n",
        "                            if b > max:\n",
        "                                max = b\n",
        "                                SKU = row2[1]\n",
        "                    '''\n",
        "                    mean.append(a)\n",
        "                    row1.append(a)\n",
        "                    result.append(row1)\n",
        "                mean1 = sum(mean) / len(mean)\n",
        "                print(mean1)\n",
        "                writer.writerows(result)\n"
      ],
      "metadata": {
        "id": "SXMI6CaEmKlM"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_Leven('klue.csv', 'sangrimlee_bert-base-multilingual-cased-korquad_validation_pred_truncation.csv', 'result_file.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKbGAvSZmRyu",
        "outputId": "7eb9d123-81bb-4574-e51b-ae59deb39b3f"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1137724550898205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logit 값에 대한 soft voting\n",
        "\n",
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        "\n",
        "def logits_voting(A_model, B_model, C_model):\n",
        "    # 각 모델마다 input_ids, start_logits, end_logits값 저장.\n",
        "    # 모델 logit 확률 top 5 구해서 모델 1 top1 모델 2 top1 모델3 top1 모델1 top2 순으로 체크.\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "ihJBQMJDqFXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c044c91b12eb47f047c895d462d020aa8e4307e7bfafc2c2e5cdad580c7ef67a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e280f39b04e4d9aa381d339a1dc6598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0ea7607aeac4c369cbf3f908630b953",
              "IPY_MODEL_5e827eb6c96f46e486be14e5b0793b18",
              "IPY_MODEL_cfa20ea077c840938d6db35650eaddb9"
            ],
            "layout": "IPY_MODEL_eb3be64c44b4411cbd87708b04385c14"
          }
        },
        "a0ea7607aeac4c369cbf3f908630b953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49b6d788d164f0a961f018ab5fce0ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e969cbd598eb4cd2b666dc4bb3ea75c4",
            "value": "100%"
          }
        },
        "5e827eb6c96f46e486be14e5b0793b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b4d56f8b2ab4de89fafe8a7e21d61d0",
            "max": 8811,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ce498f0fbe044dca96a2a01689c9f51",
            "value": 8811
          }
        },
        "cfa20ea077c840938d6db35650eaddb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2925e1539ef44e09a4e7b41b00733026",
            "placeholder": "​",
            "style": "IPY_MODEL_4d0049ee1098418fbf9bb524afa70246",
            "value": " 8811/8811 [00:00&lt;00:00, 165384.59it/s]"
          }
        },
        "eb3be64c44b4411cbd87708b04385c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49b6d788d164f0a961f018ab5fce0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e969cbd598eb4cd2b666dc4bb3ea75c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b4d56f8b2ab4de89fafe8a7e21d61d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce498f0fbe044dca96a2a01689c9f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2925e1539ef44e09a4e7b41b00733026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d0049ee1098418fbf9bb524afa70246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31c918c5b67d48b7ac32ebae4c3efdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94293cd9f70a41fe99a0357af72889dc",
              "IPY_MODEL_4b8e593f45304c9786bd3312edc20883",
              "IPY_MODEL_5083be6eb00d4b38861331d60023491f"
            ],
            "layout": "IPY_MODEL_6adf609d503d480ea7489d988f23397c"
          }
        },
        "94293cd9f70a41fe99a0357af72889dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bcd946acd604460a96000b82f0a257c",
            "placeholder": "​",
            "style": "IPY_MODEL_1a22a08eff354bd2bd3b60c76450e0aa",
            "value": "100%"
          }
        },
        "4b8e593f45304c9786bd3312edc20883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c9dc81a5364c5a8188c664b47234d3",
            "max": 978,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5aad5a4cb8ba4c7b8f3cf97702e836c8",
            "value": 978
          }
        },
        "5083be6eb00d4b38861331d60023491f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_914ff81e7a164798b8cce2dcf95783ab",
            "placeholder": "​",
            "style": "IPY_MODEL_121b0346376f47899b42a05f8caf466f",
            "value": " 978/978 [00:00&lt;00:00, 60092.43it/s]"
          }
        },
        "6adf609d503d480ea7489d988f23397c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bcd946acd604460a96000b82f0a257c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a22a08eff354bd2bd3b60c76450e0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43c9dc81a5364c5a8188c664b47234d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aad5a4cb8ba4c7b8f3cf97702e836c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "914ff81e7a164798b8cce2dcf95783ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121b0346376f47899b42a05f8caf466f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26afe17d1b4945d2b3ee00d27b955975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac28198bcf244a18a60483c4b5628143",
              "IPY_MODEL_cc16beab8d784092a4b47f52c2276698",
              "IPY_MODEL_09d88b87407c47a183a445dc88a99d83"
            ],
            "layout": "IPY_MODEL_452631053f0c4292ba06b83b31bb3d41"
          }
        },
        "ac28198bcf244a18a60483c4b5628143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71a451d3e8c48819fe545f626958cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_670b1b3da11c4640844b809b9dea90aa",
            "value": "100%"
          }
        },
        "cc16beab8d784092a4b47f52c2276698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_202b3933d0464b36baaab2adeb68e28b",
            "max": 497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96d6908b6d054e51aa3a02d576b8af49",
            "value": 497
          }
        },
        "09d88b87407c47a183a445dc88a99d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74627f3e083e457abc7071b8c44a42ec",
            "placeholder": "​",
            "style": "IPY_MODEL_f920475979ba4d9fae2a2a0845622d2b",
            "value": " 497/497 [1:52:35&lt;00:00, 70.73s/step, batch_loss=26.801590, loss=2.224568]"
          }
        },
        "452631053f0c4292ba06b83b31bb3d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71a451d3e8c48819fe545f626958cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670b1b3da11c4640844b809b9dea90aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "202b3933d0464b36baaab2adeb68e28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d6908b6d054e51aa3a02d576b8af49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74627f3e083e457abc7071b8c44a42ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f920475979ba4d9fae2a2a0845622d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "face27d143504e2e8c16903a6af6c870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae552eb2cf56452490573ef78304acab",
              "IPY_MODEL_b7c843d20d0644bc8cbdc0ae0ec11df6",
              "IPY_MODEL_3964a59f2e224e759e734157813e1181"
            ],
            "layout": "IPY_MODEL_10e8db00a90549319513197e8bda52c0"
          }
        },
        "ae552eb2cf56452490573ef78304acab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d5a75e6cc34d239af47521a0d8b542",
            "placeholder": "​",
            "style": "IPY_MODEL_44bfb033180145798dac9a8c4b4f5b3b",
            "value": "100%"
          }
        },
        "b7c843d20d0644bc8cbdc0ae0ec11df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6d4454e553343a7985f2f60054bca5a",
            "max": 3709,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_008a1091ee034ec9a1aee5acef521ef0",
            "value": 3709
          }
        },
        "3964a59f2e224e759e734157813e1181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fcb27f56cc4d49a45cafd6537c3261",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe1c597320b49ffbe7d9ee34a0a8c2e",
            "value": " 3709/3709 [00:00&lt;00:00, 169641.93it/s]"
          }
        },
        "10e8db00a90549319513197e8bda52c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d5a75e6cc34d239af47521a0d8b542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44bfb033180145798dac9a8c4b4f5b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6d4454e553343a7985f2f60054bca5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008a1091ee034ec9a1aee5acef521ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43fcb27f56cc4d49a45cafd6537c3261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe1c597320b49ffbe7d9ee34a0a8c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}